[
  {
    "objectID": "repos.html",
    "href": "repos.html",
    "title": "Repositories",
    "section": "",
    "text": "This page shows an overview of the public repositories in my Github/Gitlab:\n\nRepos to use the U-Net algorithm (i.e., deep learning algorithm) to make a land use/land cover classification U-netR or a 3D version used to detect deforestation UnetRDef.\nRepo with several scripts to perform different analyses for updating some of Mexico’s Natural Capital indicators (Capital Natural de México). This repo contains much of the work I did in CONABIO (Comisión Nacional para el Conocimiento y Uso de la Biodiversidad) BiodiversidadES.\nRepo to model aboveground biomass (AGB) using LiDAR. Includes scripts for calculating AGB, extracting LiDAR metrics, fitting different models, making AGB predictions, and writing a manuscript using RMarkdown. AGBLiDAR.\nRepo to calculate some basic forest’s structural and diversity attributes: VegCommunity.\nRepo to fit linear models using the forest attributes as dependent variables and image texture as independent ones: RSModels.\nRepo to extract additional parameters from the BFAST model, i.e., a method to detect disturbances from images time series (e.g., amplitude, magnitude, R2, NA percentage, stable historical period): bfast_params_extr.\nRepo that contains the files to build the GEE manual book using bookdown GEE_manual.\nRepo that contains the analyses used to discriminate between degraded and conserved forests Conserved-vs-Degraded-Forest.\nRepo to classify vegetation in high and intermediate productivity (using NDVI) to distinguish conserved forest from secondary/degraded Class-HPV-Deg.\nRepo with a leaflet html. Cuilala-map."
  },
  {
    "objectID": "posts/2025-03-17-Map-accuracy-in-R.html",
    "href": "posts/2025-03-17-Map-accuracy-in-R.html",
    "title": "Map accuracy in R",
    "section": "",
    "text": "This post will show you how to validate a classification map using the Olofsson et al., 2014 best practices protocol and the mapaccuracy package.\nlibrary(mapaccuracy)\nlibrary(tidyverse)\n\n\nThis data simulates the map accuracy results obtained from a stratified random sampling. This validation procedure is a modification of the Olofsson et al., 2014 recommendations, in which a buffer stratum is used to try to contain omission errors in the rarest classes (i.e., deforestation), following recommendations by Olofsson et al., 2020 and Arévalo et al., 2021.\nThe two datasets you will need to obtain the validation main results are: area estimates (obtained from cell counting in the classification) and results obtained from the stratified random sampling indicating the map (i.e., classified) and reference (i.e., visual interpretation of field data) classes.\nareas2 &lt;- tibble(Clase = c(\"Forest loss\", \"Perm Forest\", \"Perm Non-forest\", \"Buff Perm Forest\", \"Buff Perm Non-forest\"),\n                 ha = c(5, 1950, 8000, 50, 25))\n\ndf &lt;- tibble(Map = c(rep(\"Forest loss\", 50),\n                      rep(\"Perm Forest\", 360),\n                      rep(\"Perm Non-forest\", 90),\n                      rep(\"Buff Perm Forest\", 50),\n                      rep(\"Buff Perm Non-forest\", 25)),\n             Reference = c(rep(\"Forest loss\", 43),\n                            rep(\"Perm Non-forest\", 2),\n                            rep(\"Perm Forest\", 5),\n                            rep(\"Perm Non-forest\", 10),\n                            rep(\"Perm Forest\", 350),\n                            rep(\"Perm Non-forest\", 81),\n                            rep(\"Perm Forest\", 9),\n                            rep(\"Buff Perm Forest\", 48),\n                            rep(\"Forest loss\", 2),\n                            rep(\"Buff Perm Non-forest\", 25)))\n\n\n\nConvert area estimates to a vector with names and calculate the total area.\nareas &lt;- areas2$ha\nnames(areas) &lt;- areas2$Clase\n\ntotalarea &lt;- sum(areas2$ha)\nThen, let’s calculate the map accuracy estimates using Olofsson et al., 2014 equations.\nresul &lt;- olofsson(df$Reference, df$Map, Nh = areas)\nHere, the results object contains estimates such as: Overall accuracy, User’s accuracy, Producer’s accuracy, unbiased area estimates (as proportion), Standard error of the accuracies (overall, user’s and producer’s) and area estimates, and the matrix expressed in area weights.\nresul\n# $OA\n# [1] 0.9145696\n# \n# $UA\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.8600000           0.9722222           0.9000000           0.9600000 \n# Buff Perm Non-forest \n# 1.0000000 \n# \n# $PA\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.6825397           0.7031153           0.9925057           1.0000000 \n# Buff Perm Non-forest \n# 1.0000000 \n# \n# $area\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.0006281157        0.2688268528        0.7232668661        0.0047856431 \n# Buff Perm Non-forest \n# 0.0024925224 \n# \n# $SEoa\n# [1] 0.02542024\n# \n# $SEua\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.049569576         0.008673299         0.031799936         0.027994168 \n# Buff Perm Non-forest \n# 0.000000000 \n# \n# $SEpa\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.152157323         0.066365204         0.002328898         0.000000000 \n# Buff Perm Non-forest \n# 0.000000000 \n# \n# $SEa\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.0001417231        0.0254198567        0.0254198515        0.0001395522 \n# Buff Perm Non-forest \n# 0.0000000000 \n# \n# $matrix\n# Forest loss  Perm Forest Perm Non-forest Buff Perm Forest\n# Forest loss        0.0004287139 4.985045e-05   1.994018e-05               NA\n# Perm Forest                     NA 1.890163e-01   5.400465e-03               NA\n# Perm Non-forest                  NA 7.976072e-02   7.178465e-01               NA\n# Buff Perm Forest      0.0001994018           NA             NA      0.004785643\n# Buff Perm Non-forest             NA           NA             NA               NA\n# sum                   0.0006281157 2.688269e-01   7.232669e-01      0.004785643\n# Buff Perm Non-forest          sum\n# Forest loss                       NA 0.0004985045\n# Perm Forest                          NA 0.1944167498\n# Perm Non-forest                       NA 0.7976071785\n# Buff Perm Forest                     NA 0.0049850449\n# Buff Perm Non-forest         0.002492522 0.0024925224\n# sum                         0.002492522 1.0000000000\nAfterward, you need to sum some area estimates and errors to merge the buffer classes with the total classes (e.g., Buff Perm Forest with Perm Forest). And calculate the lower and upeer limits of the unbiased area estimates, assuming a normal distribution. The classes you need to sum will vary depending on the sampling design used to validate the map.\nexp_df &lt;- tibble(clase = names(resul$area),\n                 area = resul$area * totalarea,\n                 SEa = resul$SEa * totalarea)\n\n# Sum errors\nexp_df$areaSum &lt;- 0\nexp_df$SEaSum &lt;- 0\n\n# Perm Forest\nexp_df$areaSum[2] &lt;- exp_df$area[2] + exp_df$area[5]\nexp_df$SEaSum[2] &lt;- exp_df$SEa[2] + exp_df$SEa[5]\n\n# Perm Non-forest\nexp_df$areaSum[3] &lt;- exp_df$area[3] + exp_df$area[4]\nexp_df$SEaSum[3] &lt;- exp_df$SEa[3] + exp_df$SEa[4]\n\n# Forest loss\nexp_df$areaSum[1] &lt;- exp_df$area[1]\nexp_df$SEaSum[1] &lt;- exp_df$SEa[1]\n\nexp_df |&gt;\n  slice_head(n = 3) |&gt;\n  mutate(LIC = areaSum - 1.96 * SEaSum,\n         UIC = areaSum + 1.96 * SEaSum) \nAnd you get your unbiased area estimates with a confidence interval.\n# A tibble: 3 × 7\n# clase             area    SEa areaSum SEaSum     LIC     UIC\n# &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n# 1 Forest loss     6.3    1.42     6.3   1.42    3.51    9.09\n# 2 Perm Forest     2696.  255.    2721.  255.   2222.   3221.  \n# 3 Perm Non-forest 7254.  255.    7302.  256.   6800.   7805.  \n\n\n\nArévalo, P., Olofsson, P., & Woodcock, C. E. (2020). Continuous monitoring of land change activities and post-disturbance dynamics from Landsat time series: A test methodology for REDD+ reporting. Remote Sensing of Environment, 238, 111051. https://doi.org/10.1016/j.rse.2019.01.013\nOlofsson, P., Foody, G. M., Herold, M., Stehman, S. V., Woodcock, C. E., & Wulder, M. A. (2014). Good practices for estimating area and assessing accuracy of land change. Remote Sensing of Environment, 148, 42–57. https://doi.org/10.1016/j.rse.2014.02.015\nOlofsson, P., Arévalo, P., Espejo, A. B., Green, C., Lindquist, E., McRoberts, R. E., & Sanz, M. J. (2020). Mitigating the effects of omission errors on area and area change estimates. Remote Sensing of Environment, 236. https://doi.org/10.1016/j.rse.2019.111492"
  },
  {
    "objectID": "posts/2025-03-17-Map-accuracy-in-R.html#data",
    "href": "posts/2025-03-17-Map-accuracy-in-R.html#data",
    "title": "Map accuracy in R",
    "section": "",
    "text": "This data simulates the map accuracy results obtained from a stratified random sampling. This validation procedure is a modification of the Olofsson et al., 2014 recommendations, in which a buffer stratum is used to try to contain omission errors in the rarest classes (i.e., deforestation), following recommendations by Olofsson et al., 2020 and Arévalo et al., 2021.\nThe two datasets you will need to obtain the validation main results are: area estimates (obtained from cell counting in the classification) and results obtained from the stratified random sampling indicating the map (i.e., classified) and reference (i.e., visual interpretation of field data) classes.\nareas2 &lt;- tibble(Clase = c(\"Forest loss\", \"Perm Forest\", \"Perm Non-forest\", \"Buff Perm Forest\", \"Buff Perm Non-forest\"),\n                 ha = c(5, 1950, 8000, 50, 25))\n\ndf &lt;- tibble(Map = c(rep(\"Forest loss\", 50),\n                      rep(\"Perm Forest\", 360),\n                      rep(\"Perm Non-forest\", 90),\n                      rep(\"Buff Perm Forest\", 50),\n                      rep(\"Buff Perm Non-forest\", 25)),\n             Reference = c(rep(\"Forest loss\", 43),\n                            rep(\"Perm Non-forest\", 2),\n                            rep(\"Perm Forest\", 5),\n                            rep(\"Perm Non-forest\", 10),\n                            rep(\"Perm Forest\", 350),\n                            rep(\"Perm Non-forest\", 81),\n                            rep(\"Perm Forest\", 9),\n                            rep(\"Buff Perm Forest\", 48),\n                            rep(\"Forest loss\", 2),\n                            rep(\"Buff Perm Non-forest\", 25)))"
  },
  {
    "objectID": "posts/2025-03-17-Map-accuracy-in-R.html#process",
    "href": "posts/2025-03-17-Map-accuracy-in-R.html#process",
    "title": "Map accuracy in R",
    "section": "",
    "text": "Convert area estimates to a vector with names and calculate the total area.\nareas &lt;- areas2$ha\nnames(areas) &lt;- areas2$Clase\n\ntotalarea &lt;- sum(areas2$ha)\nThen, let’s calculate the map accuracy estimates using Olofsson et al., 2014 equations.\nresul &lt;- olofsson(df$Reference, df$Map, Nh = areas)\nHere, the results object contains estimates such as: Overall accuracy, User’s accuracy, Producer’s accuracy, unbiased area estimates (as proportion), Standard error of the accuracies (overall, user’s and producer’s) and area estimates, and the matrix expressed in area weights.\nresul\n# $OA\n# [1] 0.9145696\n# \n# $UA\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.8600000           0.9722222           0.9000000           0.9600000 \n# Buff Perm Non-forest \n# 1.0000000 \n# \n# $PA\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.6825397           0.7031153           0.9925057           1.0000000 \n# Buff Perm Non-forest \n# 1.0000000 \n# \n# $area\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.0006281157        0.2688268528        0.7232668661        0.0047856431 \n# Buff Perm Non-forest \n# 0.0024925224 \n# \n# $SEoa\n# [1] 0.02542024\n# \n# $SEua\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.049569576         0.008673299         0.031799936         0.027994168 \n# Buff Perm Non-forest \n# 0.000000000 \n# \n# $SEpa\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.152157323         0.066365204         0.002328898         0.000000000 \n# Buff Perm Non-forest \n# 0.000000000 \n# \n# $SEa\n# Forest loss         Perm Forest      Perm Non-forest    Buff Perm Forest \n# 0.0001417231        0.0254198567        0.0254198515        0.0001395522 \n# Buff Perm Non-forest \n# 0.0000000000 \n# \n# $matrix\n# Forest loss  Perm Forest Perm Non-forest Buff Perm Forest\n# Forest loss        0.0004287139 4.985045e-05   1.994018e-05               NA\n# Perm Forest                     NA 1.890163e-01   5.400465e-03               NA\n# Perm Non-forest                  NA 7.976072e-02   7.178465e-01               NA\n# Buff Perm Forest      0.0001994018           NA             NA      0.004785643\n# Buff Perm Non-forest             NA           NA             NA               NA\n# sum                   0.0006281157 2.688269e-01   7.232669e-01      0.004785643\n# Buff Perm Non-forest          sum\n# Forest loss                       NA 0.0004985045\n# Perm Forest                          NA 0.1944167498\n# Perm Non-forest                       NA 0.7976071785\n# Buff Perm Forest                     NA 0.0049850449\n# Buff Perm Non-forest         0.002492522 0.0024925224\n# sum                         0.002492522 1.0000000000\nAfterward, you need to sum some area estimates and errors to merge the buffer classes with the total classes (e.g., Buff Perm Forest with Perm Forest). And calculate the lower and upeer limits of the unbiased area estimates, assuming a normal distribution. The classes you need to sum will vary depending on the sampling design used to validate the map.\nexp_df &lt;- tibble(clase = names(resul$area),\n                 area = resul$area * totalarea,\n                 SEa = resul$SEa * totalarea)\n\n# Sum errors\nexp_df$areaSum &lt;- 0\nexp_df$SEaSum &lt;- 0\n\n# Perm Forest\nexp_df$areaSum[2] &lt;- exp_df$area[2] + exp_df$area[5]\nexp_df$SEaSum[2] &lt;- exp_df$SEa[2] + exp_df$SEa[5]\n\n# Perm Non-forest\nexp_df$areaSum[3] &lt;- exp_df$area[3] + exp_df$area[4]\nexp_df$SEaSum[3] &lt;- exp_df$SEa[3] + exp_df$SEa[4]\n\n# Forest loss\nexp_df$areaSum[1] &lt;- exp_df$area[1]\nexp_df$SEaSum[1] &lt;- exp_df$SEa[1]\n\nexp_df |&gt;\n  slice_head(n = 3) |&gt;\n  mutate(LIC = areaSum - 1.96 * SEaSum,\n         UIC = areaSum + 1.96 * SEaSum) \nAnd you get your unbiased area estimates with a confidence interval.\n# A tibble: 3 × 7\n# clase             area    SEa areaSum SEaSum     LIC     UIC\n# &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n# 1 Forest loss     6.3    1.42     6.3   1.42    3.51    9.09\n# 2 Perm Forest     2696.  255.    2721.  255.   2222.   3221.  \n# 3 Perm Non-forest 7254.  255.    7302.  256.   6800.   7805."
  },
  {
    "objectID": "posts/2025-03-17-Map-accuracy-in-R.html#references",
    "href": "posts/2025-03-17-Map-accuracy-in-R.html#references",
    "title": "Map accuracy in R",
    "section": "",
    "text": "Arévalo, P., Olofsson, P., & Woodcock, C. E. (2020). Continuous monitoring of land change activities and post-disturbance dynamics from Landsat time series: A test methodology for REDD+ reporting. Remote Sensing of Environment, 238, 111051. https://doi.org/10.1016/j.rse.2019.01.013\nOlofsson, P., Foody, G. M., Herold, M., Stehman, S. V., Woodcock, C. E., & Wulder, M. A. (2014). Good practices for estimating area and assessing accuracy of land change. Remote Sensing of Environment, 148, 42–57. https://doi.org/10.1016/j.rse.2014.02.015\nOlofsson, P., Arévalo, P., Espejo, A. B., Green, C., Lindquist, E., McRoberts, R. E., & Sanz, M. J. (2020). Mitigating the effects of omission errors on area and area change estimates. Remote Sensing of Environment, 236. https://doi.org/10.1016/j.rse.2019.111492"
  },
  {
    "objectID": "posts/2024-12-13-Create-certificates-in-R.html",
    "href": "posts/2024-12-13-Create-certificates-in-R.html",
    "title": "Create certificates in R",
    "section": "",
    "text": "Create participation certificates in R\nThis post will show you how to create certificates automatically using R. First, install and load the labeleR package. I will use tibble to create the the table containing the names.\nlibrary(labeleR)\nlibrary(tibble)\nCreate or read the table containing the names\ndf &lt;- tibble(Names = c(\"John Smith\", \"Alejandra Pérez\", \"Hans Zimmer\"))\n\n\nAttendees\nCreate attendees cerficates. Here you can indicate the language of the certificate (Spanish or English), the column name containing the names in df, the name of the Congress, date, hour, signer and logos. If you want to customize the certificate, you can use an Rmd template.\ncreate_attendance_certificate(\n  data = df,\n  path = \"labeleR_output\",\n  filename = \"attendance_certificates\",\n  language = \"Spanish\" ,\n  name.column = \"Names\",\n  # type = \"Congress\",\n  title = \"Congreso Nacional de Geografía \",\n  date = \"23/06/2024\",\n  hours = \"24\",\n  # freetext = \"taught by Professor S. Snape\",\n  signer = \"Elmer Homero\",\n  signer.role = \"Organizados\",\n  rpic = \"Rlogo.png\",\n  lpic = \"Rlogo.png\",\n  # keep.files = TRUE, \n  signature.pic = \"signEx.png\",\n  template = \"miFormato.Rmd\"\n)\nI wanted to customize the template, so the easiest way is to first run the certificates with keep.files = TRUE. This will add the template Rmarkdown file to the output folder. You can copy paste this file and modify it at your will (knowing a little laTex). The following template enables adding a background image for the template. Notice that you could modify the spaces and area between the text.\nHere is the code for the template in latex (since output is pdf).\n---\ntitle: ''\ngeometry: \"left=2cm,right=2cm,top=1cm,bottom=1cm\"\noutput:\n  pdf_document: default\nheader-includes: \\usepackage{tikz}\nclassoption: landscape\nparams:\n  name.column.i: \"\"\n  type: \"\"\n  title: \"\"\n  date: \"\"\n  hours: \"\"\n  freetext: \"\"\n  signer: \"\"\n  signer.role: \"\"\n---\n\n\\begin{center}\n\\pagenumbering{gobble}\n\n\\begin{tikzpicture}[remember picture,overlay]\n% draw image\n\\node[inner sep=0] at (current page.center)\n{\\includegraphics[width=\\paperwidth,height=\\paperheight]{D:/Drive/Jonathan_trabaggio/Doctorado/R/Sandbox/background.jpg}};\n\\end{tikzpicture}\n\n% logos %\n\\includegraphics[height=3cm]{lpic.png} \n\\hfill\n\\includegraphics[height=3cm]{rpic.png}\n\\linebreak\n\\vfill\n\n{\\fontsize{40pt}{40pt}\\selectfont\\bf Certificado de asistencia} \n\\vfill\n\n{\\fontsize{40pt}{40pt}\\selectfont `r params$name.column.i` } \\\\\n\\vfill\n\n\\Large\n\nha asistido al `r params$type` {\\bf `r params$title`} \\\\\n\\vfill\n\n`r params$freetext` \\\\\n\\vfill\n\ncon fecha `r params$date` \\\\\n\\vfill\n\ny una duración de `r params$hours` hora(s). \\\\\n\\vfill\n\n% firma %\nFirmado por: \\\\\n\\vfill\n\\includegraphics[height=2cm]{spic.png}\\\\\n`r params$signer` \\\\\n`r params$signer.role` \\\\\n\n\\end{center}\n\\pagebreak\nOnce the past code is run with the corresponding template. This is the result\n\n\n\nCertificate"
  },
  {
    "objectID": "posts/2024-09-02-stac.html",
    "href": "posts/2024-09-02-stac.html",
    "title": "STAC in R",
    "section": "",
    "text": "This blog entry will show how to use STAC using R. This example was based on the original STAC tutorial.\nFirst check data providers in the following link Datasets.\nThen load necessary packages.\nlibrary(sf)\nlibrary(rstac)\nlibrary(stars)\nlibrary(purrr)\nIn this example we will use Sentinel-2 Collection 1 Level 2A from AWS. Other popular providers are the Microsoft Planetary Computer on https://planetarycomputer.microsoft.com/api/stac/v1. Remember to set the url up to “v1”, i.e., not including the collectino per se.\nDefine data provider.\nstac_source &lt;- rstac::stac(\n  \"https://earth-search.aws.element84.com/v1\"\n)\nThen, let’s see which collections are available in the endpoint.\ncol_quer &lt;- stac_source |&gt;\n  rstac::collections()\nBefore running get_request the request is only represented as a future query. Let’s do the request.\navailable_collections &lt;- rstac::get_request(col_quer)\navailable_collections\nCreate a roi or read it from a gpkg file. Need to run at the en st_bbox to be used in the query. Here I created an example roi.\nroi &lt;- st_as_sf(tibble::tibble(lat = c(-101.33706520389003,-101.33706520389003,-100.79873512576503, -100.79873512576503, -101.33706520389003),\n                        lon = c(19.589466998816956, 20.0674578405529, 20.0674578405529,19.589466998816956, 19.589466998816956)),\n         coords = c(\"lat\", \"lon\"),\n         crs = 4326) |&gt;\n  st_cast(\"MULTIPOINT\", group_or_split = TRUE) |&gt;\n  st_union() |&gt;\n  st_cast(\"POLYGON\") \n\nroibbox &lt;- roi |&gt;\n  st_bbox()\nFrom the available collections copy and paste the one you are interested in, set the datetime, roi and limit of images.\nexecuted_stac_query &lt;- rstac::stac_search(\n  q = stac_source,\n  collections = \"sentinel-2-c1-l2a\",\n  bbox = roi,\n  datetime = \"2021-01-01T00:00:00Z/2021-07-31T23:59:59Z\"\n) |&gt;\nrstac::get_request()\nSee objects included in query. Check names of bands of interest so they can be used in the download step.\nsigned_stac_query &lt;- rstac::items_sign(\n  executed_stac_query,\n  rstac::sign_planetary_computer()\n)\nsigned_stac_query\nDownload images\nfolder &lt;- \"myfolder\"\n\nrstac::assets_download(signed_stac_query, \n                       c(\"nir\", \"red\"), \n                       output_dir = folder)\nLet’s check the files. We’ll need a loop to stack the two bands for a single date and then create a spatiotemporal object, setting the date as the time dimension. This checking can be done using terra or stars packages. Here we used stars.\nFinally, let’s plot the first band in the two available dates.\nfiles &lt;- list.files(folder, \"B08|B04\", recursive = TRUE, full.names = TRUE)\n\n# Read only first two images (two dates)\nimgs &lt;- map(c(1,3), function(i){\n  read_stars(files[c(i, (i+1))], proxy = TRUE)\n})\n\n# Stack along the time dimension\nimgs2 &lt;- do.call(c, c(imgs, along = \"time\"))\n\n# See result\nplot(imgs2[1,,,1:2])\n\n\n\nSentinel-2 images showing the first band in two dates."
  },
  {
    "objectID": "posts/2023-11-10-Leaflet-in-r.html",
    "href": "posts/2023-11-10-Leaflet-in-r.html",
    "title": "Leaflet in R",
    "section": "",
    "text": "This post shows how to build beautiful interactive maps in R using leaflet.\nlibrary(leaflet)\nlibrary(sf)\nlibrary(terra)\nlibrary(raster)\nlibrary(RColorBrewer)\nlibrary(htmlwidgets)\n\n\nHere I am reading three different datasets, a polygon (mx_states) and a point (caps) layer, as well as a raster (DEM).\n# States polygons\n# Data downloaded from http://www.conabio.gob.mx/informacion/gis/?vns=gis_root/dipol/estata/dest22gw\nmx_states &lt;- st_read(\"dest22gw.shp\")\n# DEM\n# Data downloaded from: http://www.conabio.gob.mx/informacion/gis/?vns=gis_root/dipol/estata/dest22gw\ndem &lt;- rast(\"filled_demgw.tif\")\n# Capitals\n# Data downloaded from: https://www.efrainmaps.es/descargas-gratuitas/m%C3%A9xico/\ncaps &lt;- st_read(\"México_Ciudades.shp\")\n\n\n\nCreate palettes for the data. Here we are goin to use RcolorBrewer functionalities and some leaflet functions. Also, notice that I am creating two palettes for the DEM. This is a small hack to put the legend in a reverse order (low values in the lower side and higher in the upper one).\n## States palette\ncoul &lt;- brewer.pal(4, \"PuOr\") \npal_st &lt;- colorRampPalette(coul)(33)\n## Dem palette\ncoul &lt;- grDevices::colorRampPalette(c(\"#026449\", \"#12722c\",\"#d7d17e\",\n                                        \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n                                      interpolate = \"spline\",\n                                      bias = 1)(256)\npal_dem &lt;- leaflet::colorNumeric(\n  c(\"#026449\", \"#12722c\",\"#d7d17e\",\n    \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n  values(dem),\n  na.color = \"transparent\",\n  alpha = FALSE,\n  reverse = FALSE\n)\n# Palette hack to invert legend\npal_dem2 &lt;- leaflet::colorNumeric(\n  c(\"#026449\", \"#12722c\",\"#d7d17e\",\n    \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n  values(dem),\n  na.color = \"transparent\",\n  alpha = FALSE,\n  reverse = TRUE\n)\n## Capitals palette, same as states\n\n\n\nThen create the leaflet map. First let’s add the polygons.\nmapa &lt;- leaflet::leaflet()\n\n## Add Polygons\nmapa &lt;- mapa %&gt;% \n    leaflet::addPolygons(data = mx_states,\n                         stroke = TRUE, \n                         smoothFactor = 0.5, \n                         opacity = 1,\n                         fillOpacity = 0.9,\n                         fillColor = ~ pal_st,\n                         weight = ~0.2,\n                         color = ~\"black\",\n                         group = \"States\",\n                         popup = ~mx_states$NOMGEO)\nAdd the raster. Here notice the use of pal_dem2 in addLegend and sort the values in decreasing order using labFormat.\n## Get tange of dem\nminmax &lt;- range(raster::values(dem)[!is.na(raster::values(dem))])\n\n## Add raster\nmapa &lt;- mapa %&gt;% \n  leaflet::addRasterImage(raster::raster(dem), \n                          colors = pal_dem, \n                          opacity = 0.9,  \n                          group = \"DEM\",\n                          layerId = \"DEM\") %&gt;%\n  leaflet::addLegend(position = \"bottomleft\", \n                     pal = pal_dem2, \n                     values = seq(minmax[1], minmax[2], 100), #4 categorical maps terra::levels(dem)[[1]]$ID,\n                     title = \"Elevación m s.n.m\",\n                     labFormat = labelFormat(transform = function(x) sort(x, decreasing = TRUE)))\n                    # for categorical maps\n                     # labFormat =  leaflet::labelFormat(\n                     #   transform = function(x) {\n                     #     df_eq %&gt;%\n                     #       dplyr::filter(ID == x) %&gt;%\n                     #       dplyr::pull(!!sym(key)) \n                     #   })) \nAdd the points. Here I set a different color to the circle inside the marker.\n## Points\n### Create customized markers\n### Can create in several lists, that's why two lapply are used\n### In this case we really only need one level\nresul &lt;- lapply(1:length(pal_st), function(j){\n    leaflet::makeAwesomeIcon(\n      icon = \"circle\",\n      library = \"fa\",\n      iconColor = pal_st[j],\n      markerColor = \"white\",\n      \n    )\n  }) \n# Cast as awesome icon list\nresul &lt;- structure(resul, class = \"leaflet_awesome_icon_set\")\n\n## Add points\nmapa &lt;- mapa %&gt;% \n    leaflet::addAwesomeMarkers(data = caps, \n                               icon = resul,\n                               popup = ~caps$CIUDAD,\n                               group = \"Capitals\")\nAdd three Esri basemaps\n## Base maps\nmapas_base &lt;- c(\"Esri.WorldTopoMap\", \"Esri.WorldImagery\", \"Esri.WorldGrayCanvas\")\n\n# Add basemaps\nfor(provider in mapas_base) {\n  mapa &lt;- mapa %&gt;% \n    leaflet::addProviderTiles(provider, \n                              group = provider)\n}\nAdd controls and mini map. OverlayGroups should match the name given for each layer in the previous sections.\n# Add controls and mini map\nmapa &lt;- mapa %&gt;%\n  leaflet::addLayersControl(overlayGroups = c(\"States\", \"DEM\", \"Capitals\"),\n                            baseGroups = mapas_base,\n                            position = \"topright\",\n                            options = leaflet::layersControlOptions(collapsed = FALSE,\n                                                                    hideSingleBase = TRUE)) %&gt;%\n  leaflet::addMiniMap(tiles = mapas_base[[1]], \n                      toggleDisplay = TRUE,\n                      position = \"bottomleft\") \nAdd more customizations: change base map, zoom to extent of layers, add globe button to reset zoom level to the starting point, add opacity slider.\n# More customizations\nmapa &lt;- mapa %&gt;%\n  # update base map\n  htmlwidgets::onRender(\"\n    function(el, x) {\n      var myMap = this;\n      myMap.on('baselayerchange',\n        function (e) {\n          myMap.minimap.changeLayer(L.tileLayer.provider(e.name));\n        })\n    }\") %&gt;% \n  # add full extent button\n  leaflet::addEasyButton(leaflet::easyButton(\n    icon = \"fa-globe\", \n    title = \"Zoom to Level 1\",\n    onClick = leaflet::JS(\"function(btn, map){ map.fitBounds([\n                                        [\", 14.55712, \",\", -117.12579, \"], \",\n                          \"[\", 32.71876, \",\", -86.74011, \"]\n                                        ]); }\"))) %&gt;%\n  # opacity slider\n  leaflet::addControl(html = \"&lt;input id=\\\"OpacitySlide\\\" type=\\\"range\\\" min=\\\"0\\\" max=\\\"1\\\" step=\\\"0.1\\\" value=\\\"0.5\\\"&gt;\") %&gt;%\n  # change opacity of the layers\n  htmlwidgets::onRender(\n    \"function(el,x,data){\n                     var map = this;\n                     var evthandler = function(e){\n                        var layers = map.layerManager.getVisibleGroups();\n                        console.log('VisibleGroups: ', layers); \n                        console.log('Target value: ', +e.target.value);\n                        layers.forEach(function(group) {\n                          var layer = map.layerManager._byGroup[group];\n                          console.log('currently processing: ', group);\n                          Object.keys(layer).forEach(function(el){\n                            if(layer[el] instanceof L.Polygon){;\n                            console.log('Change opacity of: ', group, el);\n                             layer[el].setStyle({fillOpacity:+e.target.value});\n                            }\n                          });\n                        })\n                     };\n              $('#OpacitySlide').mousedown(function () { map.dragging.disable(); });\n              $('#OpacitySlide').mouseup(function () { map.dragging.enable(); });\n              $('#OpacitySlide').on('input', evthandler)}\n          \")\nSave file as html widget.\nhtmlwidgets::saveWidget(mapa, \n                        \"Map1.html\")\nThe final result (click on the following image to access the map):\n\n\n\nInteractive leaflet map."
  },
  {
    "objectID": "posts/2023-11-10-Leaflet-in-r.html#read-data",
    "href": "posts/2023-11-10-Leaflet-in-r.html#read-data",
    "title": "Leaflet in R",
    "section": "",
    "text": "Here I am reading three different datasets, a polygon (mx_states) and a point (caps) layer, as well as a raster (DEM).\n# States polygons\n# Data downloaded from http://www.conabio.gob.mx/informacion/gis/?vns=gis_root/dipol/estata/dest22gw\nmx_states &lt;- st_read(\"dest22gw.shp\")\n# DEM\n# Data downloaded from: http://www.conabio.gob.mx/informacion/gis/?vns=gis_root/dipol/estata/dest22gw\ndem &lt;- rast(\"filled_demgw.tif\")\n# Capitals\n# Data downloaded from: https://www.efrainmaps.es/descargas-gratuitas/m%C3%A9xico/\ncaps &lt;- st_read(\"México_Ciudades.shp\")"
  },
  {
    "objectID": "posts/2023-11-10-Leaflet-in-r.html#create-palettes",
    "href": "posts/2023-11-10-Leaflet-in-r.html#create-palettes",
    "title": "Leaflet in R",
    "section": "",
    "text": "Create palettes for the data. Here we are goin to use RcolorBrewer functionalities and some leaflet functions. Also, notice that I am creating two palettes for the DEM. This is a small hack to put the legend in a reverse order (low values in the lower side and higher in the upper one).\n## States palette\ncoul &lt;- brewer.pal(4, \"PuOr\") \npal_st &lt;- colorRampPalette(coul)(33)\n## Dem palette\ncoul &lt;- grDevices::colorRampPalette(c(\"#026449\", \"#12722c\",\"#d7d17e\",\n                                        \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n                                      interpolate = \"spline\",\n                                      bias = 1)(256)\npal_dem &lt;- leaflet::colorNumeric(\n  c(\"#026449\", \"#12722c\",\"#d7d17e\",\n    \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n  values(dem),\n  na.color = \"transparent\",\n  alpha = FALSE,\n  reverse = FALSE\n)\n# Palette hack to invert legend\npal_dem2 &lt;- leaflet::colorNumeric(\n  c(\"#026449\", \"#12722c\",\"#d7d17e\",\n    \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n  values(dem),\n  na.color = \"transparent\",\n  alpha = FALSE,\n  reverse = TRUE\n)\n## Capitals palette, same as states"
  },
  {
    "objectID": "posts/2023-11-10-Leaflet-in-r.html#leaflet-map",
    "href": "posts/2023-11-10-Leaflet-in-r.html#leaflet-map",
    "title": "Leaflet in R",
    "section": "",
    "text": "Then create the leaflet map. First let’s add the polygons.\nmapa &lt;- leaflet::leaflet()\n\n## Add Polygons\nmapa &lt;- mapa %&gt;% \n    leaflet::addPolygons(data = mx_states,\n                         stroke = TRUE, \n                         smoothFactor = 0.5, \n                         opacity = 1,\n                         fillOpacity = 0.9,\n                         fillColor = ~ pal_st,\n                         weight = ~0.2,\n                         color = ~\"black\",\n                         group = \"States\",\n                         popup = ~mx_states$NOMGEO)\nAdd the raster. Here notice the use of pal_dem2 in addLegend and sort the values in decreasing order using labFormat.\n## Get tange of dem\nminmax &lt;- range(raster::values(dem)[!is.na(raster::values(dem))])\n\n## Add raster\nmapa &lt;- mapa %&gt;% \n  leaflet::addRasterImage(raster::raster(dem), \n                          colors = pal_dem, \n                          opacity = 0.9,  \n                          group = \"DEM\",\n                          layerId = \"DEM\") %&gt;%\n  leaflet::addLegend(position = \"bottomleft\", \n                     pal = pal_dem2, \n                     values = seq(minmax[1], minmax[2], 100), #4 categorical maps terra::levels(dem)[[1]]$ID,\n                     title = \"Elevación m s.n.m\",\n                     labFormat = labelFormat(transform = function(x) sort(x, decreasing = TRUE)))\n                    # for categorical maps\n                     # labFormat =  leaflet::labelFormat(\n                     #   transform = function(x) {\n                     #     df_eq %&gt;%\n                     #       dplyr::filter(ID == x) %&gt;%\n                     #       dplyr::pull(!!sym(key)) \n                     #   })) \nAdd the points. Here I set a different color to the circle inside the marker.\n## Points\n### Create customized markers\n### Can create in several lists, that's why two lapply are used\n### In this case we really only need one level\nresul &lt;- lapply(1:length(pal_st), function(j){\n    leaflet::makeAwesomeIcon(\n      icon = \"circle\",\n      library = \"fa\",\n      iconColor = pal_st[j],\n      markerColor = \"white\",\n      \n    )\n  }) \n# Cast as awesome icon list\nresul &lt;- structure(resul, class = \"leaflet_awesome_icon_set\")\n\n## Add points\nmapa &lt;- mapa %&gt;% \n    leaflet::addAwesomeMarkers(data = caps, \n                               icon = resul,\n                               popup = ~caps$CIUDAD,\n                               group = \"Capitals\")\nAdd three Esri basemaps\n## Base maps\nmapas_base &lt;- c(\"Esri.WorldTopoMap\", \"Esri.WorldImagery\", \"Esri.WorldGrayCanvas\")\n\n# Add basemaps\nfor(provider in mapas_base) {\n  mapa &lt;- mapa %&gt;% \n    leaflet::addProviderTiles(provider, \n                              group = provider)\n}\nAdd controls and mini map. OverlayGroups should match the name given for each layer in the previous sections.\n# Add controls and mini map\nmapa &lt;- mapa %&gt;%\n  leaflet::addLayersControl(overlayGroups = c(\"States\", \"DEM\", \"Capitals\"),\n                            baseGroups = mapas_base,\n                            position = \"topright\",\n                            options = leaflet::layersControlOptions(collapsed = FALSE,\n                                                                    hideSingleBase = TRUE)) %&gt;%\n  leaflet::addMiniMap(tiles = mapas_base[[1]], \n                      toggleDisplay = TRUE,\n                      position = \"bottomleft\") \nAdd more customizations: change base map, zoom to extent of layers, add globe button to reset zoom level to the starting point, add opacity slider.\n# More customizations\nmapa &lt;- mapa %&gt;%\n  # update base map\n  htmlwidgets::onRender(\"\n    function(el, x) {\n      var myMap = this;\n      myMap.on('baselayerchange',\n        function (e) {\n          myMap.minimap.changeLayer(L.tileLayer.provider(e.name));\n        })\n    }\") %&gt;% \n  # add full extent button\n  leaflet::addEasyButton(leaflet::easyButton(\n    icon = \"fa-globe\", \n    title = \"Zoom to Level 1\",\n    onClick = leaflet::JS(\"function(btn, map){ map.fitBounds([\n                                        [\", 14.55712, \",\", -117.12579, \"], \",\n                          \"[\", 32.71876, \",\", -86.74011, \"]\n                                        ]); }\"))) %&gt;%\n  # opacity slider\n  leaflet::addControl(html = \"&lt;input id=\\\"OpacitySlide\\\" type=\\\"range\\\" min=\\\"0\\\" max=\\\"1\\\" step=\\\"0.1\\\" value=\\\"0.5\\\"&gt;\") %&gt;%\n  # change opacity of the layers\n  htmlwidgets::onRender(\n    \"function(el,x,data){\n                     var map = this;\n                     var evthandler = function(e){\n                        var layers = map.layerManager.getVisibleGroups();\n                        console.log('VisibleGroups: ', layers); \n                        console.log('Target value: ', +e.target.value);\n                        layers.forEach(function(group) {\n                          var layer = map.layerManager._byGroup[group];\n                          console.log('currently processing: ', group);\n                          Object.keys(layer).forEach(function(el){\n                            if(layer[el] instanceof L.Polygon){;\n                            console.log('Change opacity of: ', group, el);\n                             layer[el].setStyle({fillOpacity:+e.target.value});\n                            }\n                          });\n                        })\n                     };\n              $('#OpacitySlide').mousedown(function () { map.dragging.disable(); });\n              $('#OpacitySlide').mouseup(function () { map.dragging.enable(); });\n              $('#OpacitySlide').on('input', evthandler)}\n          \")\nSave file as html widget.\nhtmlwidgets::saveWidget(mapa, \n                        \"Map1.html\")\nThe final result (click on the following image to access the map):\n\n\n\nInteractive leaflet map."
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html",
    "title": "Rasters and vectors with terra",
    "section": "",
    "text": "This post shows a simple example of how to work with rasters and vectors using the terra package. Terra replaces the older raster package, since terra is usually faster to use.\nlibrary(tibble)\nlibrary(terra)\nlibrary(dplyr)\nThen create some objects to work with and plot them.\nim1 &lt;- rast(matrix(1:9, nrow = 3),\n            crs = \"EPSG:4326\",\n            extent = c(-103,-100,19,22))\n\npts1 &lt;- vect(data.frame(lon = c(-102.5, -102.5, -100.5, -100.5),\n                        lat = c(19.5, 21.5, 21.5, 19.5)),\n             geom = c(\"lon\", \"lat\"), \n             crs = \"EPSG:4326\")\n\npoly1 &lt;- vect(\"POLYGON ((-102.5 19.5, -102.5 21.5, -100.5 21.5, -100.5 19.5, -102.5 19.5))\",\n             crs = \"EPSG:4326\")\n\nplot(im1)\nplot(pts1, add = T)\nplot(poly1, add = T)\n\n\n\nData."
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#buffer",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#buffer",
    "title": "Rasters and vectors with terra",
    "section": "Buffer",
    "text": "Buffer\npoly2 &lt;- buffer(poly1, width = 10000, capstyle = \"square\")\nplot(poly2)\nplot(poly1, add = T)\n\n\n\nBuffer"
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#intersection",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#intersection",
    "title": "Rasters and vectors with terra",
    "section": "Intersection",
    "text": "Intersection\npoly3 &lt;- intersect(poly2, poly1)\nplot(poly3[[1]])\n\n\n\nIntersection"
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#mask-values",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#mask-values",
    "title": "Rasters and vectors with terra",
    "section": "Mask values",
    "text": "Mask values\nim2 &lt;- im1\nim2[im2&gt;=5] &lt;- NA\nplot(im2)\n\n\n\nMasked raster"
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#operations-over-all-cells",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#operations-over-all-cells",
    "title": "Rasters and vectors with terra",
    "section": "Operations over all cells",
    "text": "Operations over all cells\n# Stack same image\nim3 &lt;- c(im1, im1)\n\nim4 &lt;- app(im3, fun = \"sum\")\nplot(im4)\n\n\n\nSum of both bands"
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#global-operations",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#global-operations",
    "title": "Rasters and vectors with terra",
    "section": "Global operations",
    "text": "Global operations\nglobal(im1, fun = \"mean\")\n      mean\nlyr.1    5"
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#focal-operations",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#focal-operations",
    "title": "Rasters and vectors with terra",
    "section": "Focal operations",
    "text": "Focal operations\nim5 &lt;- focal(im1, w = 3, fun = \"max\")\nplot(im5)\n\n\n\nFocal max."
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#crop",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#crop",
    "title": "Rasters and vectors with terra",
    "section": "Crop",
    "text": "Crop\nim1_c &lt;- crop(im1, poly1)\nplot(im1_c)\n\n\n\nCropped images."
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#mask",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#mask",
    "title": "Rasters and vectors with terra",
    "section": "Mask",
    "text": "Mask\nim2_c &lt;- mask(im1, poly1)\nplot(im2_c)\n\n\n\nMasked image (seems nothing happened due to overlap between raster and polygon)."
  },
  {
    "objectID": "posts/2023-07-14-rasters-and-vectors-with-terra.html#extract-values",
    "href": "posts/2023-07-14-rasters-and-vectors-with-terra.html#extract-values",
    "title": "Rasters and vectors with terra",
    "section": "Extract values",
    "text": "Extract values\n\nManual colors\nexpts &lt;- extract(im1, pts1)\n\n# Get x and y coordinates and value\ngeom(pts1) |&gt;\n  as_tibble() |&gt;\n  select(x, y) |&gt;\n  mutate(value = expts|&gt;pull(lyr.1))\n\n# A tibble: 4 × 3\n      x     y value\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 -102.  19.5     3\n2 -102.  21.5     1\n3 -100.  21.5     7\n4 -100.  19.5     9"
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "",
    "text": "The purpose of this post is to show how to use the basic syntax of ggplot2, do some of the most common types of plots, as well as some customizations and facets. For this post we are going to use the iris dataset, as well as the skimr and cowplot packages. The first step consists of loading the desired packages, as well as the data and skimming over it. The first section will show some basic plots, while the next ones will show how to customize certain elements of the plots, like color, fill, facets and theme.\nlibrary(ggplot2)\nlibrary(skimr)\nlibrary(cowplot)\n\ndata(iris)\nskim(iris)\nThen we can start building our different plots."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#scatterplot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#scatterplot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Scatterplot",
    "text": "Scatterplot\niris |&gt;\n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_point()\n]"
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#line-plot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#line-plot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Line plot",
    "text": "Line plot\niris |&gt;\n  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +\n  geom_line()\n]("
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#bar-plot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#bar-plot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Bar plot",
    "text": "Bar plot\niris |&gt;\n  ggplot(aes(x = Species)) +\n  geom_bar()\n]"
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#column-plot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#column-plot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Column plot",
    "text": "Column plot\niris |&gt;\n  group_by(Species) |&gt;\n  summarise(meanSL = mean(Sepal.Length)) |&gt;\n  ggplot(aes(x = Species,\n             y = meanSL)) +\n  geom_col()\n\n\n\nColumn plot."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#box-plot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#box-plot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Box plot",
    "text": "Box plot\niris |&gt;\n  ggplot(aes(x = Species,\n             y = Sepal.Length)) +\n  geom_boxplot()\n\n\n\nBoxplot"
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#histogram-plot",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#histogram-plot",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Histogram plot",
    "text": "Histogram plot\niris |&gt;\nggplot(aes(x = Sepal.Length)) +\n  geom_histogram()\n\n\n\nHistogram"
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#color",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#color",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Color",
    "text": "Color\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point()\n\n\n\nScatterplot with colors by factor."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#fill",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#fill",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Fill",
    "text": "Fill\niris |&gt;\n  ggplot(aes(x = Species,\n             fill = Species)) +\n  geom_bar()\n\n\n\nBarplot with fill by factor."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#customized-colors",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#customized-colors",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Customized colors",
    "text": "Customized colors\n\nManual colors\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  scale_colour_manual(values = c(\"forestgreen\", \"royalblue\", \"firebrick2\"))\n\n\n\nScatterplot with manual colors by factor.\n\n\n\n\nRcolorbrewer\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"RdYlBu\")\n\n\n\nScatterplots with colors set by RColorbrewer."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#axes-1",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#axes-1",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Axes",
    "text": "Axes\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(2, 4.5, 0.25),\n                     limits = c(2, 4.5)) +\n  scale_x_continuous(breaks = seq(4, 8, 0.5),\n                     limits = c(4, 8))\n\n\n\nScatterplot with customized axes."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#axes-labels",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#axes-labels",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Axes labels",
    "text": "Axes labels\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  labs(x = \"Sepal length (cm)\", \n       y = \"Sepal width (cm)\")\n\n\n\nScatterplot with customized axes labels."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#facet-grid",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#facet-grid",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Facet grid",
    "text": "Facet grid\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  facet_grid(~ Species)\n\n\n\nScatterplot with facets set as a grid."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#facet-wrap",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#facet-wrap",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Facet wrap",
    "text": "Facet wrap\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  facet_grid(~ Species)\n\n\n\nScatterplot with facets set as a wrap (multiple factors will be accumulated by each panel)."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#personalized-theme",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#personalized-theme",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Personalized theme",
    "text": "Personalized theme\nmy_theme &lt;- theme_bw() + \n  theme(plot.title=element_text(size=18,hjust = 0.5),\n        text=element_text(size=24,colour=\"black\"),\n        axis.text.x = element_text(size=18,\n                                   colour=\"black\",\n                                   angle = 90, \n                                   hjust = 1,\n                                   vjust = 0.5),\n        axis.text.y = element_text(size=18,\n                                   colour=\"black\",\n                                   angle = 0, \n                                   vjust = 0.5,\n                                   hjust = 1),\n        axis.title = element_text(size=18,\n                                  colour=\"black\",\n                                  face = \"bold\"), \n        axis.line = element_line(colour = \"black\"),\n        legend.title = element_text(size=18),\n        legend.text = element_text(size=18),\n        axis.line.x =element_line(colour=\"black\"),\n        axis.line.y =element_line(colour=\"black\"),\n        panel.grid.major=element_blank(),\n        panel.grid.minor=element_blank(),\n        panel.border=element_blank(),\n        panel.background=element_blank(),\n        strip.background =element_rect(fill=\"gray90\",\n                                       colour = \"black\"),\n        strip.text = element_text(size=18,\n                                  colour=\"black\",\n                                  face = \"bold\"),\n        plot.margin = unit(c(0.01,0.01,0.01,0.01), \"cm\"))\n\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  facet_wrap(~ Species) + \n  my_theme\n\n\n\nScatterplot with facet wrap where several theme elements have been customized according to personal criteria."
  },
  {
    "objectID": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#cowplot-theme",
    "href": "posts/2023-06-22-beautiful-plots(ggplot2)-in-r.html#cowplot-theme",
    "title": "Beautiful-plots(ggplot2)-in-r",
    "section": "Cowplot theme",
    "text": "Cowplot theme\niris |&gt;\n  ggplot(aes(x = Sepal.Length, \n             y = Sepal.Width,\n             col = Species)) +\n  geom_point() +\n  facet_wrap(~ Species) + \n  theme_cowplot()\n]"
  },
  {
    "objectID": "posts/2023-06-09-web-scraping-with-r.html",
    "href": "posts/2023-06-09-web-scraping-with-r.html",
    "title": "Web scraping with r",
    "section": "",
    "text": "Web scraping with R\nThis post will show you how to get data from a webpage (also known as web scraping) with R and the rvest package. This analysis was performed to complement the data obtained from the spotify API. Since I could not obtain all the data I was interested in from the latter API, I decided to web scrape the bandcamp site.\nThe first thing is to load the necessary packages: rvest for the webscraping and purrr for making loops.\nlibrary(rvest)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(dplyr)\nThen, indicate the website of interest. In this case, bandcamp.\nsite_url &lt;- \"https://bandcamp.com/\"\nHere is the dataframe I am going to use to consult the data from bandcamp.\nnogenre &lt;- structure(list(artist = c(\"Discipline\", \"Back from the Futer\", \n\"La Plante Sauvage\", \"Quella Vecchia Locanda\", \"Daal\", \"Bobby Prince\", \n\"Greco Bastian\", \"Wayfarer\", \"Flub\", \"Schizofrnatik\", \"Endolith\", \n\"Energetic Mind\", \"Thanatopsis\", \"Mary Halvorson Octet\", \"4 ciénegas\"\n), album = c(\"Unfolded Like Staircase\", \"Aavikko\", \"Alain Goraguer\", \n\"Quella Vecchia Locanda\", \"Decalgue of Darkness\", \"Doom 2 OST\", \n\"Greco Bastian\", \"A Romance with Violence\", \"Flub\", \"Funk From Hell\", \n\"Voyager\", \"Bonniesongs\", \"Requiem\", \"Away With You\", \"Cuatro ciénegas\"\n), genre = c(NA_character_, NA_character_, NA_character_, NA_character_, \nNA_character_, NA_character_, NA_character_, NA_character_, NA_character_, \nNA_character_, NA_character_, NA_character_, NA_character_, NA_character_, \nNA_character_), url = c(NA, NA, NA, NA, NA, \"https://www.youtube.com/watch?v=OyHqGSO67wo\", \nNA, NA, NA, NA, NA, NA, NA, NA, NA)), row.names = c(37L, 13L, \n77L, 113L, 32L, 19L, 60L, 151L, 54L, 121L, 49L, 50L, 137L, 95L, \n2L), class = \"data.frame\")\nThe next step is creating a function that will be used to make the search in bandcamp. Some additional tweaks had to be made so that the function worked. Most of this part was defined by playing with the bandcamp’s search bar and annotating how the url of the search was processed. Then, you need to inspect the web page to see the names of the sections you are interested in extracting. Finally, I just made some data wragnling to clean the data and export it more homogeneously.\nThe main functions for webscraping with rvest are read_html, html_node and html_text. The first one enables reading the html code of the indicated url. The second one enables extracting one node or section of this web page and finally, the third one converts the extracted object into text.\nrvest_func &lt;- function(x){\n  band_orig &lt;- x\n  # These substitutions were based on trial and error on the bandcamp website.\n  # Substitute spaces by + sign to work with the syntax used to search for terms with more than one word.\n  band &lt;- gsub(\"\\\\s\", \"+\", band_orig)\n  # Transform ñ into the translation made in the search bar\n  band &lt;- gsub(\"ñ\", \"%C3%B1\", band)\n  # Set the url to search for a particular band\n  url_sub2 &lt;- paste0('search?q=',band,'&item_type')\n  \n  # build the url to be scraped by combining the site url with the band url\n  df1 &lt;- paste0(site_url, url_sub2) |&gt; \n    # scrape the html\n    read_html() |&gt; \n    # Inspect the web page to see which sections are available and select the name of the one of interest\n    html_node('.result-info') |&gt;\n    # Get the entries of interes\n    html_node('.tags.data-search') |&gt;\n    # Retrieve the data as text\n    html_text() |&gt;\n    # Replace new lines for nothing\n    str_replace_all(\"\\n\", \"\") |&gt;\n    # Remove the tag \"tags:\"\n    str_replace_all(\"tags: \", \"\") |&gt;\n    # Substitute multiple spaces for a single one\n    str_replace_all(\"\\\\s+\", \" \") |&gt;\n    # Remove spaces between commas, ^ or at the end of the string\n    str_replace_all(\"(?&lt;=\\\\,)\\\\s+|^\\\\s+|\\\\s+$\", \"\")\n  \n  # Separate each genre into its own column\n  df1 &lt;- separate_wider_delim(tibble(genre = df1), \n                              col = genre, \n                              delim = \",\",\n                              names = paste0(\"genre\", 1:20),\n                              too_few = \"align_start\") |&gt;\n    # Transform data into long format\n    pivot_longer(everything(),\n                 names_to = c(\"name\")) |&gt;\n    # Drop NA entries \n    drop_na(value) |&gt;\n    # Select the value column\n    select(value) |&gt;\n    # Rename\n    rename(\"genre\" = \"value\")\n  \n  # Return a tibble with the band name and genres extracted from bandcamp\n  resul &lt;- tibble(artist = rep(band_orig, nrow(df1)),\n                  genre = df1 |&gt; pull(genre))\n  return(resul)\n  }\nUse map to apply the functino to each artist. Use possibly as a TryCatch; thus, if no genre was found for certain artist it will return the message “Error in file”.\nresul_exp_nogenre &lt;- map(nogenre |&gt;\n                             pull(artist), \n                         possibly(rvest_func, \n                                  otherwise = \"Error in file\"))\nThen add the genres as a new column to the previous dataframe and add a counter (llist) that indicates how many genres were associated with each artist.\nprenogenre &lt;- nogenre |&gt;\n  # Add the list with extracted genres to the original df\n  mutate(lista = resul_exp_nogenre) |&gt;\n  # Set a value that indicates if no genres were found for certain artits.\n  # Put 0 if that is the case (using the possibly) or the number of genres found\n  mutate(llist = map(1:length(resul_exp_nogenre), possibly(function(i){\n    nrow(resul_exp_nogenre[[i]])\n  }, otherwise = 0))) |&gt;\n  # unnest, extract elements from list.\n  unnest(llist) \nThen eliminate entries without a genre, and unnest the genres list. Obtain the final data frame.\nnogenreFill &lt;- prenogenre |&gt;\n  # Eliminate artist for which no genre was found\n  filter(llist &gt;= 1) |&gt;\n  # Unnest  lista column\n  unnest(lista,\n         names_repair = \"universal\") |&gt;\n  # Rename column names\n  rename(\"artist\" = \"artist...1\",\n         \"genre\" = \"genre...6\") |&gt;\n  # Select columns of interest.\n  select(artist, album, genre, url)\nA snapshot of the result:\n\n\n\nExample of the data obtained after web scraping the bandcamp site."
  },
  {
    "objectID": "posts/2023-04-04-spotify-in-r.html",
    "href": "posts/2023-04-04-spotify-in-r.html",
    "title": "Spotify API in R",
    "section": "",
    "text": "Spotify API in R\nThis post will show you how to connect to the Spotify API using R and the spotifyR package. This API enables you to extract data for particular artists or songs from the Spotify database.\nThe first step is registering in the Spotify Developer App: https://developer.spotify.com/. Once you are registered, you should create a new app. In that new window you only need to give the app a name, and app description and set some redirect URIs. All the other entries you can leave them empty. For example:\n\n\n\nExample of fields entered in the spotify dashboard.\n\n\nThen you, just need to open R, load the libraries we are going to use.\nlibrary(spotifyr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(forcats)\nand then copy the client id and client secret into R and get the access_token.\nSys.setenv(SPOTIFY_CLIENT_ID = \"My-client-id\")\nSys.setenv(SPOTIFY_CLIENT_SECRET = \"My-client-secret\")\n\naccess_token &lt;- get_spotify_access_token()\nThen you need to read the artist and album database or any other data frame. In this case, I am going to use a small example with some albums I like.\ndf &lt;- tibble(artist = c(\"Warbringer\", \"Satyricon\", \"Meshuggah\"),\n            album = c(\"Woe to the Vanquished\", \"Rebel Extravanganza\", \"Obzen\"))\nThen we are going to use mutate to extract the genre associated with each artist. Since, not all artists have an associated genre (or can be found in spotify), it is advisable to use possibly to avoid errors if no genre was find in the Spotify database. Then use this function and finally, do some data wrangling to obtain each genre associated with an artist in a single row.\nsafer_process_file &lt;- possibly(function(x) {\n  resul &lt;- search_spotify(x, type = \"artist\") |&gt;\n    slice(1) |&gt;\n    select(genres) |&gt;\n    unnest(cols = c(genres))\n  ifelse(nrow(resul) == 0, NA, resul)\n},\notherwise = list(\"Error in file\"))\n\nresul &lt;- df |&gt;\n  # slice(1:9) |&gt;\n  mutate(genre = map(df$artist, safer_process_file))\n\nresul_exp &lt;- resul |&gt;\n  # slice(377) |&gt;\n  unnest(cols = c(genre)) |&gt;\n  unnest(cols = genre,\n         keep_empty = T)\nFinally, you might want to summarise this information into a plot of the most common genres in your df. So we are going to use a circular plot to show this.\n# Make counts by genre and arrange by n\nplotter &lt;- resul_exp |&gt;\n  group_by(genre) |&gt;\n  count() |&gt;\n  arrange(desc(n)) |&gt;\n  ungroup() |&gt;\n  mutate(id = row_number())\n\n# Based on: https://r-graph-gallery.com/296-add-labels-to-circular-barplot.html\n# Get the name and the y position of each label\nlabel_data &lt;- data.frame(genre = plotter$genre,\n                         id = plotter$id,\n                         value = plotter$n)\n\n# calculate the ANGLE of the labels\nnumber_of_bar &lt;- nrow(label_data)\nangle &lt;-  90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)\n\n# calculate the alignment of labels: right or left\n# Left part of the plot labels will have an angle &lt; -90\nlabel_data$hjust&lt;-ifelse(angle &lt; -90, 1, 0)\n\n# flip angle BY to make them readable\nlabel_data$angle&lt;-ifelse(angle &lt; -90, angle+180, angle)\n\n# Start the plot\nplotter |&gt;\n  ggplot(aes(x=as.factor(id), y=n)) +       \n  # This add the bars with a purple color\n  geom_bar(stat=\"identity\", fill=alpha(\"#8b1c61\", 0.7)) +\n  # First parameter: size of inner circle, second one, margins on the outer circle\n  ylim(-50,100) +\n  # Minimal theme\n  theme_minimal() +\n  # Transform normal bar plot to circular\n  coord_polar(start = 0) +\n  # Add the labels, using the label_data dataframe that we have created before\n  geom_text(data=label_data,\n            aes(x=id,\n                y=value+0.5, label=genre, hjust=hjust),\n            color=\"black\",\n            fontface=\"bold\",\n            alpha=1,\n            size=2,\n            angle= label_data$angle,\n            inherit.aes = FALSE ) +\n  theme(plot.margin = margin(-3, -10, -3, -10, \"cm\"),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        panel.grid = element_blank()#,\n  )\n\nggsave(\"genreSimple.png\",\n       device = \"pdf\",\n       width = 15,\n       height = 15,\n       units = \"cm\",\n       dpi = 300)\nThe result:\n\n\n\nCircular bar plot of the genres.\n\n\nIt is pretty obvious I like metal! 🤘"
  },
  {
    "objectID": "posts/2023-03-05-shaded-relief-maps-in-r.html",
    "href": "posts/2023-03-05-shaded-relief-maps-in-r.html",
    "title": "Shaded relief maps in R",
    "section": "",
    "text": "Shaded relief maps in R\nThis is a follow up of the series of experiments I have been working with rayshader. In this post, I will focus on making a shaded relief map using different colors to represent different altitudes. Also, in this post I will show you how to visualize the shaded relief map with a given projection and add some labels to the final map.\nlibrary(elevatr)\nlibrary(sf)\nlibrary(terra)\nlibrary(rayshader)\nlibrary(magick)\nDefine some variables: name of the polygon to save the files, the name used to add a label at the end, the CRS to project the visualization of the map, and some variables to render the shaded relief and final labels. In this case, I had to use PROJ notation to define the projection to which I wanted the map to be projected to; although, nowadays this notation is discouraged in favor of WKT2 notation or EPSG or ESRI codes.\nname_poly &lt;- \"Mexico\"\nname_legend &lt;- \"Mexico\"\n# Had to use proj4, although it is not prefered over epsg codes\n# However there was no epsg:6361\nnewProj &lt;- \"+proj=lcc +lat_0=12 +lon_0=-102 +lat_1=17.5 +lat_2=29.5 +x_0=2500000 +y_0=0\"\nsunangle &lt;- 315\n# Lower value more z exaggeration\nzscale &lt;- 20\nzoom_val &lt;- 6\nsunaltitude &lt;- 30\nfont &lt;- \"sans\"\nfont_color &lt;- \"#01611F\"\nThen, read the roi polygon file and use it to obtain the DEM data.\n# Get polygon of roi\n# Can be downloaded from: https://github.com/JonathanVSV/Ppage2/tree/master/assets/data\npoly &lt;- st_read(\"MX_inegi.gpkg\")\n# Get RGB mosaic\n# Get elevation data using elevatr\ndem &lt;- get_elev_raster(poly,\n                      prj = \"EPSG:4326\",\n                      src = \"aws\",\n                      z = zoom_val,\n                      neg_to_na = FALSE)\nThen, extract the bounding box coordinates of the polygon to add them in the add as a notation in the final image. Do some adjustments such as round to two decimals and add N and W letters.\nbox_coords &lt;- st_bbox(poly)\ncoords_df &lt;- data.frame(c1 = paste0(abs(round(box_coords[2],2)), \"° N, \",\n                                    abs(round(box_coords[1],2)), \"° W\"),\n                        c2 = paste0(abs(round(box_coords[4],2)), \"° N, \",\n                                    abs(round(box_coords[3],2)), \"° W\"))\nThen, mask the images using the roi’s polygon and crop the dem to the extent of the same polygon.\n# Convert raster to spatRast\ndem &lt;- rast(dem)\n\n# Mask areas according to polygon\ndem &lt;- mask(dem, poly)\n\n# Crop dem extent to poly\ndem &lt;- crop(dem, poly)\nAfterward, transform the dem into a matrix.\n# And convert it to a matrix:\ndem_mat &lt;- raster_to_matrix(dem)\nDefine color palette for the topography colors, using hexadecimal codes.\nmy_pal &lt;- grDevices::colorRampPalette(c(\"#026449\", \"#12722c\",\"#d7d17e\",\n                    \"#95400d\", \"#980802\", \"#746c69\", \"#f1f1f1\",\"#fdfdfd\"),\n                    interpolate = \"spline\",\n                    bias = 1)(256)\nThen create the hillshade map under the topographic color representation and add shadows. I added some transparency to the height shade layer (resulting from height_shade) so it can be better combined with the hillshaded image (resulting from sphere_shade).\nim &lt;- dem_mat |&gt;\n  sphere_shade(sunangle = sunangle,\n               texture = 'bw',\n               zscale = zscale,\n               colorintensity = 0.9) |&gt;\n  add_overlay(height_shade(dem_mat, \n                           texture = my_pal),\n              alphalayer = 0.7) |&gt;\n  add_shadow(ray_shade(dem_mat,\n                       sunaltitude = sunaltitude,\n                       zscale=zscale),\n             max_darken = 0.9,\n             rescale_original = T) \nThen convert the array obtained in the previous step to spatRast again and project it.\n# Pass it to raster again and set CRS params\nim &lt;- rast(im)\ncrs(im) &lt;- crs(\"EPSG:4326\")\next(im) &lt;- ext(dem)\n\n# Reproject\n# EPSG:6361 Mexico LCC\n# https://epsg.io/6361\n\nnewProj &lt;- st_crs(newProj)$wkt\nim_rep &lt;- project(im, y = newProj)\n# Return image to 0 - 255 range\nim_rep &lt;- im_rep*255\nThen export the image into a png. In this case, you need to create a folder named “Plots” outside R in your working directory or use dir.create(\"Plots\") inside R, so you can export the file in the exact same location as in the example. Other alternative, might be to delete the folder part (i.e., “Plots/”) and just export it directly in the working directory.\n# Export to png\npng(paste0(\"Plots/\",name_poly,\"_AltCol.png\"),\n    width = 25,\n    height = 20,\n    units = \"cm\",\n    res = 300)\nplotRGB(im_rep,\n        # stretch = \"hist\",\n        smooth = T,\n        # completely opaque\n        alpha = 255,\n        add = F,\n        maxcell = Inf, \n        bgalpha = 0)\ndev.off()\nOnce you obtain the png, you can make some enhancements using the magick package to crop the image, increase the saturation of the colors, increase the contrast, among other adjustments.\n# Final enhancements\nim1 &lt;- image_read(paste0(\"Plots/\",name_poly,\"_AltCol.png\"))\n# Crop image to remove borders\nim2 &lt;- image_trim(im1)\n# Add color saturation\nim2 &lt;- image_modulate(im2, \n                      brightness = 100, \n                      saturation = 120, \n                      hue = 100)\n# Increase contrast\nim2 &lt;- image_contrast(im2, \n                      sharpen = 2)\nFinally, using the same package you can make some annotations, add some borders to the image and write the final image into another png.\n# Main title\nim2 &lt;- image_annotate(im2, \n                      paste0(name_poly),\n                      font = font,\n                      color = font_color, \n                      # bold\n                      weight = 700,\n                      size = 140, \n                      gravity = \"southwest\",\n                      location = \"+200+200\")\n# Subtitle                      \nim2 &lt;- image_annotate(im2, \n                      text = c(\"shaded relief\"), \n                      weight = 700,\n                      font = font, \n                      location = \"+190+130\",\n                      color = font_color, \n                      size = 80, \n                      gravity = \"southwest\")\n# Coordinates                      \nim2 &lt;- image_annotate(im2, \n                      text = paste0(coords_df$c1, \" - \", coords_df$c2),\n                      # Normal face \n                      weight = 400,\n                      font = font, \n                      location = \"+165+60\",\n                      color = font_color, \n                      size = 30, \n                      gravity = \"southwest\")\n# Add white border\nim2 &lt;- image_border(im2, \n                    color = \"white\",\n                    geometry = \"10x10\")\n# Add black border                    \nim2 &lt;- image_border(im2, \n                    color = \"black\",\n                    geometry = \"10x10\")\n\nimage_write(im2, \n            path = paste0(\"Plots/\",name_poly,\"_AltCol_final.png\"), \n            format = \"png\",\n            quality = 95)\nThe result:\n\n\n\nShaded relief map of Mexico\n\n\nIn the final map, the tallest peaks can be appreciated in white, such as the Pico de Orizaba (Citlaltépetl), Iztaccihuátl, Nevado de Toluca, Popocatépetl, Cofre de Perote, among others. As a final annotation I was planning to add the altitude range of the map, but the resulting range from the DEM is not very precise, so I decided not to include it (DEM highest point was 5139 m, while highest point should be around 5600 m)."
  },
  {
    "objectID": "posts/2023-01-28-3d-maps-in-r.html",
    "href": "posts/2023-01-28-3d-maps-in-r.html",
    "title": "3D maps in r",
    "section": "",
    "text": "3D maps in R\nThe purpose of this post is to show how make a 3D map using rayshader. The idea is to use a DEM obtained from the SRTM mission (worldwide cover) or an available DEM from other National Institutions, such as Mexico’s National Institute of Statistics and Geography to obtain a 3D relief of the area of interest; and an RGB composite to overlay it on the relief. The cloudless RGB mosaic I am using in this post was obtained from Landsat-8 images and was produced using Google Earth Engine. Finally, a shapefile with the locations of two urban settlements in the area is loaded to show their location.\nFirst load the libraries we are going to use.\nlibrary(rayshader)\nlibrary(raster)\nlibrary(sf)\nlibrary(dplyr)\nThen, read the images.\ndem &lt;- raster(\"dem_more.tif\")\nlocs &lt;- st_read(\"Morelia.shp\")\nrgb &lt;- stack(\"rgb.tif\")\nThen, clip the rgb image values to the lower and upper 3 % quantiles so the image can be better appreciated.\nquants &lt;- quantile(as.vector(values(rgb)), c(0.03, 0.97))\n\n# Clip values to lower and upper 3 %\nrgb[rgb &lt; quants[1]] &lt;- quants[1]\nrgb[rgb &gt; quants[2]] &lt;- quants[2]\nrgb &lt;- ((rgb - quants[1])* 1/ quants[2]) + 0\nNext, let’s transform the rgb into an array and the dem into matrix, so they can be rendered in 3D.\nrgb_array = as.array(rgb)\ndem_mat &lt;-  raster_to_matrix(dem)\nExtract the coordinates of the two human settlements used as reference (as numbers) and drop the geometry.\nlocs &lt;- locs |&gt;\n  mutate(x = st_coordinates(locs)[,1],\n         y = st_coordinates(locs)[,2]) |&gt;\n  st_drop_geometry()\nAfterward, do the 3d rendering with the rgb and dem layers and set additional parameters for the visualization. Subsequently, add the labels of the two localities.\nrgb_array |&gt;\nplot_3d(dem_mat, \n        zscale = 12, \n        fov = 0, \n        theta = 20, \n        zoom = 0.65, \n        # azimut\n        phi = 45, \n        windowsize = c(1000, 800)) \n  render_label(dem_mat,\n               long = locs$x[1],\n               lat = locs$y[1],\n               # altitude = 120000,\n               zscale = 19,\n               extent = raster::extent(dem),\n               text = locs$Nombre[1],\n               linecolor = \"white\",\n               textcolor = \"white\")\n  render_label(dem_mat,\n               long = locs$x[2],\n               lat = locs$y[2],\n               # altitude = 120000,\n               zscale = 14,\n               extent = raster::extent(dem),\n               text = locs$Nombre[2],\n               linecolor = \"white\",\n               textcolor = \"white\")\nFinally, save a snapshot of the 3d model.\nrender_snapshot(filename = \"Morelia3D.png\",\n                gravity = \"North\")\nThe result:\n\n\n\n3D map of Patzcuaro and Morelia surroundings in Michoacán, Mexico.\n\n\nIf you are familiar with the surrounding of Morelia, Michoacán, Mexico, you will immediatly recognize Patzcuaro and Cuitzeo lakes, as well as some hills, such as the Quinceo."
  },
  {
    "objectID": "posts/2023-01-14-landscape-metrics-in-r.html",
    "href": "posts/2023-01-14-landscape-metrics-in-r.html",
    "title": "Landscape metrics in R",
    "section": "",
    "text": "Landscape metrics are frequently used in landscape ecology to asses the spatial structure of a landscape. Thus, these metrics usually summarise fragmentation and connectivity patterns. The usual inputs to calculate thees metrics is a classification which has the spatial structure of different land covers / land uses.\n\n\nFor this example, I am going to use a raster obtained from the Global Forest Watch dataset, where I defined forest as those areas with higher than 70 % tree cover in the 2000 and then used the year of loss bands to calculate the remaining forest cover for each year. Additionally, we are going to use a landscapes extent shape, which cover the regions of interest.\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(stars)\nlibrary(tmap)\nlibrary(landscapemetrics)\n\nforest &lt;- read_stars(\"Data/GFC_remainingForest_2000-2021.tif\")\nplots &lt;- st_read(\"Data/landscapes.shp\")\n\n\n\nThe first to do is crop the image to the extent of the rois\n# Crop to roi\nforest &lt;- st_crop(forest, st_bbox(plots))\n\n# Check everything is ok \nplot(forest)\nThen you can clip the image to the rois, so the landscape metrics are calculateed for each roi. In this step, you need to convert the image object from starts proxy oboject to stars, thus, that’s the reason to do the st_as_stars. Here we are analyzing only the roi’s; however, you could also use a moving window approach to calculate the metrics for each pixel neighborhood.\nlist_3y_plots &lt;- lapply(1:dim(forest)[3], function(i){\n  # Select i band\n  x &lt;- st_as_stars(forest[,,,i])\n  # Reclassify raster into 1 and NA\n  # x[x&lt;1] &lt;- NA\n  lapply(1:nrow(plots), function(j){\n    x[plots |&gt;\n        slice(j)]\n  })\n})\nThen, you can define the metrics of interest to calculate for each landscape. You can consult the complete list of metrics in: https://r-spatialecology.github.io/landscapemetrics/reference/index.html\n# Define type of metrics that we want\nmetrics &lt;- list_lsm(level = \"class\", \n                    type = c(\"aggregation metric\"), #, \"area and edge metric\"), \n                    simplify = TRUE)\nThen, calculate each metric for each lanscape\n# Calculate metrics\nmetris_3y &lt;- lapply(list_3y_plots, function(x){\n  lapply(x, function(y){\n    calculate_lsm(y, \n                  what = metrics,\n                  full_name = TRUE)\n  })\n})\n\nnames(metris_3y) &lt;- 1:dim(forest)[3]\nMake some wrangling to get the data outside the nested lists and bind them into a single dataframe.\n# Rename nested lists\nfor(i in 1:length(metris_3y)){\n  names(metris_3y[[i]]) &lt;- plots$Paisaje\n}\n\nmetris_3y_bis &lt;- lapply(metris_3y, function(x){\n  bind_rows(x, .id = \"plot\")\n})\n\nmetris_3y_bis &lt;- bind_rows(metris_3y_bis, .id = \"year\")\nFilter to stay only with the class of interest and write the results to a csv.\n# Filter only to stay with class 1 metrics (i.e., forest)\nmetris_3y_bis |&gt;\n  filter(class == 1) |&gt;\n  write.csv(\"Results/forest_class_aggr_metrics_3y_byplot.csv\")"
  },
  {
    "objectID": "posts/2023-01-14-landscape-metrics-in-r.html#data",
    "href": "posts/2023-01-14-landscape-metrics-in-r.html#data",
    "title": "Landscape metrics in R",
    "section": "",
    "text": "For this example, I am going to use a raster obtained from the Global Forest Watch dataset, where I defined forest as those areas with higher than 70 % tree cover in the 2000 and then used the year of loss bands to calculate the remaining forest cover for each year. Additionally, we are going to use a landscapes extent shape, which cover the regions of interest.\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(stars)\nlibrary(tmap)\nlibrary(landscapemetrics)\n\nforest &lt;- read_stars(\"Data/GFC_remainingForest_2000-2021.tif\")\nplots &lt;- st_read(\"Data/landscapes.shp\")"
  },
  {
    "objectID": "posts/2023-01-14-landscape-metrics-in-r.html#landscape-metrics-calculation",
    "href": "posts/2023-01-14-landscape-metrics-in-r.html#landscape-metrics-calculation",
    "title": "Landscape metrics in R",
    "section": "",
    "text": "The first to do is crop the image to the extent of the rois\n# Crop to roi\nforest &lt;- st_crop(forest, st_bbox(plots))\n\n# Check everything is ok \nplot(forest)\nThen you can clip the image to the rois, so the landscape metrics are calculateed for each roi. In this step, you need to convert the image object from starts proxy oboject to stars, thus, that’s the reason to do the st_as_stars. Here we are analyzing only the roi’s; however, you could also use a moving window approach to calculate the metrics for each pixel neighborhood.\nlist_3y_plots &lt;- lapply(1:dim(forest)[3], function(i){\n  # Select i band\n  x &lt;- st_as_stars(forest[,,,i])\n  # Reclassify raster into 1 and NA\n  # x[x&lt;1] &lt;- NA\n  lapply(1:nrow(plots), function(j){\n    x[plots |&gt;\n        slice(j)]\n  })\n})\nThen, you can define the metrics of interest to calculate for each landscape. You can consult the complete list of metrics in: https://r-spatialecology.github.io/landscapemetrics/reference/index.html\n# Define type of metrics that we want\nmetrics &lt;- list_lsm(level = \"class\", \n                    type = c(\"aggregation metric\"), #, \"area and edge metric\"), \n                    simplify = TRUE)\nThen, calculate each metric for each lanscape\n# Calculate metrics\nmetris_3y &lt;- lapply(list_3y_plots, function(x){\n  lapply(x, function(y){\n    calculate_lsm(y, \n                  what = metrics,\n                  full_name = TRUE)\n  })\n})\n\nnames(metris_3y) &lt;- 1:dim(forest)[3]\nMake some wrangling to get the data outside the nested lists and bind them into a single dataframe.\n# Rename nested lists\nfor(i in 1:length(metris_3y)){\n  names(metris_3y[[i]]) &lt;- plots$Paisaje\n}\n\nmetris_3y_bis &lt;- lapply(metris_3y, function(x){\n  bind_rows(x, .id = \"plot\")\n})\n\nmetris_3y_bis &lt;- bind_rows(metris_3y_bis, .id = \"year\")\nFilter to stay only with the class of interest and write the results to a csv.\n# Filter only to stay with class 1 metrics (i.e., forest)\nmetris_3y_bis |&gt;\n  filter(class == 1) |&gt;\n  write.csv(\"Results/forest_class_aggr_metrics_3y_byplot.csv\")"
  },
  {
    "objectID": "posts/2023-01-06-3D-histograms-in-r.html",
    "href": "posts/2023-01-06-3D-histograms-in-r.html",
    "title": "3D histograms in R",
    "section": "",
    "text": "In this post I am going to show you how to construct a beautiful 3D histogram that can be a very nice way to show your frequency data. For this, I will use the ggridges package.\n\n\nThe ggridges package has functions to construct 3d histograms.\nFor this example we are going to load some data of the number of observations of Sentinel-2 1C images over different ecorregions in Mexico. Here’s an extract of that table, containing the frequency of pixels with number of valid observations (y2). The data was reduced to preserve the proportions with a smaller number of observations.\n\n\n\ndesc_id\nyear\nmonth\nlabels\ny2\n\n\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n6\n\n\nSelvas Calido Humedas\n2018\n1\n5\n0\n\n\n\nlibrary(tidyverse)\nlibrary(ggridges)\n\ndf &lt;- read.csv(\"Data/Ridges_plot2.csv\")\nThen we will calculate the mean for the groups of interest (ecoregion, month and year) and join them to the original df.\ntemp &lt;- df |&gt;\n  group_by(desc_id, month, year) |&gt;\n  summarise(mean = mean(y2)) |&gt;\n  ungroup() |&gt;\n  group_by(desc_id, year) |&gt;\n  arrange(desc(mean)) |&gt;\n  filter(year &gt;= 2018) |&gt;\n  select(desc_id, year, month)\n\ndf &lt;- df %&gt;%\n  left_join(temp, by = c(\"desc_id\", \"year\", \"month\"))\nThen we can create the 3d histogram with geom_density_ridges_gradient and save it as jpeg.\ndf |&gt;\n  filter(year &gt;= 2018) |&gt;\n  ggplot(aes(x = y2, \n             y = factor(month, levels = seq(1,12,1)),\n             fill = after_stat(x))) +\n  geom_density_ridges_gradient(scale = 2.10,\n                               rel_min_height = 0.01,\n                               alpha = 0.5,\n                               gradient_lwd = 1,\n                               panel_scaling = F,\n                               show.legend = F,\n                               bandwidth = 1) +\n                               #quantile_lines=TRUE,\n                               #quantile_fun=function(x,...)mean(x)) +\n  scale_fill_viridis_c(name = \"Número \\nobservaciones\",\n                      #type = \"seq\",\n                      #palette = \"RdGn\",\n                      direction = -1,\n                      alpha = 0.6,\n                      option = \"viridis\") +\n  scale_alpha(range = c(0.2,0.3)) +\n  scale_x_continuous(limits = c(0,15.5),\n                     breaks = seq(0,15,3),\n                     expand = c(0,0.5)) +\n  facet_grid(desc_id~year) +\n  labs(x = \"Número de observaciones\",\n       y = \"Mes\") +\n  theme_bw() +\n  theme(strip.background = element_rect(fill = \"gray90\"),\n        strip.text.y = element_text(angle=0),\n        axis.text.x = element_text(angle = 90,\n                                   vjust = 0.5),\n        text = element_text(size = 12),\n        axis.text.y = element_text(size = 8)) \n\nggsave(\"Plots/Histogramas_mensuales_ggridges.jpeg\",\n       width = 16,\n       height = 28,\n       units = \"cm\",\n       dpi = 350)\n]"
  },
  {
    "objectID": "posts/2023-01-06-3D-histograms-in-r.html#ggridges",
    "href": "posts/2023-01-06-3D-histograms-in-r.html#ggridges",
    "title": "3D histograms in R",
    "section": "",
    "text": "The ggridges package has functions to construct 3d histograms.\nFor this example we are going to load some data of the number of observations of Sentinel-2 1C images over different ecorregions in Mexico. Here’s an extract of that table, containing the frequency of pixels with number of valid observations (y2). The data was reduced to preserve the proportions with a smaller number of observations.\n\n\n\ndesc_id\nyear\nmonth\nlabels\ny2\n\n\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n2\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n3\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n1\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n4\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n5\n\n\nSelvas Calido Humedas\n2018\n1\n5\n6\n\n\nSelvas Calido Humedas\n2018\n1\n5\n0\n\n\n\nlibrary(tidyverse)\nlibrary(ggridges)\n\ndf &lt;- read.csv(\"Data/Ridges_plot2.csv\")\nThen we will calculate the mean for the groups of interest (ecoregion, month and year) and join them to the original df.\ntemp &lt;- df |&gt;\n  group_by(desc_id, month, year) |&gt;\n  summarise(mean = mean(y2)) |&gt;\n  ungroup() |&gt;\n  group_by(desc_id, year) |&gt;\n  arrange(desc(mean)) |&gt;\n  filter(year &gt;= 2018) |&gt;\n  select(desc_id, year, month)\n\ndf &lt;- df %&gt;%\n  left_join(temp, by = c(\"desc_id\", \"year\", \"month\"))\nThen we can create the 3d histogram with geom_density_ridges_gradient and save it as jpeg.\ndf |&gt;\n  filter(year &gt;= 2018) |&gt;\n  ggplot(aes(x = y2, \n             y = factor(month, levels = seq(1,12,1)),\n             fill = after_stat(x))) +\n  geom_density_ridges_gradient(scale = 2.10,\n                               rel_min_height = 0.01,\n                               alpha = 0.5,\n                               gradient_lwd = 1,\n                               panel_scaling = F,\n                               show.legend = F,\n                               bandwidth = 1) +\n                               #quantile_lines=TRUE,\n                               #quantile_fun=function(x,...)mean(x)) +\n  scale_fill_viridis_c(name = \"Número \\nobservaciones\",\n                      #type = \"seq\",\n                      #palette = \"RdGn\",\n                      direction = -1,\n                      alpha = 0.6,\n                      option = \"viridis\") +\n  scale_alpha(range = c(0.2,0.3)) +\n  scale_x_continuous(limits = c(0,15.5),\n                     breaks = seq(0,15,3),\n                     expand = c(0,0.5)) +\n  facet_grid(desc_id~year) +\n  labs(x = \"Número de observaciones\",\n       y = \"Mes\") +\n  theme_bw() +\n  theme(strip.background = element_rect(fill = \"gray90\"),\n        strip.text.y = element_text(angle=0),\n        axis.text.x = element_text(angle = 90,\n                                   vjust = 0.5),\n        text = element_text(size = 12),\n        axis.text.y = element_text(size = 8)) \n\nggsave(\"Plots/Histogramas_mensuales_ggridges.jpeg\",\n       width = 16,\n       height = 28,\n       units = \"cm\",\n       dpi = 350)\n]"
  },
  {
    "objectID": "posts/2022-10-14-soundscape-analysis.html",
    "href": "posts/2022-10-14-soundscape-analysis.html",
    "title": "Soundscape analysis in R",
    "section": "",
    "text": "Soundscape can be defined as the collection of sounds that are recorded from a particular landscape. Soundscapes typically can have three main components: biophony, geophony and anthropohony. Depending on the type of landscape and weather conditions certain components can be the predominant ones.\nThere are two approaches for studying soundscapes: 1) focusing on the complete soundscape without getting to know the identity of each species, 2) identifying each species in its sound signal. For this example, the first approach was chosen to analyse the data.\nIn this approach there are several indices you can calculate from the spectrogram. Each one focusing on different aspects of the heterogeneity of the spectral signals. Here is a brief list of the possible indices that can be calculated in R.\n\nAcoustic complexity index.\nAcoustic entropy index.\nAcoustic richness index.\nNumber of frequency peaks.\nAmplitude index.\nNormalized difference soundscape index.\nSpectral entropy.\nTemporal entropy.\nAcoustic diversity index.\nAcoustic eveness.\n\n\n\n\nSpectrograms are visual representations of recordings that can help identify the frequency at which sounds ocurr, as well as temporal patterns. For example, this is a spectrogram showing the sounds of a recording in a tropical rainforest. Please notice that the x-axis represents time in the recording, the y-axis, the dominant frequency in each sound and the color represents the instensity (or magnitude) of the sound in dB.\n]\nThe code to construct the previous spectrogram is the following\naudio &lt;- readWave(file,\n                  from = 5,\n                  to = 200,\n                  units = \"seconds\")\n\nspectro(audio,\n        f = 24000,\n        wl = 512,\n        flim = c(0,11.9),\n        palette = viridis::viridis_pal(direction = -1,\n                                       option = \"magma\"),\n        collevels = seq(-35,0,5))\n\n\n\nFor this example, the acoustic diversity index will be calculated. Although the soundscape package contains a function that enables computing certain indices in parallel, a new function to do exactly that with any of the previous indices will be made.\nFirst, we need to load the required packages and define some variables\nlibrary(tuneR)\nlibrary(seewave)\nlibrary(audio)\nlibrary(phonTools)\nlibrary(tibble)\nlibrary(soundecology)\n# library(kableExtra)\nlibrary(dplyr)\n# library(pbapply)\nlibrary(ggplot2)\nlibrary(stringr)\n# library(foreach)\n# library(doParallel)\nlibrary(progress)\nlibrary(doSNOW)\n\n# Variables\n\n# Second to start analysis from recordings\nstart &lt;- 5\n# Second to end analysis from recordings \nend &lt;- 290\n# Threshold in decibels to ignore noise or background noise from sounds\nthreshdB &lt;- -35\n# Max frequency to be analysed\nmax_freq &lt;- 12000\n# Width of frequency bins used to make the spectrogram\nfreq_step &lt;- 1000\n\n# Lower freq for high pass filter\nlowfreq &lt;- 200\n# Number of cores to make parallel processing\nnumCores &lt;- 5 #parallel::detectCores(logical = F)-1\nNext, we should locate the files that are going to be analysed.\n#--------------------Read files-------------------------------------\nsite &lt;- \"MySite\"\naudios &lt;- list.files(paste0(\"E:/Data/Audios/\", site),\n                     \"*.wav\",\n                     full.names = T,\n                     include.dirs = T,\n                     recursive = T)\nThen, we need to define the functions we are going to use. In this case, a filter function will be used to filter the sounds.\n# -------------------------Define functions---------------------------\nfilter_fun &lt;- function(audio,\n                       filtering = \"none\",\n                       # frequency = 8000,\n                       lower = 200,\n                       higher = 9000){\n\n  frequency &lt;- audio@samp.rate\n\n  # Filter low-pass\n  if(filtering == \"none\"){\n    audio2 &lt;- audio\n  }\n  if(filtering == \"low\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      to = higher,\n                      rescale = F)\n  }\n  if(filtering == \"high\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      rescale = F)\n  }\n  if(filtering == \"band-pass\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      to = higher,\n                      rescale = F)\n  }\n  if(filtering == \"band-stop\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      to = higher,\n                      rescale = F,\n                      bandpass = FALSE)\n  }\n  if(filtering != \"none\"){\n    audio &lt;- Wave(audio2,\n                  samp.rate = audio@samp.rate,\n                  bit = audio@bit)\n  }\n  audio\n}\nThen a function is going to be made to calculate the alpha diversity indices of interest. In this case, only the acoustic diversity will be calculated.\nalpha_ind &lt;- function(audio){\n\n  # Spectral entropy, calculated from the spectrogram, scaled between 0 and 1, also known as Pielou's eveness index,\n  # SE = sh(spec(audio,\n  #              f = 24000,\n  #              wl = 512,\n  #              flim = c(0,12)))\n  # dividing the spectrogram into bins (default 10, each one of 1000 Hz) and taking the proportion of the signals in each bin above a threshold (default -50 dBFS). The ADI is the result of the Shannon index applied to these bins.\n  AD = acoustic_diversity(audio,\n                          max_freq = max_freq,\n                          db_threshold = threshdB,\n                          freq_step = freq_step)$adi_left\n\n  tibble(AD)\n}\nAnd finally, the function that will include the previous two functions: filtering and calculating the alpha diversity indices.\ncalc_f &lt;- function(x){\n  audio1 &lt;- readWave(x,\n                     from = start,\n                     to = end,\n                     units = \"seconds\")\n  audio_f1 &lt;- filter_fun(audio1,\n                         filtering = \"high\",\n                         lower = lowfreq)#,\n  #higher = 9000)\n  resul1 &lt;- alpha_ind(audio1)\n  resul1 |&gt;\n    mutate(file = x) |&gt;\n    select(file, AD) |&gt;\n    as.data.frame()\n}\nThen we can make the process in parallel and export a csv with the calculated indices, one for each file.\n# ------------------------Start parallel process--------------------------------\n\n# registerDoParallel(numCores)\n\ncl &lt;- makeCluster(numCores)\nregisterDoSNOW(cl)\n\n# Progress bar\npb &lt;- txtProgressBar(max = length(audios), style = 3)\nprogress &lt;- function(n) setTxtProgressBar(pb, n)\nopts &lt;- list(progress = progress)\n\ndf &lt;- foreach(x = audios,\n              .combine = rbind,\n              .packages = c(\"seewave\",\n                            \"dplyr\",\n                            \"tuneR\",\n                            \"soundecology\"),\n              .options.snow = opts) %dopar% {\n\n  try(calc_f(x))\n\n}\n\nstopCluster(cl)\nclose(pb)\n\nwrite.csv(df,\n          paste0(\"Results/All\",site,\"_thresh\",threshdB,\"maxFreq\",max_freq,\".csv\"))"
  },
  {
    "objectID": "posts/2022-10-14-soundscape-analysis.html#introduction",
    "href": "posts/2022-10-14-soundscape-analysis.html#introduction",
    "title": "Soundscape analysis in R",
    "section": "",
    "text": "Soundscape can be defined as the collection of sounds that are recorded from a particular landscape. Soundscapes typically can have three main components: biophony, geophony and anthropohony. Depending on the type of landscape and weather conditions certain components can be the predominant ones.\nThere are two approaches for studying soundscapes: 1) focusing on the complete soundscape without getting to know the identity of each species, 2) identifying each species in its sound signal. For this example, the first approach was chosen to analyse the data.\nIn this approach there are several indices you can calculate from the spectrogram. Each one focusing on different aspects of the heterogeneity of the spectral signals. Here is a brief list of the possible indices that can be calculated in R.\n\nAcoustic complexity index.\nAcoustic entropy index.\nAcoustic richness index.\nNumber of frequency peaks.\nAmplitude index.\nNormalized difference soundscape index.\nSpectral entropy.\nTemporal entropy.\nAcoustic diversity index.\nAcoustic eveness."
  },
  {
    "objectID": "posts/2022-10-14-soundscape-analysis.html#spectrograms",
    "href": "posts/2022-10-14-soundscape-analysis.html#spectrograms",
    "title": "Soundscape analysis in R",
    "section": "",
    "text": "Spectrograms are visual representations of recordings that can help identify the frequency at which sounds ocurr, as well as temporal patterns. For example, this is a spectrogram showing the sounds of a recording in a tropical rainforest. Please notice that the x-axis represents time in the recording, the y-axis, the dominant frequency in each sound and the color represents the instensity (or magnitude) of the sound in dB.\n]\nThe code to construct the previous spectrogram is the following\naudio &lt;- readWave(file,\n                  from = 5,\n                  to = 200,\n                  units = \"seconds\")\n\nspectro(audio,\n        f = 24000,\n        wl = 512,\n        flim = c(0,11.9),\n        palette = viridis::viridis_pal(direction = -1,\n                                       option = \"magma\"),\n        collevels = seq(-35,0,5))"
  },
  {
    "objectID": "posts/2022-10-14-soundscape-analysis.html#code-to-perform-analysis",
    "href": "posts/2022-10-14-soundscape-analysis.html#code-to-perform-analysis",
    "title": "Soundscape analysis in R",
    "section": "",
    "text": "For this example, the acoustic diversity index will be calculated. Although the soundscape package contains a function that enables computing certain indices in parallel, a new function to do exactly that with any of the previous indices will be made.\nFirst, we need to load the required packages and define some variables\nlibrary(tuneR)\nlibrary(seewave)\nlibrary(audio)\nlibrary(phonTools)\nlibrary(tibble)\nlibrary(soundecology)\n# library(kableExtra)\nlibrary(dplyr)\n# library(pbapply)\nlibrary(ggplot2)\nlibrary(stringr)\n# library(foreach)\n# library(doParallel)\nlibrary(progress)\nlibrary(doSNOW)\n\n# Variables\n\n# Second to start analysis from recordings\nstart &lt;- 5\n# Second to end analysis from recordings \nend &lt;- 290\n# Threshold in decibels to ignore noise or background noise from sounds\nthreshdB &lt;- -35\n# Max frequency to be analysed\nmax_freq &lt;- 12000\n# Width of frequency bins used to make the spectrogram\nfreq_step &lt;- 1000\n\n# Lower freq for high pass filter\nlowfreq &lt;- 200\n# Number of cores to make parallel processing\nnumCores &lt;- 5 #parallel::detectCores(logical = F)-1\nNext, we should locate the files that are going to be analysed.\n#--------------------Read files-------------------------------------\nsite &lt;- \"MySite\"\naudios &lt;- list.files(paste0(\"E:/Data/Audios/\", site),\n                     \"*.wav\",\n                     full.names = T,\n                     include.dirs = T,\n                     recursive = T)\nThen, we need to define the functions we are going to use. In this case, a filter function will be used to filter the sounds.\n# -------------------------Define functions---------------------------\nfilter_fun &lt;- function(audio,\n                       filtering = \"none\",\n                       # frequency = 8000,\n                       lower = 200,\n                       higher = 9000){\n\n  frequency &lt;- audio@samp.rate\n\n  # Filter low-pass\n  if(filtering == \"none\"){\n    audio2 &lt;- audio\n  }\n  if(filtering == \"low\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      to = higher,\n                      rescale = F)\n  }\n  if(filtering == \"high\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      rescale = F)\n  }\n  if(filtering == \"band-pass\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      to = higher,\n                      rescale = F)\n  }\n  if(filtering == \"band-stop\"){\n    audio2 &lt;- ffilter(audio,\n                      f = frequency,\n                      from = lower,\n                      to = higher,\n                      rescale = F,\n                      bandpass = FALSE)\n  }\n  if(filtering != \"none\"){\n    audio &lt;- Wave(audio2,\n                  samp.rate = audio@samp.rate,\n                  bit = audio@bit)\n  }\n  audio\n}\nThen a function is going to be made to calculate the alpha diversity indices of interest. In this case, only the acoustic diversity will be calculated.\nalpha_ind &lt;- function(audio){\n\n  # Spectral entropy, calculated from the spectrogram, scaled between 0 and 1, also known as Pielou's eveness index,\n  # SE = sh(spec(audio,\n  #              f = 24000,\n  #              wl = 512,\n  #              flim = c(0,12)))\n  # dividing the spectrogram into bins (default 10, each one of 1000 Hz) and taking the proportion of the signals in each bin above a threshold (default -50 dBFS). The ADI is the result of the Shannon index applied to these bins.\n  AD = acoustic_diversity(audio,\n                          max_freq = max_freq,\n                          db_threshold = threshdB,\n                          freq_step = freq_step)$adi_left\n\n  tibble(AD)\n}\nAnd finally, the function that will include the previous two functions: filtering and calculating the alpha diversity indices.\ncalc_f &lt;- function(x){\n  audio1 &lt;- readWave(x,\n                     from = start,\n                     to = end,\n                     units = \"seconds\")\n  audio_f1 &lt;- filter_fun(audio1,\n                         filtering = \"high\",\n                         lower = lowfreq)#,\n  #higher = 9000)\n  resul1 &lt;- alpha_ind(audio1)\n  resul1 |&gt;\n    mutate(file = x) |&gt;\n    select(file, AD) |&gt;\n    as.data.frame()\n}\nThen we can make the process in parallel and export a csv with the calculated indices, one for each file.\n# ------------------------Start parallel process--------------------------------\n\n# registerDoParallel(numCores)\n\ncl &lt;- makeCluster(numCores)\nregisterDoSNOW(cl)\n\n# Progress bar\npb &lt;- txtProgressBar(max = length(audios), style = 3)\nprogress &lt;- function(n) setTxtProgressBar(pb, n)\nopts &lt;- list(progress = progress)\n\ndf &lt;- foreach(x = audios,\n              .combine = rbind,\n              .packages = c(\"seewave\",\n                            \"dplyr\",\n                            \"tuneR\",\n                            \"soundecology\"),\n              .options.snow = opts) %dopar% {\n\n  try(calc_f(x))\n\n}\n\nstopCluster(cl)\nclose(pb)\n\nwrite.csv(df,\n          paste0(\"Results/All\",site,\"_thresh\",threshdB,\"maxFreq\",max_freq,\".csv\"))"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html",
    "href": "posts/2022-02-17-rasters-con-stars.html",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Existen varios paquetes en R que permiten manejar datos espaciales, ya sea en formato de vector o raster. Algunos de ellos incluyen: sp, rgdal, rgeos, sf, stars, raster, terra. Sin embargo, en este curso nos enfocaremos en utilizar sf para el manejo de información vectorial y stars para el manejo de rasters.\n\n\n\n\nstars es un paquete creado para trabajar de manera sencilla con información raster y fue creado por el mismo grupo de trabajo que creo sf, así que muchas funciones y sintaxis son compartidas con dicho paquete.\n\n\n\n\nEl objeto básico en stars son los spatiotemporal arrays (stars), es decir arreglos espacio temporales. Recordemos que un arreglo corresponde a cualquier objeto organizado en dimensiones. Por ejemplo, una arreglo de dos dimensiones podría corresponder a una matriz que cuenta con una dimensión vertical (filas) y horizontal (columnas). De igual manera, un arreglo de tres dimensiones podría corresponder a una imagen raster con dos dimensiones espaciales (vertical y horizontal) y una dimensión espectral (bandas). Adicionalmente, un arreglo con cuatro dimensiones podría incluir una dimensión temporal.\n\n\nAl igual que en sf cada raster va a estar asociado a un sistema de coordenadas de referencia (CRS). Por lo cual, dicho CRS indicará la proyección de los datos y el datum.\n\n\n\n\n\nLos datos stars van a estar organizados en un formato de array, es decir, de una tabla o cuadro de datos de n dimensiones. Para ver un ejemplos carguemos un archivo raster.\n\nlibrary(stars)\n## Loading required package: abind\n## Loading required package: sf\n## Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\ntif = system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nx = read_stars(tif)\nx\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##              Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## L7_ETMs.tif     1      54     69 68.91242      86  255\n## dimension(s):\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL\n\nAnalicemos qué dice esta información. Primero nos dice que se trata de un objeto stars de tres dimensiones y un atributo. Además, nos da algunas estadísticas de la información que contiene. A continuación, podemos ver las tres dimensiones: x, y y band, es decir, dos dimensiones espaciales y una espectral. Adicionalmente, se puede consultar el número de celdas en cada dimensión (from y to), la coordenada inicial en cada dimensión (offset), el tamaño de la celda en cada dimensión (delta), el sistema de referencia en el que se encuentra la información (refsys), si corresponde a puntos (point) y los valores de secuencia en caso de que la dimensión no sea regular (e.g., geometrías).\n\n\nLa misma información se puede consultar de manera más sintética.\n\nst_dimensions(x)\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL\n\n\n\n\nPara leer y escribir datos desde archivos externos se utilizan las funciones read_stars y write_stars. Por ejemplo, carguemos un archivo que viene en el paquete stars:\n\nfilename &lt;- system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nx &lt;- read_stars(filename)\nx\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##              Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## L7_ETMs.tif     1      54     69 68.91242      86  255\n## dimension(s):\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL\n\nPara escribir un vector al disco:\n\nwrite_stars(x, \n         \"x_exp.tif\")\n\nLas funciones st_read y st_write contienen más argumentos para definir ## Visualización de datos\n\n\nPor último, el visualizar los datos nos puede dar una muy buena idea de los productos intermedios en un flujo de trabajo o verificar que la información que importamos o exportamos es la correcta. Para ver el objecto stars con todos sus atributos:\n\nplot(x)\n\n\n\n\nTambién se puede hacer un RGB en color natural o falso color.\n\nplot(x, \n     rgb = c(3,2,1))\n\n\n\nplot(x, \n     rgb = c(4,3,2))\n\n\n\n\n\n\n\nPrimero vamos a cargar información desde mi github.\n\n## [1] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\Sentinel2-2A_10B_2020-01-01_2020-12-30.tif\"\n## [2] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\SRTM_area.tif\"                             \n## [3] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\roi.zip\"\n\nVeamos qué descargamos.\n\nim1 &lt;- read_stars(paste0(getwd(), \"/Data/\", \"Sentinel2-2A_10B_2020-01-01_2020-12-30.tif\"))\n\nim1\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...     6     913   1552 1501.178 2010.75 5041\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12\nplot(im1)\n\n\n\n\n\n\n\n\n\n\nPara elegir parte de los rasters, se puede hacerlo eligiendo parte del arreglo. Esto se puede hacer utilizando la notación tradicional de objetos stars o usando la forma tidyverse-esque.\n\n\nEn la primera forma se utiliza la notación de arreglos [], en la que la primera dimensión corresponde a la dimensión de atributos, la segunda a la primera dimensión espacial (horizontal, x), la tercera a la segunda dimensión temporal (vertical, y) y la cuarta corresponde a la dimensión espectral (bandas).\n\nim1[,1:10,1:20]\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...    73  691.25   1149 1315.034 1693.25 5041\n## dimension(s):\n##      from to   offset        delta refsys point     values x/y\n## x       1 10 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1 20  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1 10       NA           NA     NA    NA B2,...,B12\nim1_sub1 &lt;- im1[,1:10,1:20, 2]\nim1_sub1\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median   Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...   189  485.75  556.5 555.88     635  889\n## dimension(s):\n##      from to   offset        delta refsys point values x/y\n## x       1 10 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y       1 20  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]\n## band    2  2       NA           NA     NA    NA     B3\nlibrary(tidyverse)\n## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n## v ggplot2 3.3.5     v purrr   0.3.4\n## v tibble  3.1.6     v dplyr   1.0.7\n## v tidyr   1.1.4     v stringr 1.4.0\n## v readr   2.1.1     v forcats 0.5.1\n## -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n## x dplyr::filter()     masks stats::filter()\n## x dplyr::lag()        masks stats::lag()\n## x readr::parse_date() masks curl::parse_date()\nim1_sub2 &lt;- im1 |&gt;\n  slice(x, 1:10) |&gt;\n  slice(y, 1:20) |&gt;\n  slice(band, 2) \nim1_sub2\n## stars object with 2 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median   Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...   189  485.75  556.5 555.88     635  889\n## dimension(s):\n##   from to   offset        delta refsys point values x/y\n## x    1 10 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y    1 20  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]\n\n\n\n\nAdemás podríamos estar interesados en filtrar valores de los rasters en función de los valores de cierta banda. Para ello, podemos hacer la función filter.\n\nlibrary(cubelyr)\nim1_sub3 &lt;- im1 |&gt;\n  filter(x &lt; -101.2332, x &gt; -101.235,\n         y &gt; 19.6564, y &lt; 19.6582,\n         band &gt; 3 )\nplot(im1_sub3)\n\n\n\n\n\n\n\nPara seleccionar parte de un raster basado en un vector se puede utilizar la notación tradicional de corchetes [] o la función st_crop.\n\nroi &lt;- st_read(paste0(getwd(), \"/Data/\", \"roi.shp\"))\n## Reading layer `roi' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\roi.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.2307 ymin: 19.64597 xmax: -101.2206 ymax: 19.65094\n## Geodetic CRS:  WGS 84\nplot(roi)\n\n\n\nim1_crop &lt;- im1[roi]\nplot(im1_crop)\n\n\n\nim1_crop2 &lt;- st_crop(im1, \n                     roi)\nplot(im1_crop2)\n\n\n\n\nPara extraer los valores del objeto stars y convertirlos a arreglos se puede usar la función pull. Usando esta función se extrae el atributo indicado dentro de pull.\n\nim_pull &lt;- im1 |&gt;\n  pull(1)\n# Mostrar únicamente el encabezado y algunos datos de muestra\nhead(im_pull)\n## , , 1\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  434  482  414  401  414  415  386  333  200   205   227   264   259   317\n## [2,]  434  482  441  398  401  411  440  513  533   478   372   398   397   411\n## [3,]  443  487  400  354  339  337  371  399  479   494   462   490   444   367\n## [4,]  488  441  326  309  325  333  359  324  390   511   501   489   463   393\n## [5,]  560  409  309  320  314  244  114   84  104   303   466   538   402   367\n## [6,]  594  418  321  306  255   73  134  225  296   300   208   453   471   275\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   155   316   402   424   426   434   422   403   369   367   189   456\n## [2,]   244   224   357   419   382   398   420   392   350   346   270   408\n## [3,]   192   171   257   422   478   415   394   347   336   268   459   251\n## [4,]   149   153   160   343   456   465   397   320   219   193   247   109\n## [5,]   130   133   136   292   416   447   435   372   171   211   155   125\n## [6,]   115   107   100   207   348   460   444   373   169   559   194   225\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   350   625   290   457   886   977   748   984   730   728   587   415\n## [2,]   268  1015   814  1119   807   531   406   378   347   405   436   324\n## [3,]   317   317   561   603   642   625   819   470   448   579   712   886\n## [4,]   259   278   664   718   374   946   814   365   285   474   713   661\n## [5,]   199   328   831  1035   447   995   588   414   330   734  1551   998\n## [6,]   308   485  1242   799   493   636   294   890  1186  1449   902   803\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   527   548   722   632   975   955  1417   828   645  1251   639   815\n## [2,]   631  1060  1049   717  1335   667   679   596   724   508   521   738\n## [3,]   431   304   688   513   662   932   549   375   632   611   535   555\n## [4,]   506   383   581   582   633  1319   342   611   626   748  1037   477\n## [5,]   298   279   393   629   716  1144   907   898   860   786   923   870\n## [6,]   590  1003  1012   796  1155  1320   750  1144  1341   450   595  1233\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]   612   304   149   105   198   254   783   756   711   627   495   680\n## [2,]   965   639   185   110   174   234   817   699   891   907   597   560\n## [3,]   535   444   477   204   130   275   484   974   749   890   679   692\n## [4,]   690   424  1140   392   102   174   210   596   733   927   937   770\n## [5,]  1019   825   662   505   321    89   100   477   405  1350  1211   770\n## [6,]   618   818   827   673   420   160   100   477   405  1350  1211  1016\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   271   334   467  1429   396   781  1410   847   718   570   775   564\n## [2,]   507   636   564   637  1280  1241   937   985  1004   783   690  1146\n## [3,]   909   832   610   965  1300  1042   818   985  1004   783   690  1146\n## [4,]  1098  1088  1220   965  1300  1042   818   928  1225   809   882  1280\n## [5,]  1098  1088  1220  1130   713   881  1396   647   468   549  1516  1060\n## [6,]  1078   756   856   620   444   460  1285   798   792   784   771   613\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1169  1099  1250  1012  1258  1114   776\n## [2,]  1169  1099  1250  1012  1119  1352  1038\n## [3,]   936  1132   821   704   883   937  1143\n## [4,]   885   766   896  1327  1115  1047   582\n## [5,]   707  1021  1393  1542   964  1324   844\n## [6,]   558   809  1572  1467  1384   922   872\n## \n## , , 2\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  662  695  612  616  600  651  617  623  441   440   454   485   501   591\n## [2,]  662  695  640  587  599  611  634  754  866   779   655   636   656   708\n## [3,]  685  707  603  507  489  507  552  614  666   721   665   697   668   692\n## [4,]  729  661  505  458  463  493  540  488  574   719   689   680   708   722\n## [5,]  803  619  470  475  471  369  206  202  250   477   682   742   636   749\n## [6,]  889  619  469  473  404  189  291  449  508   509   442   670   774   666\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   354   616   622   618   598   606   601   575   524   509   388   728\n## [2,]   576   532   631   622   542   570   591   545   511   529   520   686\n## [3,]   509   497   567   638   657   579   556   519   531   465   695   471\n## [4,]   482   475   435   590   675   656   583   505   381   389   441   279\n## [5,]   494   489   495   580   625   635   617   539   347   448   299   368\n## [6,]   491   478   451   561   631   633   641   540   371   804   439   458\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   546   765   525   739  1014  1196  1030  1196   997   994   832   638\n## [2,]   451  1211  1060  1333   966   722   666   633   580   655   739   563\n## [3,]   548   527   811   892   931   873  1113   699   738   845   957  1136\n## [4,]   475   556   897  1014   573  1112  1086   651   518   678   919   902\n## [5,]   460   586  1025  1267   611  1300   825   651   537  1022  1935  1227\n## [6,]   646   769  1521  1064   811   927   591  1132  1436  1634  1180  1050\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   681   855   957   846  1254  1153  1607  1181  1036  1885   869  1012\n## [2,]   872  1281  1247   841  1392   965  1011   895  1094   819   830  1100\n## [3,]   608   456   929   759   964  1185   758   657   850   854   856   903\n## [4,]   785   649   765   836   752  1514   586   819   825   943  1472   665\n## [5,]   545   540   611   863   900  1365  1111  1150  1021  1189  1111  1070\n## [6,]   783  1256  1188   923  1295  1526  1052  1385  1653   757   971  1402\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]   959   538   309   253   432   465   975  1008   885   806   816   906\n## [2,]  1212  1011   456   320   361   477  1037   898  1030  1163   869   737\n## [3,]   914   779   779   418   308   526   662  1172  1008  1130   937   864\n## [4,]   830   760  1406   588   325   439   449   874   956  1112  1034  1040\n## [5,]  1331  1105   985   770   577   320   275   693   605  1551  1448  1040\n## [6,]   937  1052  1121  1041   665   396   275   693   605  1551  1448  1204\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   451   540   728  1702   667  1057  1646  1067   985   826  1027   897\n## [2,]   697   734   791   996  1432  1421  1058  1169  1172   960   949  1411\n## [3,]  1119  1122   809  1194  1556  1278  1054  1169  1172   960   949  1411\n## [4,]  1283  1263  1537  1194  1556  1278  1054  1108  1492  1007  1002  1552\n## [5,]  1283  1263  1537  1283   904  1088  1728   850   613   731  1772  1327\n## [6,]  1251  1082  1037   850   673   695  1369   959   967   915   881   744\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1321  1295  1544  1302  1529  1336   996\n## [2,]  1321  1295  1544  1302  1327  1576  1240\n## [3,]  1129  1317  1073   879  1000  1232  1397\n## [4,]  1023  1010  1173  1584  1252  1209   798\n## [5,]   914  1130  1583  1844  1136  1448  1140\n## [6,]   821   942  1729  1615  1701  1130  1033\n## \n## , , 3\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  939  986  839  840  824  881  815  791  414   445   507   580   556   644\n## [2,]  939  986  886  780  817  857  892 1007 1127   969   784   759   824   799\n## [3,]  960  978  815  696  674  693  765  842  941   993   898   944   898   782\n## [4,] 1028  929  683  636  652  671  741  685  792   987   970   954   981   801\n## [5,] 1091  847  653  671  656  505  295  227  272   559   905  1021   843   737\n## [6,] 1203  866  662  671  563  226  277  420  589   595   453   922   976   569\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   367   625   815   858   834   805   787   778   728   705   443   767\n## [2,]   553   524   727   820   764   782   818   764   701   708   554   730\n## [3,]   454   397   610   865   898   781   773   732   737   601   738   483\n## [4,]   353   330   360   726   895   884   805   676   533   414   423   272\n## [5,]   282   263   286   624   833   857   854   758   408   404   311   320\n## [6,]   230   232   226   408   778   864   878   744   416   869   422   457\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   609   830   522   732  1120  1357  1204  1245  1161  1185  1240   841\n## [2,]   528  1335  1189  1544  1136   817   773   636   645   895   916   629\n## [3,]   586   567   868  1100  1091   990  1242   726   788  1283  1275  1272\n## [4,]   490   570  1190  1682   688  1233  1172   681   515   751  1027  1187\n## [5,]   408   543  1135  1539   721  1415   914   717   593  1200  2212  1484\n## [6,]   643   790  1792  1255   916  1064   593  1194  1500  1775  1272  1082\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   876  1056  1120   993  1360  1319  1735  1296  1241  2006  1024  1126\n## [2,]   993  1421  1470  1018  1670  1098  1176   988  1367  1045  1038  1325\n## [3,]   642   500  1034   885  1149  1408   877   790   990  1044  1079  1037\n## [4,]  1145   756   896   899   885  1620   611  1069   985  1139  1517   997\n## [5,]   573   521   609   912  1087  1671  1265  1341  1180  1239  1373  1230\n## [6,]   800  1234  1248  1130  1539  1803  1195  1439  1708   977  1147  1449\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1012   564   291   224   385   429  1113  1044  1026  1023   881   981\n## [2,]  1635  1317   471   236   334   469  1140  1078  1100  1474  1019   857\n## [3,]   952   966   907   357   272   516   719  1287  1128  1213   991  1103\n## [4,]   924   835  1564   538   220   345   412   994  1045  1182  1213  1209\n## [5,]  1444  1176  1157   883   553   217   235   688   719  1683  1504  1209\n## [6,]  1078  1210  1274  1200   773   345   235   688   719  1683  1504  1300\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   455   525   749  1680   617  1122  1724  1225  1098   935  1173  1113\n## [2,]   726   779   853   958  1472  1538  1244  1396  1339  1076  1079  1728\n## [3,]  1242  1224   954  1333  1876  1471  1211  1396  1339  1076  1079  1728\n## [4,]  1396  1567  1734  1333  1876  1471  1211  1232  1606  1202  1167  1777\n## [5,]  1396  1567  1734  1416  1257  1240  1864   883   657   994  1970  1409\n## [6,]  1354  1159  1164  1059   894   710  1565  1160  1098   983   945   831\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1560  1543  1869  1469  1919  1555  1183\n## [2,]  1560  1543  1869  1469  1555  1816  1433\n## [3,]  1374  1456  1202   985  1234  1628  1580\n## [4,]  1195  1118  1310  1637  1316  1255   870\n## [5,]  1039  1245  1744  1939  1295  1668  1282\n## [6,]   874  1022  2013  1786  1940  1452  1289\n## \n## , , 4\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1078 1072  972  991 1036 1066 1187 1172  970   906   864   815  1065   984\n## [2,] 1078 1072 1017  926  940  982 1002 1219 1378  1251  1072  1032  1153  1201\n## [3,] 1096 1111  961  809  768  777  859  959 1105  1220  1109  1049  1115  1211\n## [4,] 1168 1063  815  733  744  788  827  816  876  1075  1061  1058  1116  1265\n## [5,] 1271 1011  752  759  770  566  360  409  508   913  1153  1147  1177  1222\n## [6,] 1345 1149  759  783  610  399  597  850  984   867   856  1062  1404  1213\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   878  1081  1065   962   936   926   922   856   852   820   823   946\n## [2,]  1080  1010  1130   980   883   879   920   882   846   786  1001  1044\n## [3,]  1023   986  1057  1068  1006   926   891   847   803   860  1032   809\n## [4,]  1036   924   903  1013  1090   986   899   784   658   732   669   551\n## [5,]  1012   906   916  1030  1082   970   970   869   650   756   668   685\n## [6,]   957   939   897   979  1104  1019   991   862   872   972   841   897\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   915  1058  1065  1217  1259  1300  1440  1491  1433  1402  1426  1152\n## [2,]   828  1222  1472  1894  1248  1188  1202  1008   936  1345  1358   945\n## [3,]   906   925  1156  1431  1159  1343  1558  1148  1110  1402  1446  1331\n## [4,]   865   876  1507  1816  1132  1399  1410  1025   918  1027  1348  1651\n## [5,]   920   877  1381  1591  1047  1581  1120  1009  1036  1536  2175  1631\n## [6,]  1049  1166  1968  1552  1234  1511  1127  1468  1685  1813  1604  1104\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1152  1271  1342  1303  1393  1476  1599  1530  1598  2419  1517  1444\n## [2,]  1137  1479  1437  1310  1760  1493  1534  1576  1671  1412  1397  1776\n## [3,]  1102   949  1173  1106  1460  1397  1234  1114  1246  1394  1486  1492\n## [4,]  1455  1055  1103  1050  1259  1439  1068  1205  1262  1323  1694  1368\n## [5,]   994   932  1059  1036  1474  1834  1361  1465  1416  1593  1789  1551\n## [6,]  1114  1353  1431  1287  1635  1705  1379  1710  1736  1419  1362  1583\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1382  1005   628   618   711   829  1245  1359  1236  1280  1342  1248\n## [2,]  1997  1713   965   636   671   856  1266  1281  1225  1513  1423   994\n## [3,]  1379  1365  1353   749   641   846  1048  1339  1430  1199  1243  1381\n## [4,]  1167  1271  1540   894   600   775   842  1190  1363  1310  1470  1378\n## [5,]  1636  1532  1492  1257   924   643   585   891  1016  1775  1637  1378\n## [6,]  1455  1319  1593  1579  1111   733   585   891  1016  1775  1637  1303\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   826   840  1089  1202  1057  1402  1680  1461  1422  1179  1425  1638\n## [2,]   960  1158  1129  1368  1813  1809  1366  1402  1409  1307  1331  1762\n## [3,]  1417  1342  1145  1510  1882  1604  1530  1402  1409  1307  1331  1762\n## [4,]  1489  1673  1701  1510  1882  1604  1530  1368  1437  1413  1609  1731\n## [5,]  1489  1673  1701  1474  1472  1514  1852  1304   805  1354  1913  1534\n## [6,]  1446  1457  1437  1396  1131  1169  1565  1226  1181  1248  1116  1077\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1559  1759  1940  1692  1996  1627  1583\n## [2,]  1559  1759  1940  1692  1660  1795  1639\n## [3,]  1665  1445  1305  1273  1377  1759  1708\n## [4,]  1301  1330  1417  1644  1461  1435  1161\n## [5,]  1209  1386  1822  2042  1571  1782  1578\n## [6,]  1114  1063  2397  2174  1617  1621  1438\n## \n## , , 5\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1200 1128 1139 1219 1298 1410 1644 1632 1762  1640  1350  1337  1648  1754\n## [2,] 1200 1128 1067 1021 1025 1038 1151 1524 1966  1979  1676  1638  1694  2047\n## [3,] 1179 1156 1077  975  886  883  928 1074 1225  1353  1207  1161  1203  1954\n## [4,] 1237 1165  910  755  758  906  967  863  937  1141  1160  1182  1397  2180\n## [5,] 1313 1106  802  827  814  547  502  704 1175  1507  1528  1286  1575  2381\n## [6,] 1624 1225  871  834  617  676 1375 1866 1766  1522  1538  1523  1959  2747\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1557  2128  1529  1209  1099  1021   951   968  1004   879  1350  1877\n## [2,]  2076  1990  1679  1201   957  1001  1035   964   933  1049  1684  1594\n## [3,]  2337  2208  1901  1501  1145  1003   994   902   958  1141  1752  1326\n## [4,]  2777  2672  2099  1621  1295  1097  1021   876   759  1455  1315  1380\n## [5,]  2996  3032  2832  2120  1414  1156  1116   869  1138  1458  1207  1850\n## [6,]  3236  3008  3117  2547  1676  1212  1124  1000  1478  1959  1540  1930\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1329  1547  1798  2064  1537  1834  1965  1912  2004  1986  1857  1515\n## [2,]  1355  1660  1991  2051  1457  1586  1967  1879  1566  1855  1930  1472\n## [3,]  1458  1342  1868  2146  1433  1555  2115  1976  1692  1736  1850  1757\n## [4,]  1778  1770  2042  2094  1233  1822  1913  1844  1733  1731  1842  1938\n## [5,]  1983  2024  1909  1768  1421  2012  1754  1626  1603  2099  2435  2011\n## [6,]  2058  1856  2177  1445  1991  1967  1555  1910  1965  1904  1679  1465\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1462  1630  1485  1627  1912  1767  2125  2427  2285  2109  1716  2190\n## [2,]  1486  1650  1721  1634  1959  1857  1946  2082  2135  2136  2199  2470\n## [3,]  1690  1542  1368  1705  1893  1805  1850  1923  1693  1850  2163  2432\n## [4,]  1928  1698  1434  1519  1644  2051  1533  1601  1569  1955  2314  1829\n## [5,]  1718  1741  1547  1610  1638  1888  1591  1679  1968  2188  1980  1913\n## [6,]  1562  1847  1877  1686  1854  1804  1520  1944  2213  2000  2193  2228\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2382  1954  1558  1428  1670  1483  1504  1853  1591  1747  2130  1765\n## [2,]  2567  2400  1671  1514  1624  1708  1754  1746  1498  1629  1896  1639\n## [3,]  2348  2013  1803  1597  1469  1470  1536  1653  1748  1517  1812  1592\n## [4,]  1810  2024  1959  1585  1874  1776  1464  1664  1708  1615  1507  1403\n## [5,]  1982  2037  2288  1939  1946  1954  1510  1601  1493  1891  1844  1403\n## [6,]  1932  1907  2137  2202  1881  1470  1510  1601  1493  1891  1844  1577\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1484  1494  1841  2080  1903  1949  1799  1545  1717  1698  1758  2023\n## [2,]  1602  1593  1639  1717  2291  2085  1667  1496  1505  1652  1732  2013\n## [3,]  1429  1390  1426  1691  2100  1855  1655  1496  1505  1652  1732  2013\n## [4,]  1618  1814  1851  1691  2100  1855  1655  1546  1657  1779  1748  1888\n## [5,]  1618  1814  1851  1720  1623  1717  1959  1261  1362  1445  1896  1837\n## [6,]  1759  1991  1862  1754  1892  1854  1958  1362  1493  1507  1589  1496\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1791  1780  1967  1714  2059  1715  1565\n## [2,]  1791  1780  1967  1714  1740  1913  1757\n## [3,]  1672  1807  1620  1514  1510  1841  1891\n## [4,]  1419  1402  1459  1802  1704  1527  1646\n## [5,]  1411  1494  2038  2236  1472  1757  1779\n## [6,]  1466  1433  2122  2400  1977  1723  1572\n## \n## , , 6\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1246 1271 1268 1252 1259 1473 1689 2021 2088  1716  1603  1578  1866  1810\n## [2,] 1246 1271 1156 1135 1156 1225 1301 1650 2214  2454  1938  1629  1776  2510\n## [3,] 1244 1235 1187 1030  944  978 1039 1153 1344  1303  1184  1299  1457  2308\n## [4,] 1314 1255  998  859  884  918  873  747 1009  1297  1332  1333  1479  2470\n## [5,] 1423 1241  887  901  892  707  712 1070 1440  1638  1641  1412  1781  2882\n## [6,] 1863 1350  918  883  700  700 1261 1945 1915  1928  1918  1800  2230  3187\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1849  2326  1596  1186  1118  1198  1183  1094   985   886  1602  2139\n## [2,]  2513  2332  1912  1361  1074  1070  1115  1085  1076  1230  1906  1696\n## [3,]  2616  2477  2191  1648  1259  1132  1090  1010  1003  1350  2138  1628\n## [4,]  3260  3198  2465  1807  1460  1258  1149   972   951  1509  1487  1491\n## [5,]  3622  3610  3435  2520  1605  1267  1192  1019  1316  1717  1537  2025\n## [6,]  3726  3651  3742  3216  2019  1421  1251  1125  1738  1966  1727  2234\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1511  1755  2200  2470  1555  1677  2148  2163  2061  2064  1985  1577\n## [2,]  1314  1493  2081  2229  1594  1898  2348  2029  1793  2051  2071  1670\n## [3,]  1902  1697  2160  2181  1519  1735  2427  2284  1865  1762  1962  1766\n## [4,]  1982  1933  2153  2228  1323  1829  2008  2251  1918  1857  1944  2165\n## [5,]  2367  2246  2015  1732  1535  2185  1723  1673  1859  2271  2435  2006\n## [6,]  2282  2113  2529  1546  2293  2156  1850  2072  2081  2026  1863  1567\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1680  1821  1698  1757  1837  1798  2103  2549  2459  2456  2008  2468\n## [2,]  1785  1704  1714  1712  2101  1942  2213  2438  2406  2421  2514  2760\n## [3,]  1641  1601  1542  1860  2115  1928  2163  2077  1771  2085  2452  2685\n## [4,]  2326  2009  1676  1669  1710  1909  1681  1809  1758  2125  2498  2038\n## [5,]  1778  1892  1823  1670  1866  2107  1620  1760  2172  2375  2149  2013\n## [6,]  1795  1866  1881  1803  1866  1742  1635  2080  2371  2287  2324  2391\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2667  2159  1796  1857  1926  1716  1678  2097  1639  1949  2383  1980\n## [2,]  2757  2579  1936  1843  1842  1841  1832  1826  1487  1778  2028  1818\n## [3,]  2673  2321  2038  1765  1694  1765  1747  1830  1838  1593  1901  1717\n## [4,]  2032  2332  2072  1836  2172  1978  1713  1849  1816  1669  1576  1407\n## [5,]  2112  2324  2539  2286  2254  2290  1777  1797  1634  2097  1866  1407\n## [6,]  2103  1920  2235  2403  2127  1853  1777  1797  1634  2097  1866  1614\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1673  1724  2010  2182  2190  2086  1861  1566  1898  1832  1918  2167\n## [2,]  1786  1784  1879  1911  2436  2204  1747  1454  1632  1794  1878  2032\n## [3,]  1563  1437  1525  1782  2212  1886  1744  1454  1632  1794  1878  2032\n## [4,]  1636  1829  1840  1782  2212  1886  1744  1590  1718  1803  1827  1949\n## [5,]  1636  1829  1840  1767  1674  1811  1994  1409  1470  1512  1957  1918\n## [6,]  1894  2131  1937  1895  2030  2091  1997  1426  1709  1636  1725  1634\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1768  1820  1934  1744  2073  1771  1707\n## [2,]  1768  1820  1934  1744  1716  1966  1873\n## [3,]  1749  1821  1744  1660  1576  1896  1851\n## [4,]  1480  1518  1515  1967  1706  1693  1798\n## [5,]  1452  1554  2137  2192  1496  1802  1790\n## [6,]  1653  1398  2207  2378  2023  1814  1656\n## \n## , , 7\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1318 1372 1324 1338 1383 1619 1868 2271 2197  1884  1620  1586  1925  2182\n## [2,] 1318 1372 1248 1233 1357 1336 1343 1686 2531  2585  2089  1937  2015  2760\n## [3,] 1327 1354 1267 1120 1005 1046 1134 1208 1398  1474  1348  1417  1455  2533\n## [4,] 1386 1399 1104  938  976  989 1095 1012 1218  1463  1427  1424  1619  2743\n## [5,] 1504 1322  973 1010  960  807  591  912 1249  1751  1739  1581  1872  3018\n## [6,] 2108 1390 1028  986  858  668 1523 2383 2210  1974  2039  1880  2463  3438\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1877  2681  1633  1361  1305  1241  1273  1231  1191  1184  1522  2377\n## [2,]  2719  2481  2175  1432  1175  1184  1238  1179  1156  1303  2172  1665\n## [3,]  2896  2767  2424  1811  1404  1219  1186  1135  1177  1373  2353  1627\n## [4,]  3585  3357  2545  2059  1570  1396  1225  1061   950  1710  1621  1626\n## [5,]  3939  3867  3723  2707  1707  1370  1350  1208  1208  2090  1312  2346\n## [6,]  4087  3874  3986  3524  2174  1500  1415  1348  1567  2469  1816  2279\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1722  1797  2202  2239  1625  1780  2396  2099  2344  2174  1848  1830\n## [2,]  1394  1892  1849  2119  1670  1984  2374  2222  1653  2178  2127  1737\n## [3,]  2032  1381  2425  2169  1562  1873  2507  2394  2218  1848  2035  1874\n## [4,]  2115  2123  2305  2324  1226  1993  2017  2457  1888  1952  2005  2350\n## [5,]  2491  2420  2121  1790  1553  2287  1843  1886  1883  2311  2574  2068\n## [6,]  2684  2239  2320  1481  2620  1956  1845  2195  2018  2092  1816  1630\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1533  1824  1693  1848  1899  1742  2413  2753  2602  2981  1949  2619\n## [2,]  1928  1861  1846  1736  2265  1940  2269  2425  2705  2716  2677  2977\n## [3,]  1727  1735  1588  1955  2163  1986  2291  2329  1895  2345  2800  2914\n## [4,]  2383  2173  1646  1861  1613  2012  1922  1935  1800  2097  2588  2047\n## [5,]  1881  2161  1770  1796  1900  2081  1680  1802  2199  2640  2311  2141\n## [6,]  1799  1941  2070  1960  1962  1975  1612  2234  2312  2300  2366  2544\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2912  2447  1906  1811  2109  1852  1725  2124  1716  2052  2439  2086\n## [2,]  2773  2819  1905  2007  1927  2062  1967  2083  1575  1883  2370  1908\n## [3,]  2931  2385  2157  2057  1724  2038  1586  1912  1906  1542  1821  1644\n## [4,]  2016  2653  2424  1837  2543  2179  1829  1932  1859  1625  1687  1584\n## [5,]  2144  2337  2860  2168  2335  2223  1657  1984  1669  2251  2015  1584\n## [6,]  2292  1955  2405  2697  2191  2222  1657  1984  1669  2251  2015  1617\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1795  1895  2036  2427  2226  2203  2009  1459  2107  1832  2068  2095\n## [2,]  1908  1801  1875  1840  2575  2264  1720  1454  1803  1848  1940  2218\n## [3,]  1629  1686  1621  1881  2240  1870  1685  1454  1803  1848  1940  2218\n## [4,]  1655  1770  1962  1881  2240  1870  1685  1472  1792  1778  1754  2105\n## [5,]  1655  1770  1962  1792  1788  1796  2444  1106  1696  1553  2261  1937\n## [6,]  2043  2077  1919  1936  2194  2040  2060  1429  1828  1675  1594  1778\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1719  1926  2236  1721  2040  1912  1753\n## [2,]  1719  1926  2236  1721  1778  1964  1715\n## [3,]  1568  1858  1754  1712  1537  1862  1890\n## [4,]  1493  1620  1713  2018  1583  1784  1802\n## [5,]  1422  1692  1954  2276  1539  1938  1585\n## [6,]  1583  1521  2389  2206  2269  1672  1637\n## \n## , , 8\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1412 1394 1445 1371 1454 1671 1929 2432 2313  1977  1834  1773  2173  2053\n## [2,] 1412 1394 1294 1263 1382 1416 1473 1878 2560  2673  2160  1811  2094  2717\n## [3,] 1372 1435 1330 1132 1076 1088 1196 1285 1531  1485  1428  1431  1725  2587\n## [4,] 1380 1393 1172 1022 1052 1064  993  957 1185  1500  1455  1454  1691  2865\n## [5,] 1588 1406 1041 1029 1031  808  756 1198 1447  1799  1861  1607  2056  3175\n## [6,] 2062 1584 1034 1059  839  727 1419 2113 2044  2031  2054  1991  2653  3539\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  2173  2465  1946  1403  1307  1403  1407  1279  1145  1155  1779  2189\n## [2,]  2870  2581  2235  1543  1270  1246  1268  1283  1285  1316  2134  1908\n## [3,]  2947  2770  2475  1856  1500  1310  1225  1153  1158  1611  2249  1724\n## [4,]  3585  3511  2702  2131  1731  1451  1351  1119  1079  1680  1703  1672\n## [5,]  3940  4064  3669  2818  1843  1493  1433  1248  1419  2061  1688  2169\n## [6,]  4042  4030  3999  3535  2313  1629  1429  1387  1898  2101  2118  2352\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1746  1752  2485  2700  1604  1841  2367  2204  2198  2242  1964  1722\n## [2,]  1366  1642  2174  2475  1711  2114  2605  2280  1961  2263  2122  1891\n## [3,]  2057  1842  2349  2311  1626  1899  2563  2468  1898  1886  2040  1827\n## [4,]  2106  1976  2351  2207  1484  1797  2201  2406  2085  2083  2084  2380\n## [5,]  2740  2355  2149  1681  1683  2279  1860  1968  1978  2392  2564  2084\n## [6,]  2477  2429  2368  1963  2235  2166  1964  2153  2092  2094  1939  1630\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1769  1825  1868  1863  1897  1956  2346  2625  2677  2665  2085  2741\n## [2,]  1918  1813  1839  1874  2228  2031  2388  2593  2850  2725  2817  3007\n## [3,]  1834  1772  1680  2028  2229  1964  2407  2426  2047  2384  2821  2931\n## [4,]  2506  2224  1858  1856  1779  1823  1963  1960  1900  2286  2628  2162\n## [5,]  1957  2142  2044  1810  1999  2038  1774  1861  2187  2505  2284  2189\n## [6,]  1801  1956  2050  1895  1948  1935  1770  2205  2367  2481  2386  2605\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2926  2511  2102  1960  2096  1942  1772  2162  1758  2006  2476  2195\n## [2,]  2950  2677  2325  2102  1964  2131  1977  2079  1559  1973  2229  2011\n## [3,]  2984  2604  2235  2055  1812  1996  1744  1980  1857  1740  1984  1798\n## [4,]  2116  2613  2279  1974  2260  2268  1807  1993  1916  1713  1691  1515\n## [5,]  2146  2526  2706  2472  2441  2412  1955  1925  1798  2126  1975  1515\n## [6,]  2291  2102  2500  2582  2298  2064  1955  1925  1798  2126  1975  1714\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1831  1911  2060  2307  2308  2268  1876  1717  2042  1854  2076  2137\n## [2,]  1860  1934  1887  1902  2428  2438  1733  1562  1807  1868  2019  2064\n## [3,]  1630  1571  1666  1891  2216  1942  1798  1562  1807  1868  2019  2064\n## [4,]  1749  1849  1920  1891  2216  1942  1798  1539  1722  1788  1879  2041\n## [5,]  1749  1849  1920  1824  1707  1929  2184  1502  1370  1688  2069  1960\n## [6,]  2026  2112  1967  2005  2113  2306  2022  1699  1742  1769  1813  1854\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1694  1868  2024  1818  2018  1864  1946\n## [2,]  1694  1868  2024  1818  1790  1931  1953\n## [3,]  1837  1783  1862  1739  1682  1746  1894\n## [4,]  1620  1607  1680  1926  1647  1846  1854\n## [5,]  1548  1698  2210  2162  1637  1869  1679\n## [6,]  1787  1533  2376  2222  2003  1912  1755\n## \n## , , 9\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1909 1893 1870 1809 1834 1967 1998 2006 1730  1550  1696  1754  1978  1788\n## [2,] 1909 1893 1742 1742 1818 1865 1990 2189 2252  2194  1940  1885  2054  2223\n## [3,] 1856 1882 1761 1668 1603 1605 1675 1833 2036  2094  2033  2083  2098  2244\n## [4,] 1908 1849 1679 1559 1533 1538 1469 1404 1612  2009  2050  2091  2134  2229\n## [5,] 2054 1851 1587 1568 1497 1185  928  913 1108  1532  1976  2131  2321  2226\n## [6,] 2588 2151 1665 1508 1219  900 1004 1328 1568  1577  1647  2057  2504  2082\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1584  2019  2279  2168  2086  2095  2080  2036  1950  1803  1687  1695\n## [2,]  2037  2000  2217  2160  1997  1959  1956  1895  1844  1777  1760  1584\n## [3,]  1911  1791  2130  2346  2249  2050  1929  1831  1780  1747  1726  1415\n## [4,]  1875  1692  1831  2186  2433  2312  2056  1735  1493  1414  1303  1273\n## [5,]  1777  1642  1701  2111  2347  2329  2189  1908  1516  1371  1220  1353\n## [6,]  1596  1594  1631  1942  2329  2379  2279  2151  1900  1720  1534  1655\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1581  1630  1687  2141  2019  1978  2153  2314  2345  2077  1961  1870\n## [2,]  1513  2000  2112  2465  1958  1924  2103  2029  1992  2082  1964  1726\n## [3,]  1686  1609  2043  2398  1857  1863  2132  1926  1939  2156  2089  1906\n## [4,]  1679  1734  2225  2376  1765  1947  2030  1862  1637  1916  2276  2344\n## [5,]  1708  1807  2121  2133  1764  2301  1733  1573  1747  2408  2886  2476\n## [6,]  1911  1980  2384  1798  1876  1955  1642  1790  2202  2453  2443  2018\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1976  2117  2086  2009  2063  1994  2353  2468  2635  2651  2375  2556\n## [2,]  1835  2139  2261  2004  2174  1985  2145  2540  3014  2929  2730  2865\n## [3,]  1664  1697  2153  2061  2120  2165  2145  2427  2581  2638  2795  2660\n## [4,]  2209  1961  2043  1854  1840  2049  1936  2202  2110  2286  2362  2143\n## [5,]  1935  1682  1786  1807  1918  2176  2159  2269  2195  2266  2239  2193\n## [6,]  1775  1966  2067  2012  2381  2448  2216  2347  2430  2430  2495  2429\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2587  2065  1332  1106  1370  1454  1830  2025  1959  2113  2266  2046\n## [2,]  2983  2730  1735  1174  1298  1531  2064  2154  1958  2042  2153  1914\n## [3,]  2498  2520  2133  1381  1239  1494  1808  2077  2132  2050  2175  2010\n## [4,]  2135  2292  2308  1610  1270  1386  1446  1778  1989  1998  1952  1990\n## [5,]  2239  2307  2330  2017  1618  1232  1135  1481  1704  2258  2182  1990\n## [6,]  2309  2227  2296  2356  1934  1372  1135  1481  1704  2258  2182  2049\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1600  1594  1784  1854  1849  2143  2227  2079  2055  2006  2024  2189\n## [2,]  1676  1703  1668  1775  2124  2265  2141  2043  2022  2003  2116  2352\n## [3,]  1947  1918  1890  2031  2403  2241  2077  2043  2022  2003  2116  2352\n## [4,]  2202  2284  2188  2031  2403  2241  2077  1887  1886  1966  2103  2250\n## [5,]  2202  2284  2188  2085  2112  2250  2214  1558  1410  1807  2126  2086\n## [6,]  2145  2119  2019  2012  2006  2052  2184  1826  1878  1935  1939  1875\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  2192  2409  2448  2288  2507  2349  2311\n## [2,]  2192  2409  2448  2288  2330  2589  2409\n## [3,]  2303  2215  2041  1864  2130  2585  2343\n## [4,]  1970  1995  1911  2019  2000  2085  2116\n## [5,]  1952  2167  2746  2542  2156  2304  2167\n## [6,]  1868  1990  2826  2773  2373  2208  2178\n## \n## , , 10\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1480 1488 1448 1391 1399 1439 1500 1418 1118  1129  1194  1196  1329  1207\n## [2,] 1480 1488 1411 1362 1404 1457 1524 1705 1699  1508  1438  1516  1524  1417\n## [3,] 1469 1495 1384 1305 1276 1294 1363 1502 1696  1853  1784  1709  1639  1443\n## [4,] 1483 1444 1331 1270 1258 1278 1250 1186 1353  1675  1802  1771  1624  1419\n## [5,] 1602 1485 1308 1293 1249 1011  698  600  720  1149  1613  1787  1682  1344\n## [6,] 1925 1700 1348 1263 1025  662  669  857 1100  1082  1161  1473  1732  1237\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   967  1219  1648  1758  1693  1707  1708  1682  1574  1444  1168  1107\n## [2,]  1176  1180  1553  1760  1696  1647  1687  1609  1517  1366  1247  1223\n## [3,]  1082  1017  1325  1785  1925  1795  1625  1540  1442  1296  1233   989\n## [4,]  1006   831  1022  1517  1973  2025  1771  1460  1152   968   842   737\n## [5,]   906   780   888  1302  1806  1975  1869  1597  1061   903   796   796\n## [6,]   783   735   765  1068  1622  1921  1914  1711  1286  1166  1038  1002\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1197  1371  1348  1813  1784  1554  1666  1832  1869  1615  1513  1524\n## [2,]  1164  1694  1944  2578  1904  1628  1507  1426  1576  1604  1460  1288\n## [3,]  1116  1266  1580  1960  1555  1542  1636  1344  1440  1709  1716  1720\n## [4,]  1070  1179  1772  2129  1641  1746  1638  1317  1138  1466  1891  1954\n## [5,]  1035  1191  1759  2042  1479  1958  1379  1139  1276  2058  2795  2263\n## [6,]  1151  1411  2318  2014  1456  1641  1171  1317  1878  2246  2229  1803\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1676  1897  1839  1746  1938  1834  1997  1900  1911  2084  1844  1859\n## [2,]  1403  1894  2222  1769  1952  1768  1752  1898  2240  2094  1965  2159\n## [3,]  1473  1427  1895  1624  1782  1838  1541  1656  1951  1920  1826  1863\n## [4,]  1631  1315  1726  1651  1612  1829  1597  1779  1719  1817  1846  1722\n## [5,]  1514  1261  1442  1531  1644  1984  2042  1953  1814  1855  1826  1836\n## [6,]  1552  1746  1849  1825  2226  2318  2029  2183  2255  1993  1913  1926\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1801  1435   821   613   811  1012  1657  1674  1638  1808  1789  1556\n## [2,]  2256  1933  1138   682   757  1033  1753  1802  1710  1783  1756  1467\n## [3,]  1830  1766  1574   936   724   971  1456  1813  1934  1876  1982  1869\n## [4,]  1696  1680  1837  1220   727   833   949  1362  1823  1771  1810  1848\n## [5,]  2060  1874  1744  1530  1115   746   692  1057  1369  1878  1919  1848\n## [6,]  1903  1872  1928  1790  1474   860   692  1057  1369  1878  1919  1892\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1109  1173  1383  1471  1400  1760  2154  2059  1864  1707  1748  1814\n## [2,]  1322  1417  1332  1466  1815  2213  2112  2035  1936  1818  1871  2119\n## [3,]  1822  1868  1696  1806  2438  2347  2042  2035  1936  1818  1871  2119\n## [4,]  2092  2214  2123  1806  2438  2347  2042  1855  1795  1812  1876  2060\n## [5,]  2092  2214  2123  1972  1865  1921  1924  1386  1206  1498  1880  1915\n## [6,]  2027  1868  1807  1722  1528  1570  1869  1689  1625  1704  1720  1563\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  2026  2274  2359  2254  2495  2443  2402\n## [2,]  2026  2274  2359  2254  2278  2625  2568\n## [3,]  2199  2084  1830  1685  1920  2164  2106\n## [4,]  1878  1942  1804  1891  1908  2030  1852\n## [5,]  1824  2048  2751  2488  2102  2182  2015\n## [6,]  1647  1812  2697  2733  2209  2019  2068\n\n\n\n\nPara agregar un nuevo atributo en función de los que ya existen.\n\nnames(im1) &lt;- \"Sentinel2\"\nim2 &lt;- im1 |&gt; \n  mutate(band2 = 2 * Sentinel2)\nim2\n## stars object with 3 dimensions and 2 attributes\n## attribute(s):\n##            Min. 1st Qu. Median     Mean 3rd Qu.  Max.\n## Sentinel2     6     913   1552 1501.178 2010.75  5041\n## band2        12    1826   3104 3002.356 4021.50 10082\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12\n\nAhora ya tenemos dos atributos.\n\n\n\n\n\nPara seleccionar algunos atributos se usa select.\n\nim2 |&gt; \n  select(band2)\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##        Min. 1st Qu. Median     Mean 3rd Qu.  Max.\n## band2    12    1826   3104 3002.356  4021.5 10082\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12\n\n\n\n\nEn algunos casos estaremos más interesados en calcular índices que resalten algunas características de la superficie terrestre. Por ejemplo, algún índice de vegetación. Esto se puede realizar al seleccionar las bandas de interés y aplicar la fórmula.\n\nNIR &lt;- im1[,,,8]\nR &lt;- im1 [,,,4]\n\n# Tidyverse-esque\n# Si no se agrega drop = F, se elimina la tercera dimensión y luego ya no permite concatenar esta banda con el resto de la imagen.\nNIR &lt;- im1 |&gt;\n  slice(band, 8, drop = F)\nR &lt;- im1 |&gt;\n  slice(band, 4, drop = F)\n\nNDVI &lt;- (NIR - R) / (NIR + R)\n\nplot(NDVI)\n\n\n\n\n\n\n\nPara agregar una banda a un raster se utiliza la función c.\n\nim1_cNDVI &lt;- c(im1, \n               NDVI,\n               along = 3)\n\n\n\n\n\n\n\nPara transformar un vector a raster se utiliza la función st_rasterize. Para ello, hay que determinar la resolución a la que se quiere rasterizar esta información. Utilizamos los valores de resolución que tiene el objeto im1. Recordemos que estos valores están en las unidades del CRS de la capa. En este caso, el CRS está en coordenadas geográficas, por eso se utilizarán valores en grados.\n\nroi_rast &lt;- st_rasterize(roi[\"id\"], dx = 0.000179663, dy = -0.000179663)\nplot(roi_rast)\n## Warning in plot.stars(roi_rast): breaks=\"quantile\" leads to a single class;\n## maybe try breaks=\"equal\" instead?\n\n\n\n\n\n\n\nPara transformar de raster a un vector de puntos se puede utilizar la función st_as_sf, utilizando el argumento de as_points. Además, si se desean obtener los datos en formato largo en lugar de ancho se puede utilizar el argumento long.\n\nst_as_sf(im1, \n         as_points = TRUE, \n         merge = FALSE)\n## Simple feature collection with 8343 features and 10 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -101.2352 ymin: 19.64373 xmax: -101.2169 ymax: 19.6581\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##     B2  B3   B4   B5   B6   B7   B8  B8A  B11  B12                  geometry\n## 1  434 662  939 1078 1200 1246 1318 1412 1909 1480 POINT (-101.2352 19.6581)\n## 2  434 662  939 1078 1200 1246 1318 1412 1909 1480  POINT (-101.235 19.6581)\n## 3  443 685  960 1096 1179 1244 1327 1372 1856 1469 POINT (-101.2348 19.6581)\n## 4  488 729 1028 1168 1237 1314 1386 1380 1908 1483 POINT (-101.2347 19.6581)\n## 5  560 803 1091 1271 1313 1423 1504 1588 2054 1602 POINT (-101.2345 19.6581)\n## 6  594 889 1203 1345 1624 1863 2108 2062 2588 1925 POINT (-101.2343 19.6581)\n## 7  461 693  980 1257 1480 1604 1709 1862 2636 1926 POINT (-101.2341 19.6581)\n## 8  420 645  907 1067 1152 1321 1561 1701 2432 1814 POINT (-101.2339 19.6581)\n## 9  436 635  920 1047 1187 1349 1544 1679 2429 1796 POINT (-101.2338 19.6581)\n## 10 345 528  745  990 1185 1381 1333 1621 2329 1695 POINT (-101.2336 19.6581)\n\nUtilizando la misma función se puede convertir de raster a vector de polígonos. En este caso, se indica como argumentos que no se desea obtener una capa de puntos y en merge se puede indicar si se desea fusionar los polígonos con un mismo valor o no.\n\nim1_poly &lt;- st_as_sf(im1, \n                     as_points = F, \n                     merge = T)\nplot(im1_poly)\n\n\n\n\n\n\n\n\n\n\nPara reproyectar un raster se utiliza la función st_transform. Al igual que en sf se necesita indicar el CRS objetivo ya sea mediante el código EPSG o obteniendo dicha clave con st_crs. Este tipo de reproyección no presenta pérdida de información debido a las diferencias entre proyecciones. Por lo tanto, los pixeles pueden no ser de dimensiones homogeneas en toda la imagen. Ve la siguiente función para hacer reproyecciones más clásicas.\n\nim1_utm &lt;- st_transform(im1, \n                        32614)\nim1_utm\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##            Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2     6     913   1552 1501.178 2010.75 5041\n## dimension(s):\n##      from  to offset delta                refsys point\n## x       1 103     NA    NA WGS 84 / UTM zone 14N FALSE\n## y       1  81     NA    NA WGS 84 / UTM zone 14N FALSE\n## band    1  10     NA    NA                    NA    NA\n##                            values x/y\n## x      [103x81] 265619,...,267562 [x]\n## y    [103x81] 2173570,...,2175186 [y]\n## band                   B2,...,B12    \n## curvilinear grid\n\n\n\n\nPara cambiar la resolución de un raster o reproyectar con pérdida de información se utiliza la función st_warp. Esta función permite definir el tamaño de celda objetivo mediante el argumento cellsize, así como el CRS objetivo. Esta función hace la reproyección donde todos los tamaños de celda son iguales y quizás es con la que cualquier usuario esté más familiarizado.\n\nim1_utm_20m &lt;- st_warp(im1, \n                       crs = st_crs(im1),\n                       cellsize = c(20, 20))\nim1_utm_20m\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##            Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n## Sentinel2    NA      NA     NA  NaN      NA   NA   10\n## dimension(s):\n##      from to   offset delta refsys point     values x/y\n## x       1  1 -101.235    20 WGS 84    NA       NULL [x]\n## y       1  1  19.6582   -20 WGS 84    NA       NULL [y]\n## band    1 10       NA    NA     NA    NA B2,...,B12\n\n\n\n\nPara crear un mosaico a partir de dos o más imágenes se utiliza la función st_mosaic.\n\nim_mosaic &lt;- st_mosaic(im1_sub2, im1_sub3)\nplot(im_mosaic)\n\n\n\n\n\n\n\n\n\n\nPara reclasificar un raster se puede realizar con la función cut, indicando los intervalos para las clases.\n\nreclass_NDVI &lt;- cut(NDVI,\n    breaks = c(-1, 0, 0.2, 0.5, 1),\n    labels = F)\nplot(reclass_NDVI)\n\n\n\n\n\n\n\nPara enmascarar algún raster utilizando otro. De igual manera se pueden emascarar los valores que no cumplan con algún criterio de interés.\n\nim_mask &lt;- reclass_NDVI\nim_mask[im_mask != 2] &lt;- NA\n\nreclass_NDVI2 &lt;- reclass_NDVI\nreclass_NDVI2[is.na(im_mask)] &lt;- NA\nplot(reclass_NDVI2)\n## Warning in plot.stars(reclass_NDVI2): breaks=\"quantile\" leads to a single class;\n## maybe try breaks=\"equal\" instead?\n\n\n\n\n\n\n\nPara calcular métrias por banda se puede utilizar la función pull para obtener el atributo del que se desea obtener la información. En este caso la imagen solo cuenta con un atributo, así que seleccionamos esa entrada. Después, podemos utilizar la función apply para calcular la media sobre la dimensión 3 del arreglo. Otra forma de acceder a los datos en formato de arreglo es con [[]].\n\n# Opción con pull\nim1 |&gt;\n  pull(1) |&gt;\n  apply(3, mean)\n##  [1]  527.6186  772.9070  935.5342 1230.8505 1700.1954 1874.5490 2004.2371\n##  [8] 2076.1721 2236.3476 1653.3689\n# Opción con doble corchete\nim1[[1]] |&gt;\n  apply(3, mean)\n##  [1]  527.6186  772.9070  935.5342 1230.8505 1700.1954 1874.5490 2004.2371\n##  [8] 2076.1721 2236.3476 1653.3689\n\n\n\n\nSi se desea aplicar una función sobre todas las bandas de una imagen por pixel, se puede utilizar la función st_apply para facilitar el cálculo de variables. Esto es muy utilizado para análisis con series de tiempo y obtener por ejemplo la media de cada pixel.\n\nmean_allBands &lt;- st_apply(im1, \n         1:2,\n         mean)\nmean_allBands\n## stars object with 2 dimensions and 1 attribute\n## attribute(s):\n##        Min. 1st Qu. Median     Mean 3rd Qu.   Max.\n## mean  225.8    1253 1502.2 1501.178 1716.45 4223.5\n## dimension(s):\n##   from  to   offset        delta refsys point values x/y\n## x    1 103 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y    1  81  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]\nplot(mean_allBands)\n\n\n\n\n\n\n\nPara obtener una tabla de las frecuencias por el valor de pixel se utiliza la función table.\n\ntable(reclass_NDVI)\n## reclass_NDVI\n##    1    2    3    4 \n##   64 2364 5527  388\n\n\n\n\n\nEn algunos casos los archivos raster con los que se desea trabajar son muy pesados y no caben en la memoria disponible RAM. Por ello, al llamar read_stars se crea automáticamente un objeto proxy stars. Estos objetos permite cargar los datos únicamente cuando se vayan a utilizar. Para cargar los datos ya que se vayan a utilizar se usa la función st_as_stars.\n\n\n\n\n\nPara generar visualizaciones más avanzadas podemos utilizar otros paquetes como ggplot2 o tmap. Aquí veremos un ejemplo de cada uno.\n\n\n\n\nEn ggplot se puede determinar directamente el color y relleno de cada capa vectorial. En este ejemplo se carga la biblioteca viridis para usar dicha escala de color.\n\nlibrary(viridis)\n## Loading required package: viridisLite\n## Loading required package: viridisLite\nggplot() + \n  geom_stars(data = im1) +\n  coord_equal() +\n  facet_wrap(~band) +\n  theme_void() +\n  scale_fill_viridis() +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n\n\n\n\n\n\n\nLa opción de tmap require de utilizar algún atributo de la información para determinar el color de relleno de cada polígono de acuerdo a los valores de ese atributo. Es similar a ggplot utilizando la opción de aes. Podemos ver algunas de las paletas que ya vienen pre hechas tanto para ggplot como para tmap con tmaptools::palette_explorer()\n\nlibrary(tmap)\n\n# Cargar shapr\ntm_shape(im1) +\n  # Elegir forma de visualización\n  tm_raster()"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#rasters",
    "href": "posts/2022-02-17-rasters-con-stars.html#rasters",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "El objeto básico en stars son los spatiotemporal arrays (stars), es decir arreglos espacio temporales. Recordemos que un arreglo corresponde a cualquier objeto organizado en dimensiones. Por ejemplo, una arreglo de dos dimensiones podría corresponder a una matriz que cuenta con una dimensión vertical (filas) y horizontal (columnas). De igual manera, un arreglo de tres dimensiones podría corresponder a una imagen raster con dos dimensiones espaciales (vertical y horizontal) y una dimensión espectral (bandas). Adicionalmente, un arreglo con cuatro dimensiones podría incluir una dimensión temporal.\n\n\nAl igual que en sf cada raster va a estar asociado a un sistema de coordenadas de referencia (CRS). Por lo cual, dicho CRS indicará la proyección de los datos y el datum."
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#estructura-de-datos-stars",
    "href": "posts/2022-02-17-rasters-con-stars.html#estructura-de-datos-stars",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Los datos stars van a estar organizados en un formato de array, es decir, de una tabla o cuadro de datos de n dimensiones. Para ver un ejemplos carguemos un archivo raster.\n\nlibrary(stars)\n## Loading required package: abind\n## Loading required package: sf\n## Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\ntif = system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nx = read_stars(tif)\nx\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##              Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## L7_ETMs.tif     1      54     69 68.91242      86  255\n## dimension(s):\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL\n\nAnalicemos qué dice esta información. Primero nos dice que se trata de un objeto stars de tres dimensiones y un atributo. Además, nos da algunas estadísticas de la información que contiene. A continuación, podemos ver las tres dimensiones: x, y y band, es decir, dos dimensiones espaciales y una espectral. Adicionalmente, se puede consultar el número de celdas en cada dimensión (from y to), la coordenada inicial en cada dimensión (offset), el tamaño de la celda en cada dimensión (delta), el sistema de referencia en el que se encuentra la información (refsys), si corresponde a puntos (point) y los valores de secuencia en caso de que la dimensión no sea regular (e.g., geometrías).\n\n\nLa misma información se puede consultar de manera más sintética.\n\nst_dimensions(x)\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#lectura-y-escritura-de-datos",
    "href": "posts/2022-02-17-rasters-con-stars.html#lectura-y-escritura-de-datos",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para leer y escribir datos desde archivos externos se utilizan las funciones read_stars y write_stars. Por ejemplo, carguemos un archivo que viene en el paquete stars:\n\nfilename &lt;- system.file(\"tif/L7_ETMs.tif\", package = \"stars\")\nx &lt;- read_stars(filename)\nx\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##              Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## L7_ETMs.tif     1      54     69 68.91242      86  255\n## dimension(s):\n##      from  to  offset delta                     refsys point values x/y\n## x       1 349  288776  28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [x]\n## y       1 352 9120761 -28.5 SIRGAS 2000 / UTM zone 25S FALSE   NULL [y]\n## band    1   6      NA    NA                         NA    NA   NULL\n\nPara escribir un vector al disco:\n\nwrite_stars(x, \n         \"x_exp.tif\")\n\nLas funciones st_read y st_write contienen más argumentos para definir ## Visualización de datos\n\n\nPor último, el visualizar los datos nos puede dar una muy buena idea de los productos intermedios en un flujo de trabajo o verificar que la información que importamos o exportamos es la correcta. Para ver el objecto stars con todos sus atributos:\n\nplot(x)\n\n\n\n\nTambién se puede hacer un RGB en color natural o falso color.\n\nplot(x, \n     rgb = c(3,2,1))\n\n\n\nplot(x, \n     rgb = c(4,3,2))"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#descargar-información-de-trabajo",
    "href": "posts/2022-02-17-rasters-con-stars.html#descargar-información-de-trabajo",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Primero vamos a cargar información desde mi github.\n\n## [1] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\Sentinel2-2A_10B_2020-01-01_2020-12-30.tif\"\n## [2] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\SRTM_area.tif\"                             \n## [3] \"D:\\\\Drive\\\\Jonathan_trabaggio\\\\Doctorado\\\\R\\\\SIG\\\\Curso\\\\Data\\\\roi.zip\"\n\nVeamos qué descargamos.\n\nim1 &lt;- read_stars(paste0(getwd(), \"/Data/\", \"Sentinel2-2A_10B_2020-01-01_2020-12-30.tif\"))\n\nim1\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...     6     913   1552 1501.178 2010.75 5041\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12\nplot(im1)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-los-índices-de-los-objetos-stars",
    "href": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-los-índices-de-los-objetos-stars",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para elegir parte de los rasters, se puede hacerlo eligiendo parte del arreglo. Esto se puede hacer utilizando la notación tradicional de objetos stars o usando la forma tidyverse-esque.\n\n\nEn la primera forma se utiliza la notación de arreglos [], en la que la primera dimensión corresponde a la dimensión de atributos, la segunda a la primera dimensión espacial (horizontal, x), la tercera a la segunda dimensión temporal (vertical, y) y la cuarta corresponde a la dimensión espectral (bandas).\n\nim1[,1:10,1:20]\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...    73  691.25   1149 1315.034 1693.25 5041\n## dimension(s):\n##      from to   offset        delta refsys point     values x/y\n## x       1 10 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1 20  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1 10       NA           NA     NA    NA B2,...,B12\nim1_sub1 &lt;- im1[,1:10,1:20, 2]\nim1_sub1\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median   Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...   189  485.75  556.5 555.88     635  889\n## dimension(s):\n##      from to   offset        delta refsys point values x/y\n## x       1 10 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y       1 20  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]\n## band    2  2       NA           NA     NA    NA     B3\nlibrary(tidyverse)\n## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n## v ggplot2 3.3.5     v purrr   0.3.4\n## v tibble  3.1.6     v dplyr   1.0.7\n## v tidyr   1.1.4     v stringr 1.4.0\n## v readr   2.1.1     v forcats 0.5.1\n## -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n## x dplyr::filter()     masks stats::filter()\n## x dplyr::lag()        masks stats::lag()\n## x readr::parse_date() masks curl::parse_date()\nim1_sub2 &lt;- im1 |&gt;\n  slice(x, 1:10) |&gt;\n  slice(y, 1:20) |&gt;\n  slice(band, 2) \nim1_sub2\n## stars object with 2 dimensions and 1 attribute\n## attribute(s):\n##                                    Min. 1st Qu. Median   Mean 3rd Qu. Max.\n## Sentinel2-2A_10B_2020-01-01_20...   189  485.75  556.5 555.88     635  889\n## dimension(s):\n##   from to   offset        delta refsys point values x/y\n## x    1 10 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y    1 20  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-los-valores-de-los-objetos-stars",
    "href": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-los-valores-de-los-objetos-stars",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Además podríamos estar interesados en filtrar valores de los rasters en función de los valores de cierta banda. Para ello, podemos hacer la función filter.\n\nlibrary(cubelyr)\nim1_sub3 &lt;- im1 |&gt;\n  filter(x &lt; -101.2332, x &gt; -101.235,\n         y &gt; 19.6564, y &lt; 19.6582,\n         band &gt; 3 )\nplot(im1_sub3)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-un-vector",
    "href": "posts/2022-02-17-rasters-con-stars.html#elegir-parte-basado-en-un-vector",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para seleccionar parte de un raster basado en un vector se puede utilizar la notación tradicional de corchetes [] o la función st_crop.\n\nroi &lt;- st_read(paste0(getwd(), \"/Data/\", \"roi.shp\"))\n## Reading layer `roi' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\roi.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.2307 ymin: 19.64597 xmax: -101.2206 ymax: 19.65094\n## Geodetic CRS:  WGS 84\nplot(roi)\n\n\n\nim1_crop &lt;- im1[roi]\nplot(im1_crop)\n\n\n\nim1_crop2 &lt;- st_crop(im1, \n                     roi)\nplot(im1_crop2)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#extraer-parte-de-los-objetos-stars",
    "href": "posts/2022-02-17-rasters-con-stars.html#extraer-parte-de-los-objetos-stars",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para extraer los valores del objeto stars y convertirlos a arreglos se puede usar la función pull. Usando esta función se extrae el atributo indicado dentro de pull.\n\nim_pull &lt;- im1 |&gt;\n  pull(1)\n# Mostrar únicamente el encabezado y algunos datos de muestra\nhead(im_pull)\n## , , 1\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  434  482  414  401  414  415  386  333  200   205   227   264   259   317\n## [2,]  434  482  441  398  401  411  440  513  533   478   372   398   397   411\n## [3,]  443  487  400  354  339  337  371  399  479   494   462   490   444   367\n## [4,]  488  441  326  309  325  333  359  324  390   511   501   489   463   393\n## [5,]  560  409  309  320  314  244  114   84  104   303   466   538   402   367\n## [6,]  594  418  321  306  255   73  134  225  296   300   208   453   471   275\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   155   316   402   424   426   434   422   403   369   367   189   456\n## [2,]   244   224   357   419   382   398   420   392   350   346   270   408\n## [3,]   192   171   257   422   478   415   394   347   336   268   459   251\n## [4,]   149   153   160   343   456   465   397   320   219   193   247   109\n## [5,]   130   133   136   292   416   447   435   372   171   211   155   125\n## [6,]   115   107   100   207   348   460   444   373   169   559   194   225\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   350   625   290   457   886   977   748   984   730   728   587   415\n## [2,]   268  1015   814  1119   807   531   406   378   347   405   436   324\n## [3,]   317   317   561   603   642   625   819   470   448   579   712   886\n## [4,]   259   278   664   718   374   946   814   365   285   474   713   661\n## [5,]   199   328   831  1035   447   995   588   414   330   734  1551   998\n## [6,]   308   485  1242   799   493   636   294   890  1186  1449   902   803\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   527   548   722   632   975   955  1417   828   645  1251   639   815\n## [2,]   631  1060  1049   717  1335   667   679   596   724   508   521   738\n## [3,]   431   304   688   513   662   932   549   375   632   611   535   555\n## [4,]   506   383   581   582   633  1319   342   611   626   748  1037   477\n## [5,]   298   279   393   629   716  1144   907   898   860   786   923   870\n## [6,]   590  1003  1012   796  1155  1320   750  1144  1341   450   595  1233\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]   612   304   149   105   198   254   783   756   711   627   495   680\n## [2,]   965   639   185   110   174   234   817   699   891   907   597   560\n## [3,]   535   444   477   204   130   275   484   974   749   890   679   692\n## [4,]   690   424  1140   392   102   174   210   596   733   927   937   770\n## [5,]  1019   825   662   505   321    89   100   477   405  1350  1211   770\n## [6,]   618   818   827   673   420   160   100   477   405  1350  1211  1016\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   271   334   467  1429   396   781  1410   847   718   570   775   564\n## [2,]   507   636   564   637  1280  1241   937   985  1004   783   690  1146\n## [3,]   909   832   610   965  1300  1042   818   985  1004   783   690  1146\n## [4,]  1098  1088  1220   965  1300  1042   818   928  1225   809   882  1280\n## [5,]  1098  1088  1220  1130   713   881  1396   647   468   549  1516  1060\n## [6,]  1078   756   856   620   444   460  1285   798   792   784   771   613\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1169  1099  1250  1012  1258  1114   776\n## [2,]  1169  1099  1250  1012  1119  1352  1038\n## [3,]   936  1132   821   704   883   937  1143\n## [4,]   885   766   896  1327  1115  1047   582\n## [5,]   707  1021  1393  1542   964  1324   844\n## [6,]   558   809  1572  1467  1384   922   872\n## \n## , , 2\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  662  695  612  616  600  651  617  623  441   440   454   485   501   591\n## [2,]  662  695  640  587  599  611  634  754  866   779   655   636   656   708\n## [3,]  685  707  603  507  489  507  552  614  666   721   665   697   668   692\n## [4,]  729  661  505  458  463  493  540  488  574   719   689   680   708   722\n## [5,]  803  619  470  475  471  369  206  202  250   477   682   742   636   749\n## [6,]  889  619  469  473  404  189  291  449  508   509   442   670   774   666\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   354   616   622   618   598   606   601   575   524   509   388   728\n## [2,]   576   532   631   622   542   570   591   545   511   529   520   686\n## [3,]   509   497   567   638   657   579   556   519   531   465   695   471\n## [4,]   482   475   435   590   675   656   583   505   381   389   441   279\n## [5,]   494   489   495   580   625   635   617   539   347   448   299   368\n## [6,]   491   478   451   561   631   633   641   540   371   804   439   458\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   546   765   525   739  1014  1196  1030  1196   997   994   832   638\n## [2,]   451  1211  1060  1333   966   722   666   633   580   655   739   563\n## [3,]   548   527   811   892   931   873  1113   699   738   845   957  1136\n## [4,]   475   556   897  1014   573  1112  1086   651   518   678   919   902\n## [5,]   460   586  1025  1267   611  1300   825   651   537  1022  1935  1227\n## [6,]   646   769  1521  1064   811   927   591  1132  1436  1634  1180  1050\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   681   855   957   846  1254  1153  1607  1181  1036  1885   869  1012\n## [2,]   872  1281  1247   841  1392   965  1011   895  1094   819   830  1100\n## [3,]   608   456   929   759   964  1185   758   657   850   854   856   903\n## [4,]   785   649   765   836   752  1514   586   819   825   943  1472   665\n## [5,]   545   540   611   863   900  1365  1111  1150  1021  1189  1111  1070\n## [6,]   783  1256  1188   923  1295  1526  1052  1385  1653   757   971  1402\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]   959   538   309   253   432   465   975  1008   885   806   816   906\n## [2,]  1212  1011   456   320   361   477  1037   898  1030  1163   869   737\n## [3,]   914   779   779   418   308   526   662  1172  1008  1130   937   864\n## [4,]   830   760  1406   588   325   439   449   874   956  1112  1034  1040\n## [5,]  1331  1105   985   770   577   320   275   693   605  1551  1448  1040\n## [6,]   937  1052  1121  1041   665   396   275   693   605  1551  1448  1204\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   451   540   728  1702   667  1057  1646  1067   985   826  1027   897\n## [2,]   697   734   791   996  1432  1421  1058  1169  1172   960   949  1411\n## [3,]  1119  1122   809  1194  1556  1278  1054  1169  1172   960   949  1411\n## [4,]  1283  1263  1537  1194  1556  1278  1054  1108  1492  1007  1002  1552\n## [5,]  1283  1263  1537  1283   904  1088  1728   850   613   731  1772  1327\n## [6,]  1251  1082  1037   850   673   695  1369   959   967   915   881   744\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1321  1295  1544  1302  1529  1336   996\n## [2,]  1321  1295  1544  1302  1327  1576  1240\n## [3,]  1129  1317  1073   879  1000  1232  1397\n## [4,]  1023  1010  1173  1584  1252  1209   798\n## [5,]   914  1130  1583  1844  1136  1448  1140\n## [6,]   821   942  1729  1615  1701  1130  1033\n## \n## , , 3\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,]  939  986  839  840  824  881  815  791  414   445   507   580   556   644\n## [2,]  939  986  886  780  817  857  892 1007 1127   969   784   759   824   799\n## [3,]  960  978  815  696  674  693  765  842  941   993   898   944   898   782\n## [4,] 1028  929  683  636  652  671  741  685  792   987   970   954   981   801\n## [5,] 1091  847  653  671  656  505  295  227  272   559   905  1021   843   737\n## [6,] 1203  866  662  671  563  226  277  420  589   595   453   922   976   569\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   367   625   815   858   834   805   787   778   728   705   443   767\n## [2,]   553   524   727   820   764   782   818   764   701   708   554   730\n## [3,]   454   397   610   865   898   781   773   732   737   601   738   483\n## [4,]   353   330   360   726   895   884   805   676   533   414   423   272\n## [5,]   282   263   286   624   833   857   854   758   408   404   311   320\n## [6,]   230   232   226   408   778   864   878   744   416   869   422   457\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   609   830   522   732  1120  1357  1204  1245  1161  1185  1240   841\n## [2,]   528  1335  1189  1544  1136   817   773   636   645   895   916   629\n## [3,]   586   567   868  1100  1091   990  1242   726   788  1283  1275  1272\n## [4,]   490   570  1190  1682   688  1233  1172   681   515   751  1027  1187\n## [5,]   408   543  1135  1539   721  1415   914   717   593  1200  2212  1484\n## [6,]   643   790  1792  1255   916  1064   593  1194  1500  1775  1272  1082\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]   876  1056  1120   993  1360  1319  1735  1296  1241  2006  1024  1126\n## [2,]   993  1421  1470  1018  1670  1098  1176   988  1367  1045  1038  1325\n## [3,]   642   500  1034   885  1149  1408   877   790   990  1044  1079  1037\n## [4,]  1145   756   896   899   885  1620   611  1069   985  1139  1517   997\n## [5,]   573   521   609   912  1087  1671  1265  1341  1180  1239  1373  1230\n## [6,]   800  1234  1248  1130  1539  1803  1195  1439  1708   977  1147  1449\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1012   564   291   224   385   429  1113  1044  1026  1023   881   981\n## [2,]  1635  1317   471   236   334   469  1140  1078  1100  1474  1019   857\n## [3,]   952   966   907   357   272   516   719  1287  1128  1213   991  1103\n## [4,]   924   835  1564   538   220   345   412   994  1045  1182  1213  1209\n## [5,]  1444  1176  1157   883   553   217   235   688   719  1683  1504  1209\n## [6,]  1078  1210  1274  1200   773   345   235   688   719  1683  1504  1300\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   455   525   749  1680   617  1122  1724  1225  1098   935  1173  1113\n## [2,]   726   779   853   958  1472  1538  1244  1396  1339  1076  1079  1728\n## [3,]  1242  1224   954  1333  1876  1471  1211  1396  1339  1076  1079  1728\n## [4,]  1396  1567  1734  1333  1876  1471  1211  1232  1606  1202  1167  1777\n## [5,]  1396  1567  1734  1416  1257  1240  1864   883   657   994  1970  1409\n## [6,]  1354  1159  1164  1059   894   710  1565  1160  1098   983   945   831\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1560  1543  1869  1469  1919  1555  1183\n## [2,]  1560  1543  1869  1469  1555  1816  1433\n## [3,]  1374  1456  1202   985  1234  1628  1580\n## [4,]  1195  1118  1310  1637  1316  1255   870\n## [5,]  1039  1245  1744  1939  1295  1668  1282\n## [6,]   874  1022  2013  1786  1940  1452  1289\n## \n## , , 4\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1078 1072  972  991 1036 1066 1187 1172  970   906   864   815  1065   984\n## [2,] 1078 1072 1017  926  940  982 1002 1219 1378  1251  1072  1032  1153  1201\n## [3,] 1096 1111  961  809  768  777  859  959 1105  1220  1109  1049  1115  1211\n## [4,] 1168 1063  815  733  744  788  827  816  876  1075  1061  1058  1116  1265\n## [5,] 1271 1011  752  759  770  566  360  409  508   913  1153  1147  1177  1222\n## [6,] 1345 1149  759  783  610  399  597  850  984   867   856  1062  1404  1213\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   878  1081  1065   962   936   926   922   856   852   820   823   946\n## [2,]  1080  1010  1130   980   883   879   920   882   846   786  1001  1044\n## [3,]  1023   986  1057  1068  1006   926   891   847   803   860  1032   809\n## [4,]  1036   924   903  1013  1090   986   899   784   658   732   669   551\n## [5,]  1012   906   916  1030  1082   970   970   869   650   756   668   685\n## [6,]   957   939   897   979  1104  1019   991   862   872   972   841   897\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]   915  1058  1065  1217  1259  1300  1440  1491  1433  1402  1426  1152\n## [2,]   828  1222  1472  1894  1248  1188  1202  1008   936  1345  1358   945\n## [3,]   906   925  1156  1431  1159  1343  1558  1148  1110  1402  1446  1331\n## [4,]   865   876  1507  1816  1132  1399  1410  1025   918  1027  1348  1651\n## [5,]   920   877  1381  1591  1047  1581  1120  1009  1036  1536  2175  1631\n## [6,]  1049  1166  1968  1552  1234  1511  1127  1468  1685  1813  1604  1104\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1152  1271  1342  1303  1393  1476  1599  1530  1598  2419  1517  1444\n## [2,]  1137  1479  1437  1310  1760  1493  1534  1576  1671  1412  1397  1776\n## [3,]  1102   949  1173  1106  1460  1397  1234  1114  1246  1394  1486  1492\n## [4,]  1455  1055  1103  1050  1259  1439  1068  1205  1262  1323  1694  1368\n## [5,]   994   932  1059  1036  1474  1834  1361  1465  1416  1593  1789  1551\n## [6,]  1114  1353  1431  1287  1635  1705  1379  1710  1736  1419  1362  1583\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1382  1005   628   618   711   829  1245  1359  1236  1280  1342  1248\n## [2,]  1997  1713   965   636   671   856  1266  1281  1225  1513  1423   994\n## [3,]  1379  1365  1353   749   641   846  1048  1339  1430  1199  1243  1381\n## [4,]  1167  1271  1540   894   600   775   842  1190  1363  1310  1470  1378\n## [5,]  1636  1532  1492  1257   924   643   585   891  1016  1775  1637  1378\n## [6,]  1455  1319  1593  1579  1111   733   585   891  1016  1775  1637  1303\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]   826   840  1089  1202  1057  1402  1680  1461  1422  1179  1425  1638\n## [2,]   960  1158  1129  1368  1813  1809  1366  1402  1409  1307  1331  1762\n## [3,]  1417  1342  1145  1510  1882  1604  1530  1402  1409  1307  1331  1762\n## [4,]  1489  1673  1701  1510  1882  1604  1530  1368  1437  1413  1609  1731\n## [5,]  1489  1673  1701  1474  1472  1514  1852  1304   805  1354  1913  1534\n## [6,]  1446  1457  1437  1396  1131  1169  1565  1226  1181  1248  1116  1077\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1559  1759  1940  1692  1996  1627  1583\n## [2,]  1559  1759  1940  1692  1660  1795  1639\n## [3,]  1665  1445  1305  1273  1377  1759  1708\n## [4,]  1301  1330  1417  1644  1461  1435  1161\n## [5,]  1209  1386  1822  2042  1571  1782  1578\n## [6,]  1114  1063  2397  2174  1617  1621  1438\n## \n## , , 5\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1200 1128 1139 1219 1298 1410 1644 1632 1762  1640  1350  1337  1648  1754\n## [2,] 1200 1128 1067 1021 1025 1038 1151 1524 1966  1979  1676  1638  1694  2047\n## [3,] 1179 1156 1077  975  886  883  928 1074 1225  1353  1207  1161  1203  1954\n## [4,] 1237 1165  910  755  758  906  967  863  937  1141  1160  1182  1397  2180\n## [5,] 1313 1106  802  827  814  547  502  704 1175  1507  1528  1286  1575  2381\n## [6,] 1624 1225  871  834  617  676 1375 1866 1766  1522  1538  1523  1959  2747\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1557  2128  1529  1209  1099  1021   951   968  1004   879  1350  1877\n## [2,]  2076  1990  1679  1201   957  1001  1035   964   933  1049  1684  1594\n## [3,]  2337  2208  1901  1501  1145  1003   994   902   958  1141  1752  1326\n## [4,]  2777  2672  2099  1621  1295  1097  1021   876   759  1455  1315  1380\n## [5,]  2996  3032  2832  2120  1414  1156  1116   869  1138  1458  1207  1850\n## [6,]  3236  3008  3117  2547  1676  1212  1124  1000  1478  1959  1540  1930\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1329  1547  1798  2064  1537  1834  1965  1912  2004  1986  1857  1515\n## [2,]  1355  1660  1991  2051  1457  1586  1967  1879  1566  1855  1930  1472\n## [3,]  1458  1342  1868  2146  1433  1555  2115  1976  1692  1736  1850  1757\n## [4,]  1778  1770  2042  2094  1233  1822  1913  1844  1733  1731  1842  1938\n## [5,]  1983  2024  1909  1768  1421  2012  1754  1626  1603  2099  2435  2011\n## [6,]  2058  1856  2177  1445  1991  1967  1555  1910  1965  1904  1679  1465\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1462  1630  1485  1627  1912  1767  2125  2427  2285  2109  1716  2190\n## [2,]  1486  1650  1721  1634  1959  1857  1946  2082  2135  2136  2199  2470\n## [3,]  1690  1542  1368  1705  1893  1805  1850  1923  1693  1850  2163  2432\n## [4,]  1928  1698  1434  1519  1644  2051  1533  1601  1569  1955  2314  1829\n## [5,]  1718  1741  1547  1610  1638  1888  1591  1679  1968  2188  1980  1913\n## [6,]  1562  1847  1877  1686  1854  1804  1520  1944  2213  2000  2193  2228\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2382  1954  1558  1428  1670  1483  1504  1853  1591  1747  2130  1765\n## [2,]  2567  2400  1671  1514  1624  1708  1754  1746  1498  1629  1896  1639\n## [3,]  2348  2013  1803  1597  1469  1470  1536  1653  1748  1517  1812  1592\n## [4,]  1810  2024  1959  1585  1874  1776  1464  1664  1708  1615  1507  1403\n## [5,]  1982  2037  2288  1939  1946  1954  1510  1601  1493  1891  1844  1403\n## [6,]  1932  1907  2137  2202  1881  1470  1510  1601  1493  1891  1844  1577\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1484  1494  1841  2080  1903  1949  1799  1545  1717  1698  1758  2023\n## [2,]  1602  1593  1639  1717  2291  2085  1667  1496  1505  1652  1732  2013\n## [3,]  1429  1390  1426  1691  2100  1855  1655  1496  1505  1652  1732  2013\n## [4,]  1618  1814  1851  1691  2100  1855  1655  1546  1657  1779  1748  1888\n## [5,]  1618  1814  1851  1720  1623  1717  1959  1261  1362  1445  1896  1837\n## [6,]  1759  1991  1862  1754  1892  1854  1958  1362  1493  1507  1589  1496\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1791  1780  1967  1714  2059  1715  1565\n## [2,]  1791  1780  1967  1714  1740  1913  1757\n## [3,]  1672  1807  1620  1514  1510  1841  1891\n## [4,]  1419  1402  1459  1802  1704  1527  1646\n## [5,]  1411  1494  2038  2236  1472  1757  1779\n## [6,]  1466  1433  2122  2400  1977  1723  1572\n## \n## , , 6\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1246 1271 1268 1252 1259 1473 1689 2021 2088  1716  1603  1578  1866  1810\n## [2,] 1246 1271 1156 1135 1156 1225 1301 1650 2214  2454  1938  1629  1776  2510\n## [3,] 1244 1235 1187 1030  944  978 1039 1153 1344  1303  1184  1299  1457  2308\n## [4,] 1314 1255  998  859  884  918  873  747 1009  1297  1332  1333  1479  2470\n## [5,] 1423 1241  887  901  892  707  712 1070 1440  1638  1641  1412  1781  2882\n## [6,] 1863 1350  918  883  700  700 1261 1945 1915  1928  1918  1800  2230  3187\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1849  2326  1596  1186  1118  1198  1183  1094   985   886  1602  2139\n## [2,]  2513  2332  1912  1361  1074  1070  1115  1085  1076  1230  1906  1696\n## [3,]  2616  2477  2191  1648  1259  1132  1090  1010  1003  1350  2138  1628\n## [4,]  3260  3198  2465  1807  1460  1258  1149   972   951  1509  1487  1491\n## [5,]  3622  3610  3435  2520  1605  1267  1192  1019  1316  1717  1537  2025\n## [6,]  3726  3651  3742  3216  2019  1421  1251  1125  1738  1966  1727  2234\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1511  1755  2200  2470  1555  1677  2148  2163  2061  2064  1985  1577\n## [2,]  1314  1493  2081  2229  1594  1898  2348  2029  1793  2051  2071  1670\n## [3,]  1902  1697  2160  2181  1519  1735  2427  2284  1865  1762  1962  1766\n## [4,]  1982  1933  2153  2228  1323  1829  2008  2251  1918  1857  1944  2165\n## [5,]  2367  2246  2015  1732  1535  2185  1723  1673  1859  2271  2435  2006\n## [6,]  2282  2113  2529  1546  2293  2156  1850  2072  2081  2026  1863  1567\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1680  1821  1698  1757  1837  1798  2103  2549  2459  2456  2008  2468\n## [2,]  1785  1704  1714  1712  2101  1942  2213  2438  2406  2421  2514  2760\n## [3,]  1641  1601  1542  1860  2115  1928  2163  2077  1771  2085  2452  2685\n## [4,]  2326  2009  1676  1669  1710  1909  1681  1809  1758  2125  2498  2038\n## [5,]  1778  1892  1823  1670  1866  2107  1620  1760  2172  2375  2149  2013\n## [6,]  1795  1866  1881  1803  1866  1742  1635  2080  2371  2287  2324  2391\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2667  2159  1796  1857  1926  1716  1678  2097  1639  1949  2383  1980\n## [2,]  2757  2579  1936  1843  1842  1841  1832  1826  1487  1778  2028  1818\n## [3,]  2673  2321  2038  1765  1694  1765  1747  1830  1838  1593  1901  1717\n## [4,]  2032  2332  2072  1836  2172  1978  1713  1849  1816  1669  1576  1407\n## [5,]  2112  2324  2539  2286  2254  2290  1777  1797  1634  2097  1866  1407\n## [6,]  2103  1920  2235  2403  2127  1853  1777  1797  1634  2097  1866  1614\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1673  1724  2010  2182  2190  2086  1861  1566  1898  1832  1918  2167\n## [2,]  1786  1784  1879  1911  2436  2204  1747  1454  1632  1794  1878  2032\n## [3,]  1563  1437  1525  1782  2212  1886  1744  1454  1632  1794  1878  2032\n## [4,]  1636  1829  1840  1782  2212  1886  1744  1590  1718  1803  1827  1949\n## [5,]  1636  1829  1840  1767  1674  1811  1994  1409  1470  1512  1957  1918\n## [6,]  1894  2131  1937  1895  2030  2091  1997  1426  1709  1636  1725  1634\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1768  1820  1934  1744  2073  1771  1707\n## [2,]  1768  1820  1934  1744  1716  1966  1873\n## [3,]  1749  1821  1744  1660  1576  1896  1851\n## [4,]  1480  1518  1515  1967  1706  1693  1798\n## [5,]  1452  1554  2137  2192  1496  1802  1790\n## [6,]  1653  1398  2207  2378  2023  1814  1656\n## \n## , , 7\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1318 1372 1324 1338 1383 1619 1868 2271 2197  1884  1620  1586  1925  2182\n## [2,] 1318 1372 1248 1233 1357 1336 1343 1686 2531  2585  2089  1937  2015  2760\n## [3,] 1327 1354 1267 1120 1005 1046 1134 1208 1398  1474  1348  1417  1455  2533\n## [4,] 1386 1399 1104  938  976  989 1095 1012 1218  1463  1427  1424  1619  2743\n## [5,] 1504 1322  973 1010  960  807  591  912 1249  1751  1739  1581  1872  3018\n## [6,] 2108 1390 1028  986  858  668 1523 2383 2210  1974  2039  1880  2463  3438\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1877  2681  1633  1361  1305  1241  1273  1231  1191  1184  1522  2377\n## [2,]  2719  2481  2175  1432  1175  1184  1238  1179  1156  1303  2172  1665\n## [3,]  2896  2767  2424  1811  1404  1219  1186  1135  1177  1373  2353  1627\n## [4,]  3585  3357  2545  2059  1570  1396  1225  1061   950  1710  1621  1626\n## [5,]  3939  3867  3723  2707  1707  1370  1350  1208  1208  2090  1312  2346\n## [6,]  4087  3874  3986  3524  2174  1500  1415  1348  1567  2469  1816  2279\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1722  1797  2202  2239  1625  1780  2396  2099  2344  2174  1848  1830\n## [2,]  1394  1892  1849  2119  1670  1984  2374  2222  1653  2178  2127  1737\n## [3,]  2032  1381  2425  2169  1562  1873  2507  2394  2218  1848  2035  1874\n## [4,]  2115  2123  2305  2324  1226  1993  2017  2457  1888  1952  2005  2350\n## [5,]  2491  2420  2121  1790  1553  2287  1843  1886  1883  2311  2574  2068\n## [6,]  2684  2239  2320  1481  2620  1956  1845  2195  2018  2092  1816  1630\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1533  1824  1693  1848  1899  1742  2413  2753  2602  2981  1949  2619\n## [2,]  1928  1861  1846  1736  2265  1940  2269  2425  2705  2716  2677  2977\n## [3,]  1727  1735  1588  1955  2163  1986  2291  2329  1895  2345  2800  2914\n## [4,]  2383  2173  1646  1861  1613  2012  1922  1935  1800  2097  2588  2047\n## [5,]  1881  2161  1770  1796  1900  2081  1680  1802  2199  2640  2311  2141\n## [6,]  1799  1941  2070  1960  1962  1975  1612  2234  2312  2300  2366  2544\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2912  2447  1906  1811  2109  1852  1725  2124  1716  2052  2439  2086\n## [2,]  2773  2819  1905  2007  1927  2062  1967  2083  1575  1883  2370  1908\n## [3,]  2931  2385  2157  2057  1724  2038  1586  1912  1906  1542  1821  1644\n## [4,]  2016  2653  2424  1837  2543  2179  1829  1932  1859  1625  1687  1584\n## [5,]  2144  2337  2860  2168  2335  2223  1657  1984  1669  2251  2015  1584\n## [6,]  2292  1955  2405  2697  2191  2222  1657  1984  1669  2251  2015  1617\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1795  1895  2036  2427  2226  2203  2009  1459  2107  1832  2068  2095\n## [2,]  1908  1801  1875  1840  2575  2264  1720  1454  1803  1848  1940  2218\n## [3,]  1629  1686  1621  1881  2240  1870  1685  1454  1803  1848  1940  2218\n## [4,]  1655  1770  1962  1881  2240  1870  1685  1472  1792  1778  1754  2105\n## [5,]  1655  1770  1962  1792  1788  1796  2444  1106  1696  1553  2261  1937\n## [6,]  2043  2077  1919  1936  2194  2040  2060  1429  1828  1675  1594  1778\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1719  1926  2236  1721  2040  1912  1753\n## [2,]  1719  1926  2236  1721  1778  1964  1715\n## [3,]  1568  1858  1754  1712  1537  1862  1890\n## [4,]  1493  1620  1713  2018  1583  1784  1802\n## [5,]  1422  1692  1954  2276  1539  1938  1585\n## [6,]  1583  1521  2389  2206  2269  1672  1637\n## \n## , , 8\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1412 1394 1445 1371 1454 1671 1929 2432 2313  1977  1834  1773  2173  2053\n## [2,] 1412 1394 1294 1263 1382 1416 1473 1878 2560  2673  2160  1811  2094  2717\n## [3,] 1372 1435 1330 1132 1076 1088 1196 1285 1531  1485  1428  1431  1725  2587\n## [4,] 1380 1393 1172 1022 1052 1064  993  957 1185  1500  1455  1454  1691  2865\n## [5,] 1588 1406 1041 1029 1031  808  756 1198 1447  1799  1861  1607  2056  3175\n## [6,] 2062 1584 1034 1059  839  727 1419 2113 2044  2031  2054  1991  2653  3539\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  2173  2465  1946  1403  1307  1403  1407  1279  1145  1155  1779  2189\n## [2,]  2870  2581  2235  1543  1270  1246  1268  1283  1285  1316  2134  1908\n## [3,]  2947  2770  2475  1856  1500  1310  1225  1153  1158  1611  2249  1724\n## [4,]  3585  3511  2702  2131  1731  1451  1351  1119  1079  1680  1703  1672\n## [5,]  3940  4064  3669  2818  1843  1493  1433  1248  1419  2061  1688  2169\n## [6,]  4042  4030  3999  3535  2313  1629  1429  1387  1898  2101  2118  2352\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1746  1752  2485  2700  1604  1841  2367  2204  2198  2242  1964  1722\n## [2,]  1366  1642  2174  2475  1711  2114  2605  2280  1961  2263  2122  1891\n## [3,]  2057  1842  2349  2311  1626  1899  2563  2468  1898  1886  2040  1827\n## [4,]  2106  1976  2351  2207  1484  1797  2201  2406  2085  2083  2084  2380\n## [5,]  2740  2355  2149  1681  1683  2279  1860  1968  1978  2392  2564  2084\n## [6,]  2477  2429  2368  1963  2235  2166  1964  2153  2092  2094  1939  1630\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1769  1825  1868  1863  1897  1956  2346  2625  2677  2665  2085  2741\n## [2,]  1918  1813  1839  1874  2228  2031  2388  2593  2850  2725  2817  3007\n## [3,]  1834  1772  1680  2028  2229  1964  2407  2426  2047  2384  2821  2931\n## [4,]  2506  2224  1858  1856  1779  1823  1963  1960  1900  2286  2628  2162\n## [5,]  1957  2142  2044  1810  1999  2038  1774  1861  2187  2505  2284  2189\n## [6,]  1801  1956  2050  1895  1948  1935  1770  2205  2367  2481  2386  2605\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2926  2511  2102  1960  2096  1942  1772  2162  1758  2006  2476  2195\n## [2,]  2950  2677  2325  2102  1964  2131  1977  2079  1559  1973  2229  2011\n## [3,]  2984  2604  2235  2055  1812  1996  1744  1980  1857  1740  1984  1798\n## [4,]  2116  2613  2279  1974  2260  2268  1807  1993  1916  1713  1691  1515\n## [5,]  2146  2526  2706  2472  2441  2412  1955  1925  1798  2126  1975  1515\n## [6,]  2291  2102  2500  2582  2298  2064  1955  1925  1798  2126  1975  1714\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1831  1911  2060  2307  2308  2268  1876  1717  2042  1854  2076  2137\n## [2,]  1860  1934  1887  1902  2428  2438  1733  1562  1807  1868  2019  2064\n## [3,]  1630  1571  1666  1891  2216  1942  1798  1562  1807  1868  2019  2064\n## [4,]  1749  1849  1920  1891  2216  1942  1798  1539  1722  1788  1879  2041\n## [5,]  1749  1849  1920  1824  1707  1929  2184  1502  1370  1688  2069  1960\n## [6,]  2026  2112  1967  2005  2113  2306  2022  1699  1742  1769  1813  1854\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  1694  1868  2024  1818  2018  1864  1946\n## [2,]  1694  1868  2024  1818  1790  1931  1953\n## [3,]  1837  1783  1862  1739  1682  1746  1894\n## [4,]  1620  1607  1680  1926  1647  1846  1854\n## [5,]  1548  1698  2210  2162  1637  1869  1679\n## [6,]  1787  1533  2376  2222  2003  1912  1755\n## \n## , , 9\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1909 1893 1870 1809 1834 1967 1998 2006 1730  1550  1696  1754  1978  1788\n## [2,] 1909 1893 1742 1742 1818 1865 1990 2189 2252  2194  1940  1885  2054  2223\n## [3,] 1856 1882 1761 1668 1603 1605 1675 1833 2036  2094  2033  2083  2098  2244\n## [4,] 1908 1849 1679 1559 1533 1538 1469 1404 1612  2009  2050  2091  2134  2229\n## [5,] 2054 1851 1587 1568 1497 1185  928  913 1108  1532  1976  2131  2321  2226\n## [6,] 2588 2151 1665 1508 1219  900 1004 1328 1568  1577  1647  2057  2504  2082\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]  1584  2019  2279  2168  2086  2095  2080  2036  1950  1803  1687  1695\n## [2,]  2037  2000  2217  2160  1997  1959  1956  1895  1844  1777  1760  1584\n## [3,]  1911  1791  2130  2346  2249  2050  1929  1831  1780  1747  1726  1415\n## [4,]  1875  1692  1831  2186  2433  2312  2056  1735  1493  1414  1303  1273\n## [5,]  1777  1642  1701  2111  2347  2329  2189  1908  1516  1371  1220  1353\n## [6,]  1596  1594  1631  1942  2329  2379  2279  2151  1900  1720  1534  1655\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1581  1630  1687  2141  2019  1978  2153  2314  2345  2077  1961  1870\n## [2,]  1513  2000  2112  2465  1958  1924  2103  2029  1992  2082  1964  1726\n## [3,]  1686  1609  2043  2398  1857  1863  2132  1926  1939  2156  2089  1906\n## [4,]  1679  1734  2225  2376  1765  1947  2030  1862  1637  1916  2276  2344\n## [5,]  1708  1807  2121  2133  1764  2301  1733  1573  1747  2408  2886  2476\n## [6,]  1911  1980  2384  1798  1876  1955  1642  1790  2202  2453  2443  2018\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1976  2117  2086  2009  2063  1994  2353  2468  2635  2651  2375  2556\n## [2,]  1835  2139  2261  2004  2174  1985  2145  2540  3014  2929  2730  2865\n## [3,]  1664  1697  2153  2061  2120  2165  2145  2427  2581  2638  2795  2660\n## [4,]  2209  1961  2043  1854  1840  2049  1936  2202  2110  2286  2362  2143\n## [5,]  1935  1682  1786  1807  1918  2176  2159  2269  2195  2266  2239  2193\n## [6,]  1775  1966  2067  2012  2381  2448  2216  2347  2430  2430  2495  2429\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  2587  2065  1332  1106  1370  1454  1830  2025  1959  2113  2266  2046\n## [2,]  2983  2730  1735  1174  1298  1531  2064  2154  1958  2042  2153  1914\n## [3,]  2498  2520  2133  1381  1239  1494  1808  2077  2132  2050  2175  2010\n## [4,]  2135  2292  2308  1610  1270  1386  1446  1778  1989  1998  1952  1990\n## [5,]  2239  2307  2330  2017  1618  1232  1135  1481  1704  2258  2182  1990\n## [6,]  2309  2227  2296  2356  1934  1372  1135  1481  1704  2258  2182  2049\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1600  1594  1784  1854  1849  2143  2227  2079  2055  2006  2024  2189\n## [2,]  1676  1703  1668  1775  2124  2265  2141  2043  2022  2003  2116  2352\n## [3,]  1947  1918  1890  2031  2403  2241  2077  2043  2022  2003  2116  2352\n## [4,]  2202  2284  2188  2031  2403  2241  2077  1887  1886  1966  2103  2250\n## [5,]  2202  2284  2188  2085  2112  2250  2214  1558  1410  1807  2126  2086\n## [6,]  2145  2119  2019  2012  2006  2052  2184  1826  1878  1935  1939  1875\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  2192  2409  2448  2288  2507  2349  2311\n## [2,]  2192  2409  2448  2288  2330  2589  2409\n## [3,]  2303  2215  2041  1864  2130  2585  2343\n## [4,]  1970  1995  1911  2019  2000  2085  2116\n## [5,]  1952  2167  2746  2542  2156  2304  2167\n## [6,]  1868  1990  2826  2773  2373  2208  2178\n## \n## , , 10\n## \n##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n## [1,] 1480 1488 1448 1391 1399 1439 1500 1418 1118  1129  1194  1196  1329  1207\n## [2,] 1480 1488 1411 1362 1404 1457 1524 1705 1699  1508  1438  1516  1524  1417\n## [3,] 1469 1495 1384 1305 1276 1294 1363 1502 1696  1853  1784  1709  1639  1443\n## [4,] 1483 1444 1331 1270 1258 1278 1250 1186 1353  1675  1802  1771  1624  1419\n## [5,] 1602 1485 1308 1293 1249 1011  698  600  720  1149  1613  1787  1682  1344\n## [6,] 1925 1700 1348 1263 1025  662  669  857 1100  1082  1161  1473  1732  1237\n##      [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26]\n## [1,]   967  1219  1648  1758  1693  1707  1708  1682  1574  1444  1168  1107\n## [2,]  1176  1180  1553  1760  1696  1647  1687  1609  1517  1366  1247  1223\n## [3,]  1082  1017  1325  1785  1925  1795  1625  1540  1442  1296  1233   989\n## [4,]  1006   831  1022  1517  1973  2025  1771  1460  1152   968   842   737\n## [5,]   906   780   888  1302  1806  1975  1869  1597  1061   903   796   796\n## [6,]   783   735   765  1068  1622  1921  1914  1711  1286  1166  1038  1002\n##      [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38]\n## [1,]  1197  1371  1348  1813  1784  1554  1666  1832  1869  1615  1513  1524\n## [2,]  1164  1694  1944  2578  1904  1628  1507  1426  1576  1604  1460  1288\n## [3,]  1116  1266  1580  1960  1555  1542  1636  1344  1440  1709  1716  1720\n## [4,]  1070  1179  1772  2129  1641  1746  1638  1317  1138  1466  1891  1954\n## [5,]  1035  1191  1759  2042  1479  1958  1379  1139  1276  2058  2795  2263\n## [6,]  1151  1411  2318  2014  1456  1641  1171  1317  1878  2246  2229  1803\n##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50]\n## [1,]  1676  1897  1839  1746  1938  1834  1997  1900  1911  2084  1844  1859\n## [2,]  1403  1894  2222  1769  1952  1768  1752  1898  2240  2094  1965  2159\n## [3,]  1473  1427  1895  1624  1782  1838  1541  1656  1951  1920  1826  1863\n## [4,]  1631  1315  1726  1651  1612  1829  1597  1779  1719  1817  1846  1722\n## [5,]  1514  1261  1442  1531  1644  1984  2042  1953  1814  1855  1826  1836\n## [6,]  1552  1746  1849  1825  2226  2318  2029  2183  2255  1993  1913  1926\n##      [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n## [1,]  1801  1435   821   613   811  1012  1657  1674  1638  1808  1789  1556\n## [2,]  2256  1933  1138   682   757  1033  1753  1802  1710  1783  1756  1467\n## [3,]  1830  1766  1574   936   724   971  1456  1813  1934  1876  1982  1869\n## [4,]  1696  1680  1837  1220   727   833   949  1362  1823  1771  1810  1848\n## [5,]  2060  1874  1744  1530  1115   746   692  1057  1369  1878  1919  1848\n## [6,]  1903  1872  1928  1790  1474   860   692  1057  1369  1878  1919  1892\n##      [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74]\n## [1,]  1109  1173  1383  1471  1400  1760  2154  2059  1864  1707  1748  1814\n## [2,]  1322  1417  1332  1466  1815  2213  2112  2035  1936  1818  1871  2119\n## [3,]  1822  1868  1696  1806  2438  2347  2042  2035  1936  1818  1871  2119\n## [4,]  2092  2214  2123  1806  2438  2347  2042  1855  1795  1812  1876  2060\n## [5,]  2092  2214  2123  1972  1865  1921  1924  1386  1206  1498  1880  1915\n## [6,]  2027  1868  1807  1722  1528  1570  1869  1689  1625  1704  1720  1563\n##      [,75] [,76] [,77] [,78] [,79] [,80] [,81]\n## [1,]  2026  2274  2359  2254  2495  2443  2402\n## [2,]  2026  2274  2359  2254  2278  2625  2568\n## [3,]  2199  2084  1830  1685  1920  2164  2106\n## [4,]  1878  1942  1804  1891  1908  2030  1852\n## [5,]  1824  2048  2751  2488  2102  2182  2015\n## [6,]  1647  1812  2697  2733  2209  2019  2068"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#agregar-un-nuevo-atributo",
    "href": "posts/2022-02-17-rasters-con-stars.html#agregar-un-nuevo-atributo",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para agregar un nuevo atributo en función de los que ya existen.\n\nnames(im1) &lt;- \"Sentinel2\"\nim2 &lt;- im1 |&gt; \n  mutate(band2 = 2 * Sentinel2)\nim2\n## stars object with 3 dimensions and 2 attributes\n## attribute(s):\n##            Min. 1st Qu. Median     Mean 3rd Qu.  Max.\n## Sentinel2     6     913   1552 1501.178 2010.75  5041\n## band2        12    1826   3104 3002.356 4021.50 10082\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12\n\nAhora ya tenemos dos atributos."
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#para-seleccionar-ciertos-atributos",
    "href": "posts/2022-02-17-rasters-con-stars.html#para-seleccionar-ciertos-atributos",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para seleccionar algunos atributos se usa select.\n\nim2 |&gt; \n  select(band2)\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##        Min. 1st Qu. Median     Mean 3rd Qu.  Max.\n## band2    12    1826   3104 3002.356  4021.5 10082\n## dimension(s):\n##      from  to   offset        delta refsys point     values x/y\n## x       1 103 -101.235  0.000179663 WGS 84 FALSE       NULL [x]\n## y       1  81  19.6582 -0.000179663 WGS 84 FALSE       NULL [y]\n## band    1  10       NA           NA     NA    NA B2,...,B12"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#cálculo-de-índices",
    "href": "posts/2022-02-17-rasters-con-stars.html#cálculo-de-índices",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "En algunos casos estaremos más interesados en calcular índices que resalten algunas características de la superficie terrestre. Por ejemplo, algún índice de vegetación. Esto se puede realizar al seleccionar las bandas de interés y aplicar la fórmula.\n\nNIR &lt;- im1[,,,8]\nR &lt;- im1 [,,,4]\n\n# Tidyverse-esque\n# Si no se agrega drop = F, se elimina la tercera dimensión y luego ya no permite concatenar esta banda con el resto de la imagen.\nNIR &lt;- im1 |&gt;\n  slice(band, 8, drop = F)\nR &lt;- im1 |&gt;\n  slice(band, 4, drop = F)\n\nNDVI &lt;- (NIR - R) / (NIR + R)\n\nplot(NDVI)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#agregar-bandas-a-un-raster",
    "href": "posts/2022-02-17-rasters-con-stars.html#agregar-bandas-a-un-raster",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para agregar una banda a un raster se utiliza la función c.\n\nim1_cNDVI &lt;- c(im1, \n               NDVI,\n               along = 3)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#transformación-de-datos-stars-a-sf",
    "href": "posts/2022-02-17-rasters-con-stars.html#transformación-de-datos-stars-a-sf",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para transformar un vector a raster se utiliza la función st_rasterize. Para ello, hay que determinar la resolución a la que se quiere rasterizar esta información. Utilizamos los valores de resolución que tiene el objeto im1. Recordemos que estos valores están en las unidades del CRS de la capa. En este caso, el CRS está en coordenadas geográficas, por eso se utilizarán valores en grados.\n\nroi_rast &lt;- st_rasterize(roi[\"id\"], dx = 0.000179663, dy = -0.000179663)\nplot(roi_rast)\n## Warning in plot.stars(roi_rast): breaks=\"quantile\" leads to a single class;\n## maybe try breaks=\"equal\" instead?"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#transformación-de-raster-a-vector",
    "href": "posts/2022-02-17-rasters-con-stars.html#transformación-de-raster-a-vector",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para transformar de raster a un vector de puntos se puede utilizar la función st_as_sf, utilizando el argumento de as_points. Además, si se desean obtener los datos en formato largo en lugar de ancho se puede utilizar el argumento long.\n\nst_as_sf(im1, \n         as_points = TRUE, \n         merge = FALSE)\n## Simple feature collection with 8343 features and 10 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -101.2352 ymin: 19.64373 xmax: -101.2169 ymax: 19.6581\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##     B2  B3   B4   B5   B6   B7   B8  B8A  B11  B12                  geometry\n## 1  434 662  939 1078 1200 1246 1318 1412 1909 1480 POINT (-101.2352 19.6581)\n## 2  434 662  939 1078 1200 1246 1318 1412 1909 1480  POINT (-101.235 19.6581)\n## 3  443 685  960 1096 1179 1244 1327 1372 1856 1469 POINT (-101.2348 19.6581)\n## 4  488 729 1028 1168 1237 1314 1386 1380 1908 1483 POINT (-101.2347 19.6581)\n## 5  560 803 1091 1271 1313 1423 1504 1588 2054 1602 POINT (-101.2345 19.6581)\n## 6  594 889 1203 1345 1624 1863 2108 2062 2588 1925 POINT (-101.2343 19.6581)\n## 7  461 693  980 1257 1480 1604 1709 1862 2636 1926 POINT (-101.2341 19.6581)\n## 8  420 645  907 1067 1152 1321 1561 1701 2432 1814 POINT (-101.2339 19.6581)\n## 9  436 635  920 1047 1187 1349 1544 1679 2429 1796 POINT (-101.2338 19.6581)\n## 10 345 528  745  990 1185 1381 1333 1621 2329 1695 POINT (-101.2336 19.6581)\n\nUtilizando la misma función se puede convertir de raster a vector de polígonos. En este caso, se indica como argumentos que no se desea obtener una capa de puntos y en merge se puede indicar si se desea fusionar los polígonos con un mismo valor o no.\n\nim1_poly &lt;- st_as_sf(im1, \n                     as_points = F, \n                     merge = T)\nplot(im1_poly)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#reproyección-de-rasters",
    "href": "posts/2022-02-17-rasters-con-stars.html#reproyección-de-rasters",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para reproyectar un raster se utiliza la función st_transform. Al igual que en sf se necesita indicar el CRS objetivo ya sea mediante el código EPSG o obteniendo dicha clave con st_crs. Este tipo de reproyección no presenta pérdida de información debido a las diferencias entre proyecciones. Por lo tanto, los pixeles pueden no ser de dimensiones homogeneas en toda la imagen. Ve la siguiente función para hacer reproyecciones más clásicas.\n\nim1_utm &lt;- st_transform(im1, \n                        32614)\nim1_utm\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##            Min. 1st Qu. Median     Mean 3rd Qu. Max.\n## Sentinel2     6     913   1552 1501.178 2010.75 5041\n## dimension(s):\n##      from  to offset delta                refsys point\n## x       1 103     NA    NA WGS 84 / UTM zone 14N FALSE\n## y       1  81     NA    NA WGS 84 / UTM zone 14N FALSE\n## band    1  10     NA    NA                    NA    NA\n##                            values x/y\n## x      [103x81] 265619,...,267562 [x]\n## y    [103x81] 2173570,...,2175186 [y]\n## band                   B2,...,B12    \n## curvilinear grid"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#resampling",
    "href": "posts/2022-02-17-rasters-con-stars.html#resampling",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para cambiar la resolución de un raster o reproyectar con pérdida de información se utiliza la función st_warp. Esta función permite definir el tamaño de celda objetivo mediante el argumento cellsize, así como el CRS objetivo. Esta función hace la reproyección donde todos los tamaños de celda son iguales y quizás es con la que cualquier usuario esté más familiarizado.\n\nim1_utm_20m &lt;- st_warp(im1, \n                       crs = st_crs(im1),\n                       cellsize = c(20, 20))\nim1_utm_20m\n## stars object with 3 dimensions and 1 attribute\n## attribute(s):\n##            Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\n## Sentinel2    NA      NA     NA  NaN      NA   NA   10\n## dimension(s):\n##      from to   offset delta refsys point     values x/y\n## x       1  1 -101.235    20 WGS 84    NA       NULL [x]\n## y       1  1  19.6582   -20 WGS 84    NA       NULL [y]\n## band    1 10       NA    NA     NA    NA B2,...,B12"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#crear-mosaicos-a-partir-de-varios-rasters",
    "href": "posts/2022-02-17-rasters-con-stars.html#crear-mosaicos-a-partir-de-varios-rasters",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para crear un mosaico a partir de dos o más imágenes se utiliza la función st_mosaic.\n\nim_mosaic &lt;- st_mosaic(im1_sub2, im1_sub3)\nplot(im_mosaic)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#reclasificar",
    "href": "posts/2022-02-17-rasters-con-stars.html#reclasificar",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para reclasificar un raster se puede realizar con la función cut, indicando los intervalos para las clases.\n\nreclass_NDVI &lt;- cut(NDVI,\n    breaks = c(-1, 0, 0.2, 0.5, 1),\n    labels = F)\nplot(reclass_NDVI)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#enmascarar",
    "href": "posts/2022-02-17-rasters-con-stars.html#enmascarar",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para enmascarar algún raster utilizando otro. De igual manera se pueden emascarar los valores que no cumplan con algún criterio de interés.\n\nim_mask &lt;- reclass_NDVI\nim_mask[im_mask != 2] &lt;- NA\n\nreclass_NDVI2 &lt;- reclass_NDVI\nreclass_NDVI2[is.na(im_mask)] &lt;- NA\nplot(reclass_NDVI2)\n## Warning in plot.stars(reclass_NDVI2): breaks=\"quantile\" leads to a single class;\n## maybe try breaks=\"equal\" instead?"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#cálculo-de-métricas-por-banda",
    "href": "posts/2022-02-17-rasters-con-stars.html#cálculo-de-métricas-por-banda",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para calcular métrias por banda se puede utilizar la función pull para obtener el atributo del que se desea obtener la información. En este caso la imagen solo cuenta con un atributo, así que seleccionamos esa entrada. Después, podemos utilizar la función apply para calcular la media sobre la dimensión 3 del arreglo. Otra forma de acceder a los datos en formato de arreglo es con [[]].\n\n# Opción con pull\nim1 |&gt;\n  pull(1) |&gt;\n  apply(3, mean)\n##  [1]  527.6186  772.9070  935.5342 1230.8505 1700.1954 1874.5490 2004.2371\n##  [8] 2076.1721 2236.3476 1653.3689\n# Opción con doble corchete\nim1[[1]] |&gt;\n  apply(3, mean)\n##  [1]  527.6186  772.9070  935.5342 1230.8505 1700.1954 1874.5490 2004.2371\n##  [8] 2076.1721 2236.3476 1653.3689"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#aplicar-una-función-sobre-todos-los-pixeles",
    "href": "posts/2022-02-17-rasters-con-stars.html#aplicar-una-función-sobre-todos-los-pixeles",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Si se desea aplicar una función sobre todas las bandas de una imagen por pixel, se puede utilizar la función st_apply para facilitar el cálculo de variables. Esto es muy utilizado para análisis con series de tiempo y obtener por ejemplo la media de cada pixel.\n\nmean_allBands &lt;- st_apply(im1, \n         1:2,\n         mean)\nmean_allBands\n## stars object with 2 dimensions and 1 attribute\n## attribute(s):\n##        Min. 1st Qu. Median     Mean 3rd Qu.   Max.\n## mean  225.8    1253 1502.2 1501.178 1716.45 4223.5\n## dimension(s):\n##   from  to   offset        delta refsys point values x/y\n## x    1 103 -101.235  0.000179663 WGS 84 FALSE   NULL [x]\n## y    1  81  19.6582 -0.000179663 WGS 84 FALSE   NULL [y]\nplot(mean_allBands)"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#tabla-de-frecuencias",
    "href": "posts/2022-02-17-rasters-con-stars.html#tabla-de-frecuencias",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "Para obtener una tabla de las frecuencias por el valor de pixel se utiliza la función table.\n\ntable(reclass_NDVI)\n## reclass_NDVI\n##    1    2    3    4 \n##   64 2364 5527  388"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#ggplot2",
    "href": "posts/2022-02-17-rasters-con-stars.html#ggplot2",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "En ggplot se puede determinar directamente el color y relleno de cada capa vectorial. En este ejemplo se carga la biblioteca viridis para usar dicha escala de color.\n\nlibrary(viridis)\n## Loading required package: viridisLite\n## Loading required package: viridisLite\nggplot() + \n  geom_stars(data = im1) +\n  coord_equal() +\n  facet_wrap(~band) +\n  theme_void() +\n  scale_fill_viridis() +\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))"
  },
  {
    "objectID": "posts/2022-02-17-rasters-con-stars.html#tmap",
    "href": "posts/2022-02-17-rasters-con-stars.html#tmap",
    "title": "Información espacial en formato raster en R",
    "section": "",
    "text": "La opción de tmap require de utilizar algún atributo de la información para determinar el color de relleno de cada polígono de acuerdo a los valores de ese atributo. Es similar a ggplot utilizando la opción de aes. Podemos ver algunas de las paletas que ya vienen pre hechas tanto para ggplot como para tmap con tmaptools::palette_explorer()\n\nlibrary(tmap)\n\n# Cargar shapr\ntm_shape(im1) +\n  # Elegir forma de visualización\n  tm_raster()"
  },
  {
    "objectID": "posts/2022-02-10-tidymodels-with-rasters.html",
    "href": "posts/2022-02-10-tidymodels-with-rasters.html",
    "title": "Working with tidymodels and rasters in R",
    "section": "",
    "text": "Tidymodels is a package designed to make different types of models in a tidyverse-esque way. This package is particularly useful for implementing machine learning (ML) algorithms, as well as to divide your data into, training and test sets, etc. My particular personal interest was using this package to train models and then use those models to make predictions using raster data.\nFor this procedure you should use additional packages, beside tidymodels. sf contains tools for working with spatial information saved in vectors. yardstick is a package that contains several functions to get evaluation metrics for the models. raster is a package that is going to be superseded by terra to work with rasters. Additionally, fasterize is a package useful to make transformations from vector to raster and finally, doParallel will help to make parallel processing in R.\nlibrary(tidymodels)\nlibrary(sf)\nlibrary(yardstick)\nlibrary(raster)\nlibrary(fasterize)\nlibrary(doParallel)\n\ntidymodels_prefer()\n\n\nThe first thing is to load the labeled data from which we will train and test our model. In this example, we are going to work with spatial information, rasters and vectors. So, we generated a dataset of disturbance and non-disturbance areas using visual interpretation. For the sake of this model, we are going to take the data as spatially independent, however, keep in mind that there are other types of models that can take into account spatial dependency. Here we will use BFAST components and type of forest (tropical dry forest, TDF or temperate forest, TF) as independent variables, while the only dependent variable will be if an area correspnods to disturbance or not. The main idea of the script is to compare a baseline model, based on a magnitude threshold of 0.2 vs a more complex model that might include several other indepdendent variables.\n# Load raster and set names\nim1 &lt;- stack(\"bfast_components.tif\")\nnames(im1) &lt;- c(\"breakpoint\",\"magnitude\", \"error\", \"history\", \n                \"r.squared\", \"amplitude\", \"trend\", \"Naperc\")\n\n# Choose subset of bands\nim1 &lt;- im1[[c(2,4:8)]]\n\n# Load a forest type layer\nforests_shp&lt;- st_read(\"Forest_type.shp\")\n\n# Reproject\nforests_shp &lt;- forests_shp %&gt;%\n  st_transform(st_crs(im1[[1]]))\n\n# Rasterize\nforests_im &lt;- fasterize(forests_shp, \n                        raster = raster(im1[[1]]),\n                        field = \"ID\",\n                        fun = \"last\")\n# Set TF as 0\nforests_im[forests_im==2] &lt;- 0\n\n# Stack all the independent variables as a multiband raster\nim1 &lt;- stack(forests_im, im1)\nnames(im1) &lt;- c(\"Forest\", \"Magnitude\", \"History\", \"R2\", \"Ampl\", \"Trend\", \"NAperc\")\n\n# plot(im1)\n\n# Read verified areas\ntf &lt;- st_read(\"238pts_Verified.shp\")\n\n# Make some recoding and eliminate unused variables\nsample_extr &lt;- tf %&gt;%\n  # Remove geometry, i.e., pass it to simple table\n  st_set_geometry(NULL) %&gt;%\n  # Convert forest type as a numeric variable with 0 and 1\n  mutate_at(vars(Forest), function(x) case_when(x == \"Temperate_forest\" ~ 0,\n                                                x == \"Tropical_dry_forest\" ~ 1)) %&gt;%\n  # Convert change, the dependent variable as factor                                              \n  mutate_at(vars(Change), function(x) as.factor(x)) %&gt;%\n  # Eliminate unused variables\n  dplyr::select(-c(DateChange, Obs, cell, x, y, Breakp))\n\n# Take a glimpse of the data\n# glimpse(sample_extr)\n\n\n\nAfter doing that short procedure you need to divide the complete dataset into training and test sets. This can easily be done using tidymodels. Additionally, I decided to use a separate vfold-cv-set (cross-validation set) to test the performance of different model architectures and obtain a standard error of the mean accuracy to decide which architecture could be considered as the best. After deciding the best model architecture, the the selected model will be trained and tested on the training and test datasets, respectively.\n# Set seed to make everything reproducible\nset.seed(15)\nsample_split &lt;- initial_split(sample_extr, \n                              prop = 0.70,\n                              # Stratification; save same proportions for some variable in train and test\n                              strata = Change)\n\n# Create training and test set\nbfast_training &lt;- sample_split %&gt;%\n  training()\n\nbfast_test &lt;- sample_split %&gt;%\n  testing()\n\n# Ensure reproducibility\nset.seed(5)\nbfast_folds &lt;- vfold_cv(bfast_training,\n                        v = 3,\n                        repeats = 40,\n                        strata = Change)\nOnce you got the training and test sets, as well as the vfold-cv-set the next step will be to specify the models you are going to train. This can be done by specifying different recipes.\n# Specify algorithm to be used, engine and mode (classification or regression)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"randomForest\") %&gt;%\n  set_mode(\"classification\")\n\n# Recipes\n# Model with all predictors, will be the template recipe to be used in the other recipes\nbfast_recipe &lt;- recipe(Change ~ ., \n                       data = bfast_training) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) \n\n# Baseline model\nbaseline &lt;- bfast_recipe %&gt;% \n  step_mutate(base_line = ifelse(Magnitude &lt;= -0.2, 1, 0)) %&gt;%\n  step_rm(c(Forest, R2, Ampl, NAperc, History, Trend, Magnitude))\n\n# Random forests recipe\n# Model with Magnitude, Trend,  History, NAperc, Ampl and R2, remove Forest\npred6_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest)) \n\n# Model with Magnitude, Trend,  History, NAperc and Ampl, remove Forest and R2\npred5_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2)) \n\n# Model with Magnitude, Trend,  History and NAperc\npred4_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc)) \n\n# Model with Magnitude, Trend and History\npred3_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl)) \n\n# Model with only Magnitude and Trend\npred2_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl, History)) \n\n# Model with only Magnitude\npred1_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl, History, Trend))\n\n# Create a list of the models that area going to be trained\npreprocessing &lt;- \n  list(base = baseline,\n       pred1 = pred1_rec_rf,\n       pred2 = pred2_rec_rf,\n       pred3 = pred3_rec_rf,\n       pred4 = pred4_rec_rf,\n       pred5 = pred5_rec_rf,\n       pred6 = pred6_rec_rf,\n       all = bfast_recipe\n  )\n\n# Create a workflow set\nrf_models &lt;- workflow_set(preproc = preprocessing, \n                          models = list(rf = rf_model), \n                          cross = FALSE)\nOnce all the recipes and workflow have been defined the next step is to fit or train the models. Remember we are going to first evaluate the models on the vfold-cv-set, then train it using the training dataset and evaluate it on the test set.\n# This is for running all variations of the model\n# Define the number of nodes to be used for the training procedure. I recommend using 1 less than the total number of cores available in your computer\ncl &lt;- makePSOCKcluster(5)\nregisterDoParallel(cl)\n\n# Fit all models using the vfold-cv-dataset\nrf_results &lt;- \n  rf_models %&gt;% \n  # First argument tells type of fitting to be made\n  # Fit resample takes vfolds of training and trains / tests\n  workflow_map(\"fit_resamples\", \n               # Options to `workflow_map()`: \n               seed = 10, verbose = TRUE,\n               # Options to `fit_resamples()`: \n               resamples = bfast_folds)\n\n# Collect metrics from the workflow and write the results to disk\nrf_results %&gt;%\n  collect_metrics() %&gt;% \n  # filter(.metric == \"accuracy\") %&gt;%\n  write.csv(\"Results/rf_modelcomp_allForest.csv\")\nAfter fitting all the models, you should choose the best architecture. In this case, I chose the one with non-significant difference in accuracy with the highest achieved one and tht included less independent variables. You can make a plot to see the results in a graphic way.\n# Choose best model according to accuracy\nautoplot(\n  rf_results,\n  rank_metric = \"accuracy\",  # &lt;- how to order models\n  metric = \"accuracy\",       # &lt;- which metric to visualize\n  select_best = TRUE     # &lt;- one point per workflow\n)\n\nprint(\"Select simplest best model\")\n# Select model architecture with highest accuracy\nrf_results %&gt;% \n  rank_results(rank_metric = \"accuracy\", select_best = T) %&gt;% \n  filter(.metric == \"accuracy\") \nAfter evaluating the results obtained in the vfold-cv-dataset, I chose the best model: “pred3_rf”. So we are using that name as the model name to do the rest of the process. This names are automatically created when training the model.\n# Best model name\nrf_best_model_id &lt;- \"pred3_rf\"\n\n# Pull the best model according to its id from workflow\n# Then choose the model with highest accuracy parameters\n# according to accuracy. This contains only the model that obtained the \n# highest accuracy in the vfold-cv-sets\nrf_baseline_results &lt;- rf_results %&gt;% \n  extract_workflow_set_result(\"base_rf\") %&gt;%\n  select_best(metric = \"accuracy\")\n\nrf_truebest_results &lt;- rf_results %&gt;% \n  extract_workflow_set_result(rf_best_model_id) %&gt;%\n  select_best(metric = \"accuracy\") \n\n# Make last fit (i.e., train model from scratch using complete training data\n# and then validate over validation data)\n# Select best model using the previous object (bfast_best_results)\n# These object contained the trained and verified model (using training and test sets)\nrf_baseline_last_fit &lt;- rf_results %&gt;% \n  extract_workflow(\"base_rf\") %&gt;% \n  finalize_workflow(rf_baseline_results) %&gt;% \n  last_fit(split = sample_split)\n\nrf_truebest_last_fit &lt;- rf_results %&gt;% \n  extract_workflow(rf_best_model_id) %&gt;% \n  finalize_workflow(rf_truebest_results) %&gt;% \n  last_fit(split = sample_split)\n\n# Get trained models for prediction\n# Fit not last fit, aka, withouth predictions (only trained model).\n# This are going to be used to make the predictions over the rasters\nrf_baseline_fit_notlast &lt;- rf_results %&gt;% \n  extract_workflow(\"base_rf\") %&gt;% \n  finalize_workflow(rf_baseline_results) %&gt;% \n  fit(bfast_training)\n\nrf_truebest_fit_notlast &lt;- rf_results %&gt;% \n  extract_workflow(rf_best_model_id) %&gt;% \n  finalize_workflow(rf_truebest_results) %&gt;% \n  fit(bfast_training)\nNow we have the trained models (*_notlast) and the trained and evaluated models (*_last_fit) on the test set. So the next step is to collect the predictions from the trained and evaluated models to calculate different evaluation metrics.\n# Collect predicions\nrf_baseline_wkfl_preds &lt;- rf_baseline_last_fit %&gt;%\n  collect_predictions()\nrf_truebest_wkfl_preds &lt;- rf_truebest_last_fit %&gt;%\n  collect_predictions()\n\n# Write predictions vs truth\nrf_baseline_wkfl_preds %&gt;%\n  select(Change, .pred_class) %&gt;%\n  write.csv(\"Results/PredictionsTruthRFBaseline.csv\")\nrf_truebest_wkfl_preds %&gt;%\n  select(Change, .pred_class) %&gt;%\n  write.csv(\"Results/PredictionsTruthRFBest.csv\")\n\n# Set the metrics to calculate\nbfast_metrics &lt;- metric_set(accuracy, \n                            roc_auc, \n                            precision, \n                            recall,\n                            f_meas)\n\n# Calculate metrics and write them to disk\nrf_baseline_wkfl_preds %&gt;%\n  bfast_metrics(truth = Change, \n                estimate = .pred_class,\n                event_level = \"second\", #To focus evaluation on 1\n                .pred_1) %&gt;%\n  write.csv(\"Results/EvalMetricsRFBaseline.csv\")\nrf_truebest_wkfl_preds %&gt;%\n  bfast_metrics(truth = Change, \n                estimate = .pred_class,\n                event_level = \"second\", #To focus evaluation on 1\n                .pred_1) %&gt;%\n  write.csv(\"Results/EvalMetricsRFBest.csv\")\nAdditionally, you might be interested in obtaining the ROC curves of each model, so you can do it using the following script. In this step, we will create a data frame containing the ROC curves, which can afterwards used to construct a plot showing this results.\n# ROC plots\nrf_baseline_roc &lt;- rf_baseline_wkfl_preds %&gt;%\n  roc_curve(truth = Change, \n            event_level = \"second\",\n            .pred_1)  %&gt;%\n  add_column(Model = \"Baseline\")\nrf_truebest_roc &lt;-rf_truebest_wkfl_preds %&gt;%\n  roc_curve(truth = Change, \n            event_level = \"second\",\n            .pred_1) %&gt;%\n  add_column(Model = rf_best_model_id)\n\nplotter_rf &lt;- bind_rows(rf_baseline_roc, rf_truebest_roc) %&gt;%\n  mutate(\"1 - specificity\" = 1-specificity) \nThe last step of the workflow is to spatialize the model, i.e., apply the model using the rasters to obtain a final disturbance / non-disturbance map.\n# Use model to make raster\n# Function for applying model to rasters and obtain a raster as results\nfun&lt;-function(...){\n  p&lt;-predict(...)\n  return(as.matrix(as.numeric(p[, 1, drop=T]))) \n}\n\n# Make prediction\nrf_baseline_pred_im &lt;- raster::predict(im1, \n                              model = rf_baseline_fit_notlast, \n                              type=\"class\", \n                              fun=fun)\n# Write raster\nwriteRaster(rf_baseline_pred_im,\n            paste0(\"ClassRaster/RFBaselineClass_\",\"pred_AllForest.tif\"),\n            format = \"GTiff\",\n            overwrite = T)\n\n# Make prediction\nrf_truebest_pred_im &lt;- raster::predict(im1, \n                              model = rf_truebest_fit_notlast, \n                              type=\"class\", \n                              fun=fun)\n# Write raster\nwriteRaster(rf_truebest_pred_im,\n            paste0(\"ClassRaster/RFTruebestClass_\",\"pred_AllForest.tif\"),\n            format = \"GTiff\",\n            overwrite = T)"
  },
  {
    "objectID": "posts/2022-02-10-tidymodels-with-rasters.html#load-data-and-do-some-preprocessing",
    "href": "posts/2022-02-10-tidymodels-with-rasters.html#load-data-and-do-some-preprocessing",
    "title": "Working with tidymodels and rasters in R",
    "section": "",
    "text": "The first thing is to load the labeled data from which we will train and test our model. In this example, we are going to work with spatial information, rasters and vectors. So, we generated a dataset of disturbance and non-disturbance areas using visual interpretation. For the sake of this model, we are going to take the data as spatially independent, however, keep in mind that there are other types of models that can take into account spatial dependency. Here we will use BFAST components and type of forest (tropical dry forest, TDF or temperate forest, TF) as independent variables, while the only dependent variable will be if an area correspnods to disturbance or not. The main idea of the script is to compare a baseline model, based on a magnitude threshold of 0.2 vs a more complex model that might include several other indepdendent variables.\n# Load raster and set names\nim1 &lt;- stack(\"bfast_components.tif\")\nnames(im1) &lt;- c(\"breakpoint\",\"magnitude\", \"error\", \"history\", \n                \"r.squared\", \"amplitude\", \"trend\", \"Naperc\")\n\n# Choose subset of bands\nim1 &lt;- im1[[c(2,4:8)]]\n\n# Load a forest type layer\nforests_shp&lt;- st_read(\"Forest_type.shp\")\n\n# Reproject\nforests_shp &lt;- forests_shp %&gt;%\n  st_transform(st_crs(im1[[1]]))\n\n# Rasterize\nforests_im &lt;- fasterize(forests_shp, \n                        raster = raster(im1[[1]]),\n                        field = \"ID\",\n                        fun = \"last\")\n# Set TF as 0\nforests_im[forests_im==2] &lt;- 0\n\n# Stack all the independent variables as a multiband raster\nim1 &lt;- stack(forests_im, im1)\nnames(im1) &lt;- c(\"Forest\", \"Magnitude\", \"History\", \"R2\", \"Ampl\", \"Trend\", \"NAperc\")\n\n# plot(im1)\n\n# Read verified areas\ntf &lt;- st_read(\"238pts_Verified.shp\")\n\n# Make some recoding and eliminate unused variables\nsample_extr &lt;- tf %&gt;%\n  # Remove geometry, i.e., pass it to simple table\n  st_set_geometry(NULL) %&gt;%\n  # Convert forest type as a numeric variable with 0 and 1\n  mutate_at(vars(Forest), function(x) case_when(x == \"Temperate_forest\" ~ 0,\n                                                x == \"Tropical_dry_forest\" ~ 1)) %&gt;%\n  # Convert change, the dependent variable as factor                                              \n  mutate_at(vars(Change), function(x) as.factor(x)) %&gt;%\n  # Eliminate unused variables\n  dplyr::select(-c(DateChange, Obs, cell, x, y, Breakp))\n\n# Take a glimpse of the data\n# glimpse(sample_extr)"
  },
  {
    "objectID": "posts/2022-02-10-tidymodels-with-rasters.html#divide-dataset-into-training-and-test-sets",
    "href": "posts/2022-02-10-tidymodels-with-rasters.html#divide-dataset-into-training-and-test-sets",
    "title": "Working with tidymodels and rasters in R",
    "section": "",
    "text": "After doing that short procedure you need to divide the complete dataset into training and test sets. This can easily be done using tidymodels. Additionally, I decided to use a separate vfold-cv-set (cross-validation set) to test the performance of different model architectures and obtain a standard error of the mean accuracy to decide which architecture could be considered as the best. After deciding the best model architecture, the the selected model will be trained and tested on the training and test datasets, respectively.\n# Set seed to make everything reproducible\nset.seed(15)\nsample_split &lt;- initial_split(sample_extr, \n                              prop = 0.70,\n                              # Stratification; save same proportions for some variable in train and test\n                              strata = Change)\n\n# Create training and test set\nbfast_training &lt;- sample_split %&gt;%\n  training()\n\nbfast_test &lt;- sample_split %&gt;%\n  testing()\n\n# Ensure reproducibility\nset.seed(5)\nbfast_folds &lt;- vfold_cv(bfast_training,\n                        v = 3,\n                        repeats = 40,\n                        strata = Change)\nOnce you got the training and test sets, as well as the vfold-cv-set the next step will be to specify the models you are going to train. This can be done by specifying different recipes.\n# Specify algorithm to be used, engine and mode (classification or regression)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"randomForest\") %&gt;%\n  set_mode(\"classification\")\n\n# Recipes\n# Model with all predictors, will be the template recipe to be used in the other recipes\nbfast_recipe &lt;- recipe(Change ~ ., \n                       data = bfast_training) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) \n\n# Baseline model\nbaseline &lt;- bfast_recipe %&gt;% \n  step_mutate(base_line = ifelse(Magnitude &lt;= -0.2, 1, 0)) %&gt;%\n  step_rm(c(Forest, R2, Ampl, NAperc, History, Trend, Magnitude))\n\n# Random forests recipe\n# Model with Magnitude, Trend,  History, NAperc, Ampl and R2, remove Forest\npred6_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest)) \n\n# Model with Magnitude, Trend,  History, NAperc and Ampl, remove Forest and R2\npred5_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2)) \n\n# Model with Magnitude, Trend,  History and NAperc\npred4_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc)) \n\n# Model with Magnitude, Trend and History\npred3_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl)) \n\n# Model with only Magnitude and Trend\npred2_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl, History)) \n\n# Model with only Magnitude\npred1_rec_rf &lt;- \n  bfast_recipe %&gt;% \n  step_rm(c(Forest, R2, NAperc, Ampl, History, Trend))\n\n# Create a list of the models that area going to be trained\npreprocessing &lt;- \n  list(base = baseline,\n       pred1 = pred1_rec_rf,\n       pred2 = pred2_rec_rf,\n       pred3 = pred3_rec_rf,\n       pred4 = pred4_rec_rf,\n       pred5 = pred5_rec_rf,\n       pred6 = pred6_rec_rf,\n       all = bfast_recipe\n  )\n\n# Create a workflow set\nrf_models &lt;- workflow_set(preproc = preprocessing, \n                          models = list(rf = rf_model), \n                          cross = FALSE)\nOnce all the recipes and workflow have been defined the next step is to fit or train the models. Remember we are going to first evaluate the models on the vfold-cv-set, then train it using the training dataset and evaluate it on the test set.\n# This is for running all variations of the model\n# Define the number of nodes to be used for the training procedure. I recommend using 1 less than the total number of cores available in your computer\ncl &lt;- makePSOCKcluster(5)\nregisterDoParallel(cl)\n\n# Fit all models using the vfold-cv-dataset\nrf_results &lt;- \n  rf_models %&gt;% \n  # First argument tells type of fitting to be made\n  # Fit resample takes vfolds of training and trains / tests\n  workflow_map(\"fit_resamples\", \n               # Options to `workflow_map()`: \n               seed = 10, verbose = TRUE,\n               # Options to `fit_resamples()`: \n               resamples = bfast_folds)\n\n# Collect metrics from the workflow and write the results to disk\nrf_results %&gt;%\n  collect_metrics() %&gt;% \n  # filter(.metric == \"accuracy\") %&gt;%\n  write.csv(\"Results/rf_modelcomp_allForest.csv\")\nAfter fitting all the models, you should choose the best architecture. In this case, I chose the one with non-significant difference in accuracy with the highest achieved one and tht included less independent variables. You can make a plot to see the results in a graphic way.\n# Choose best model according to accuracy\nautoplot(\n  rf_results,\n  rank_metric = \"accuracy\",  # &lt;- how to order models\n  metric = \"accuracy\",       # &lt;- which metric to visualize\n  select_best = TRUE     # &lt;- one point per workflow\n)\n\nprint(\"Select simplest best model\")\n# Select model architecture with highest accuracy\nrf_results %&gt;% \n  rank_results(rank_metric = \"accuracy\", select_best = T) %&gt;% \n  filter(.metric == \"accuracy\") \nAfter evaluating the results obtained in the vfold-cv-dataset, I chose the best model: “pred3_rf”. So we are using that name as the model name to do the rest of the process. This names are automatically created when training the model.\n# Best model name\nrf_best_model_id &lt;- \"pred3_rf\"\n\n# Pull the best model according to its id from workflow\n# Then choose the model with highest accuracy parameters\n# according to accuracy. This contains only the model that obtained the \n# highest accuracy in the vfold-cv-sets\nrf_baseline_results &lt;- rf_results %&gt;% \n  extract_workflow_set_result(\"base_rf\") %&gt;%\n  select_best(metric = \"accuracy\")\n\nrf_truebest_results &lt;- rf_results %&gt;% \n  extract_workflow_set_result(rf_best_model_id) %&gt;%\n  select_best(metric = \"accuracy\") \n\n# Make last fit (i.e., train model from scratch using complete training data\n# and then validate over validation data)\n# Select best model using the previous object (bfast_best_results)\n# These object contained the trained and verified model (using training and test sets)\nrf_baseline_last_fit &lt;- rf_results %&gt;% \n  extract_workflow(\"base_rf\") %&gt;% \n  finalize_workflow(rf_baseline_results) %&gt;% \n  last_fit(split = sample_split)\n\nrf_truebest_last_fit &lt;- rf_results %&gt;% \n  extract_workflow(rf_best_model_id) %&gt;% \n  finalize_workflow(rf_truebest_results) %&gt;% \n  last_fit(split = sample_split)\n\n# Get trained models for prediction\n# Fit not last fit, aka, withouth predictions (only trained model).\n# This are going to be used to make the predictions over the rasters\nrf_baseline_fit_notlast &lt;- rf_results %&gt;% \n  extract_workflow(\"base_rf\") %&gt;% \n  finalize_workflow(rf_baseline_results) %&gt;% \n  fit(bfast_training)\n\nrf_truebest_fit_notlast &lt;- rf_results %&gt;% \n  extract_workflow(rf_best_model_id) %&gt;% \n  finalize_workflow(rf_truebest_results) %&gt;% \n  fit(bfast_training)\nNow we have the trained models (*_notlast) and the trained and evaluated models (*_last_fit) on the test set. So the next step is to collect the predictions from the trained and evaluated models to calculate different evaluation metrics.\n# Collect predicions\nrf_baseline_wkfl_preds &lt;- rf_baseline_last_fit %&gt;%\n  collect_predictions()\nrf_truebest_wkfl_preds &lt;- rf_truebest_last_fit %&gt;%\n  collect_predictions()\n\n# Write predictions vs truth\nrf_baseline_wkfl_preds %&gt;%\n  select(Change, .pred_class) %&gt;%\n  write.csv(\"Results/PredictionsTruthRFBaseline.csv\")\nrf_truebest_wkfl_preds %&gt;%\n  select(Change, .pred_class) %&gt;%\n  write.csv(\"Results/PredictionsTruthRFBest.csv\")\n\n# Set the metrics to calculate\nbfast_metrics &lt;- metric_set(accuracy, \n                            roc_auc, \n                            precision, \n                            recall,\n                            f_meas)\n\n# Calculate metrics and write them to disk\nrf_baseline_wkfl_preds %&gt;%\n  bfast_metrics(truth = Change, \n                estimate = .pred_class,\n                event_level = \"second\", #To focus evaluation on 1\n                .pred_1) %&gt;%\n  write.csv(\"Results/EvalMetricsRFBaseline.csv\")\nrf_truebest_wkfl_preds %&gt;%\n  bfast_metrics(truth = Change, \n                estimate = .pred_class,\n                event_level = \"second\", #To focus evaluation on 1\n                .pred_1) %&gt;%\n  write.csv(\"Results/EvalMetricsRFBest.csv\")\nAdditionally, you might be interested in obtaining the ROC curves of each model, so you can do it using the following script. In this step, we will create a data frame containing the ROC curves, which can afterwards used to construct a plot showing this results.\n# ROC plots\nrf_baseline_roc &lt;- rf_baseline_wkfl_preds %&gt;%\n  roc_curve(truth = Change, \n            event_level = \"second\",\n            .pred_1)  %&gt;%\n  add_column(Model = \"Baseline\")\nrf_truebest_roc &lt;-rf_truebest_wkfl_preds %&gt;%\n  roc_curve(truth = Change, \n            event_level = \"second\",\n            .pred_1) %&gt;%\n  add_column(Model = rf_best_model_id)\n\nplotter_rf &lt;- bind_rows(rf_baseline_roc, rf_truebest_roc) %&gt;%\n  mutate(\"1 - specificity\" = 1-specificity) \nThe last step of the workflow is to spatialize the model, i.e., apply the model using the rasters to obtain a final disturbance / non-disturbance map.\n# Use model to make raster\n# Function for applying model to rasters and obtain a raster as results\nfun&lt;-function(...){\n  p&lt;-predict(...)\n  return(as.matrix(as.numeric(p[, 1, drop=T]))) \n}\n\n# Make prediction\nrf_baseline_pred_im &lt;- raster::predict(im1, \n                              model = rf_baseline_fit_notlast, \n                              type=\"class\", \n                              fun=fun)\n# Write raster\nwriteRaster(rf_baseline_pred_im,\n            paste0(\"ClassRaster/RFBaselineClass_\",\"pred_AllForest.tif\"),\n            format = \"GTiff\",\n            overwrite = T)\n\n# Make prediction\nrf_truebest_pred_im &lt;- raster::predict(im1, \n                              model = rf_truebest_fit_notlast, \n                              type=\"class\", \n                              fun=fun)\n# Write raster\nwriteRaster(rf_truebest_pred_im,\n            paste0(\"ClassRaster/RFTruebestClass_\",\"pred_AllForest.tif\"),\n            format = \"GTiff\",\n            overwrite = T)"
  },
  {
    "objectID": "posts/2022-02-07-making-diagrams-in-r.html",
    "href": "posts/2022-02-07-making-diagrams-in-r.html",
    "title": "Making diagrams in R",
    "section": "",
    "text": "Diagrams in R\nIn this post I will show you how to create simple diagrams in R that can be useful for creating flowcharts and figures using the packages DiagrammeR. So the first thing is to load DiagrammeR package.\n\n\nDiagrammeR package\nlibrary(DiagrammeR)\nThis packages works with essentially two types of objects: nodes and edges. Nodes will represent the nodes in a diagram, which usually consist of geometric figures with text. In turn, edges correspond to connections among the nodes that will usually consist of arrows that represent the direction of the workflow. In this example, I will show you how to draw a diagram by adding each node and edge separately; however, for more experienced users it might be easier to use nodes and edge dataframes to define all the nodes and edges in a single data frame.\n\n\nExample diagram\nThe first step is to create a graph, using the create_graph function. Then we will use a pipe |&gt; to start creating each node, using add_node. Notice that each node can take the following arguments: label (text that will be shown) and font color of the node, shape of the node, color and fill color of the node. Additionally, you can set if the size of the figure should be set according to the label or a predefined height and width.\na_graph &lt;- create_graph() |&gt;\n  # Set nodes\n  add_node(label = \"\\nLandsat 5, 7, 8\\nNDVI time\\nseries (1994-\\n2018)\", \n           node_aes = node_aes(\n             shape = \"cylinder\",\n             color = \"#a4aebd\",\n             fillcolor = \"#d9e8f8\",\n             fontcolor = \"black\",\n             # fixedsize = T,\n             height = 0.9,\n             width = 1.1\n           )) |&gt;\n  add_node(label = \"BFAST\\ncomponents\\nextraction\", \n           node_aes = node_aes(\n             shape = \"box\",\n             color = \"#be9c5c\",\n             fillcolor = \"#fee5cc\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"\\n238 points\\nTraining / Verification\\nMagnitude\\nGamma distribution\", \n           node_aes = node_aes(\n             shape = \"cylinder\",\n             color = \"#8fa38a\",\n             fillcolor = \"#d5e8d4\",\n             fontcolor = \"black\",\n             # fixedsize = T,\n             height = 0.9,\n             width = 1.4\n           )) |&gt;\n  add_node(label = \"Visual interpretation\\nusing Sentinel-2\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8e7571\",\n             fillcolor = \"#f7cecc\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"All-forest\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"TDF\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"TF\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"Models training\\nand evaluation\", \n           node_aes = node_aes(\n             shape = \"oval\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"Best model\\nselection\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"Prediction on\\nstudy site\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8b7e8f\",\n             fillcolor = \"#e1d4e5\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"\\n624 points\\n verification\\nStratified random\\ndistribution\", \n           node_aes = node_aes(\n             shape = \"cylinder\",\n             color = \"#8fa38a\",\n             fillcolor = \"#d5e8d4\",\n             fontcolor = \"black\",\n             # fixedsize = T,\n             height = 0.9,\n             width = 1.1\n           )) |&gt;\n  add_node(label = \"Visual interpretation\\nusing Sentinel-2\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#8e7571\",\n             fillcolor = \"#f7cecc\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"Confusion matrix\\ncalculation\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#7c7b8c\",\n             fillcolor = \"#d0cee3\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) |&gt;\n  add_node(label = \"Class unbiased area\\nestimate\", \n           node_aes = node_aes(\n             shape = \"rectangle\",\n             color = \"#7c7b8c\",\n             fillcolor = \"#d0cee3\",\n             fontcolor = \"black\",\n             fixedsize = F\n           )) \nThe second step is to define each node’s position. Notice that nodes are automatically numbered in the order they were created. Thus, node = 1 refers to the first node that was created using add_node. Each node position can be defined by its x and y coordinates.\na_graph &lt;- a_graph |&gt;\n  # Set nodes position\n  set_node_position(\n    node = 1,\n    x = 1, y = 6.5) |&gt;\n  set_node_position(\n    node = 2,\n    x = 2.45, y = 6.5) |&gt;\n  set_node_position(\n    node = 3,\n    x = 4, y = 6.5) |&gt;\n  set_node_position(\n    node = 4,\n    x = 3, y = 5) |&gt;\n  set_node_position(\n    node = 5,\n    x = 2, y = 4) |&gt;\n  set_node_position(\n    node = 6,\n    x = 3, y = 4) |&gt;\n  set_node_position(\n    node = 7,\n    x = 4, y = 4) |&gt;\n  set_node_position(\n    node = 8,\n    x = 3, y = 3)|&gt;\n  set_node_position(\n    node = 9,\n    x = 5, y = 3) |&gt;\n  set_node_position(\n    node = 10,\n    x = 5, y = 5) |&gt;\n  set_node_position(\n    node = 11,\n    x = 6.5, y = 6.5) |&gt;\n  set_node_position(\n    node = 12,\n    x = 6.5, y = 5) |&gt;\n  set_node_position(\n    node = 13,\n    x = 6.5, y = 4) |&gt;\n  set_node_position(\n    node = 14,\n    x = 6.5, y = 3)\nAfterward, we will add the edges. In this step, we will use the same numbering of the nodes as in the previous step. Thus, node 1 will be the first created node, while node 2 will be the second. Inside the add_edge function we can set the width of the arrow, as well as its color.\na_graph &lt;- a_graph |&gt;\n  # Add edges\n  add_edge(from = 1, to = 2, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 2, to = 3, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 3, to = 4, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 4, to = 5, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 4, to = 6, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 4, to = 7, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 5, to = 8, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 6, to = 8, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 7, to = 8, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 8, to = 9, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 9, to = 10, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 2, to = 10,\n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 10, to = 11, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 11, to = 12, \n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 12, to = 13,\n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\")) |&gt;\n  add_edge(from = 13, to = 14,\n           edge_aes = edge_aes(\n             penwidth = 1.5,\n             color = \"black\"))\nFinally, we can render the graph.\nrender_graph(a_graph)\nThe produced the diagram\n\n\n\nFlowchart of a BFAST + ML approach.\n\n\nIf you wish to export the diagram, you can use export_graph.\nexport_graph(a_graph,\n             file_name = \"Plots/flowchart.png\",\n             file_type = \"png\",\n             width = 3600,\n             height = 2400)"
  },
  {
    "objectID": "posts/2022-02-01-making-animations-in-r.html",
    "href": "posts/2022-02-01-making-animations-in-r.html",
    "title": "Making animations in R",
    "section": "",
    "text": "Making animations in R\nThis post will show you how to make animations in R. The first step is to load the required packages. tidyverse is a package that contains other packages useful to wrangle and clean data, as well as to make plots, such as dplyr, tidyr and ggplot2. sf is a package that has several tools to work with vector data. gganimate is a package that will add animation to our plots.\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(gganimate)\nThe second step is to read the data that is going to be used in the plot: the fires locations and week of occurence (fires.csv) and the region of interest shapefile (zm).\ndf &lt;- read.csv(\"fires.csv\",\n               na.strings=c(\"\", \" \", \"''\"))\n\nzm &lt;- st_read(\"ROI.shp\")\nNext, let’s build the plot. The first part consists a fairly normal plot made with ggplot2, where we plot first the roi and then the fire occurence points and set other display specifics. After this part, we will set the title of the plot as a dynamic title which includes the frame_time of the animation rounded with zero decimals and paste this value along with a message. Then you need to specify the variable that represents the time steps. In this case, the time step variable is Semana, which means week in Spanish. Finally, we can add other chracteristics about the desired transition of the data between time steps, i.e., how the data enters into the dynamic plot (enter) and how it exits (exit). In this case, I chose both transitions as fade.\np1 &lt;- ggplot (zm) + \n  geom_sf(fill = \"white\") +\n  geom_point(data = df, \n             aes(x = lon,\n                 y = lat), \n             col = \"firebrick2\",\n             size = 1.3,\n             alpha = 1) +\n  scale_x_continuous(limits = c(-101.3, -101.1)) + \n  scale_y_continuous(limits = c(19.65, 19.75)) + \n  cowplot::theme_cowplot() +\n  theme(axis.text.x.bottom = element_text(size = 8,\n                                          angle = 90),\n        axis.text.y = element_text(size = 8),\n        plot.title = element_text(size = 10)) +\n  # Here comes the gganimate specific part\n  labs(title = 'Week {round(frame_time,0)} in monitoring period', \n       x = 'Lon', y = 'Lat') +\n  transition_time(Semana) +\n  enter_fade() + \n  exit_fade() \nIf you wish to save the animation into a file, you can override the default size and resolution of the animation.\noptions(gganimate.dev_args = list(width = 800, \n                                  height = 600,\n                                  units = 'px', \n                                  res=200))\nThen, you need to animate the plot by defining the desired frames per second (fps) and number of frames (which can be set as the maximum value of the time steps in the data).\np1_anim &lt;- animate(p1, \n                   nframes = max(df$Semana), \n                   fps=2)\nFinally, save it as a gif.\nanim_save(\"Plots/fires.gif\",\n          p1_anim)\nAnd here’s a preview of the result.\n\n\n\nAnimation of fires in ROI"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html",
    "href": "posts/2020-02-10-manejo-imagenes.html",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Para descargarla desde mi googleDrive vamos a utilizar los siguientes comandos\n\n\nlibrary(raster)\n\n## Loading required package: sp\n\nlibrary(curl)\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/imagen1.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=17PyQnEIICpjNtPP3v59gLEaoY3zzzEcR\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location)\n\n#Leer imagen\nimagen1 &lt;- raster(location)\n\n\n\n\n\nRecordar que:\n\n\n\n\nCargar paquete raster\n\n\n\n\nEscribir completa la ubicación del archivo\n\n\n\n\nIncluir extension\n\n\n\n\nPara ubicaciones de archivos “/” en lugar de “’'”\n\n\n\n\nA continuación, se puede graficar como cualquier gráfica en R\n\n\nplot(imagen1)\n\n\n\n\n\nSin embargo, aquí nada más se cargó una banda. Para cargar una imagen con más de una banda hay que utilizar otra función.\n\n\nlibrary(raster)\n\nimagen1&lt;-stack(location)\nplot(imagen1)\n\n\n\n\n\nTambién se puede utilizar la función brick\n\n\nimagen1&lt;-brick(location)\n\n\nplot(imagen1)\n\n\n\n\n\nRegresamos a la imagen importada con stack\n\n\nimagen1&lt;-stack(location)\n\n\n\n\n\nVer las características del objeto ¿Qué es cada cosa?\n\n\nimagen1\n\n## class      : RasterStack \n## dimensions : 81, 103, 8343, 10  (nrow, ncol, ncell, nlayers)\n## resolution : 0.0001796631, 0.0001796631  (x, y)\n## extent     : -101.2353, -101.2168, 19.64364, 19.65819  (xmin, xmax, ymin, ymax)\n## crs        : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n## names      :    B2,    B3,    B4,    B5,    B6,    B7,    B8,   B8A,   B11,   B12 \n## min values :     0,     0,     0,     0,     0,     0,     0,     0,     0,     0 \n## max values : 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535\n\nnlayers(imagen1)\n\n## [1] 10\n\ncrs(imagen1)\n\n## CRS arguments:\n##  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\n\nMás características\n\n\nres(imagen1)\n\n## [1] 0.0001796631 0.0001796631\n\nncell(imagen1)\n\n## [1] 8343\n\ndim(imagen1)\n\n## [1]  81 103  10\n\nMás características\n\n\nnames(imagen1)\n\n##  [1] \"B2\"  \"B3\"  \"B4\"  \"B5\"  \"B6\"  \"B7\"  \"B8\"  \"B8A\" \"B11\" \"B12\"\n\nextent(imagen1)\n\n## class      : Extent \n## xmin       : -101.2353 \n## xmax       : -101.2168 \n## ymin       : 19.64364 \n## ymax       : 19.65819\n\n¿Qué es esto?\n\n\nimagen1[[1]]\n\n## class      : RasterLayer \n## band       : 1  (of  10  bands)\n## dimensions : 81, 103, 8343  (nrow, ncol, ncell)\n## resolution : 0.0001796631, 0.0001796631  (x, y)\n## extent     : -101.2353, -101.2168, 19.64364, 19.65819  (xmin, xmax, ymin, ymax)\n## crs        : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n## source     : D:/Descargas/imagen1.tif \n## names      : B2 \n## values     : 0, 65535  (min, max)\n\n¿y esto?\n\n\ndataType(imagen1)\n\n##  [1] \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\"\n## [10] \"INT2U\"\n\n\n\n\n\nImágenes mutiespectrales con 13 bandas de distinta resolución espacial. Por eso, en este stack sólo se tienen las imágenes\n\n\n\n\n\n\n\nTambién se puede ver la imagen con otros paquetes\n\n\nlibrary(rasterVis)\n\n## Loading required package: lattice\n## Loading required package: latticeExtra\n\nlibrary(ggplot2)\n\n## \n## Attaching package: 'ggplot2'\n## The following object is masked from 'package:latticeExtra':\n## \n##     layer\n\ngplot(imagen1)+ geom_tile(aes(fill = value))\n\n\n\n\n\nOtra forma de mostrar imagenes\n\n\nlibrary(tmap)\n\ntm_shape(imagen1)+ tm_raster()\n\n## Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3\n\n\n\n\ntm_shape(imagen1)+ tm_rgb(max.value = 2100)\n\n## Warning: Raster values found that are outside the range [0, 2100]\n\n\n\n\n\n\n\nSe puede realizar de dos maneras\n\n\n\n\n\n\nimagenRGB &lt;- subset(imagen1,1:3)\n\n\n\n\n\n\nimagenRGB &lt;- imagen1[[1:3]]\n\n\n\n\n\ncrop_imRGB &lt;- crop(imagenRGB, extent(-101.2358,-101.2150,19.64370,19.65809))\n\n\n\n\n\n\n\n\nPrimero cargar la imagen y calcular el NDVI\n\n\nlibrary(raster)\n\n#Ubicación para guardar la imagen descargada\nlocation_dem &lt;- \"D:/Descargas/img_DEM.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=1qOJxEaAFgYMr8PQNuIKJgcTYq_SyvhO0\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location_dem)\n\ndem&lt;-raster(location_dem)\n\nplot(dem)\n\n\n\n\n\ncrs(dem)\n\n## CRS arguments:\n##  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\n\nres(dem)\n\n## [1] 0.0002694946 0.0002694946\n\ndim(dem)\n\n## [1] 55 69  1\n\n\n\nslope &lt;- terrain(dem, \n                 opt = \"slope\", \n                 unit = \"degrees\", \n                 neighbors=4)\nplot(slope)\n\n\n\n\n\n\n\n\nslope &lt;- terrain(dem, \n                 opt = \"aspect\",\n                 unit = \"degrees\", \n                 neighbors = 4)\nplot(slope)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(raster)\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-subset(imagen1, c(1:3,8))\n\n\n\n\nSR&lt;-imagen1$B8A / imagen1$B4\nplot(SR)\n\n\n\n\n\nOtras formas de realizar lo mismo\n\n\nSR&lt;-imagen1[[4]] / imagen1[[3]]\nplot(SR)\n\n\n\n\n\nnames(imagen1)&lt;-c(\"B\",\"G\",\"R\",\"NIR\")\nSR&lt;-imagen1$NIR / imagen1$R\nplot(SR)\n\n\n\n\n\n\n\n\nNDVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R)\nplot(NDVI)\n\n\n\n\n\n\n\n\nEVI &lt;- 2.5 * (imagen1$NIR - imagen1$R) / ((imagen1$NIR + 6 * imagen1$R - 7.5 * imagen1$B + 1))\nplot(EVI)\n\n\n\n\n\nNo se alcanza a distinguir nada. Se ven valores de -40 a 20. Probablemente hicimos algo mal. A veces es mejor pasar de la escala 0 - 10000 a una de 0 - 1 antes de hacer los cálculos de algunos de estos índices. Entonces dividimos cada banda entre 10000.\n\n\nEVI &lt;- 2.5 * (imagen1$NIR / 10000 - imagen1$R/ 10000) / ((imagen1$NIR/ 10000 + (6 * imagen1$R/ 10000) - (7.5 * imagen1$B/ 10000) + 1))\nplot(EVI)\n\n\n\n\n\n\n\n\nEVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R + 0.5) * (1.5)\nplot(EVI)\n\n\n\n\n\n\n\n\n\n\n\nPara calcular este índice requerimos otras bandas: B8 y B11, así que volvemos a cargar la imagen.\n\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-imagen1/10000\n\nNDWI &lt;- (imagen1[[8]] - imagen1[[9]]) / (imagen1[[8]] + imagen1[[9]])\nplot(NDWI)\n\n\n\n\n\n\n\n\n\n\n\nNBR &lt;- (imagen1[[4]] - imagen1[[6]]) / (imagen1[[4]] + imagen1[[6]])\nplot(NBR)\n\n\n\n\n\n\n\n\n\n\n\n#Tasselled Cap - Brightness\n#Ahorita no se va a calcular porque no tenemos la B10\n# Brightness &lt;- 0.3037*imagen1[[1]]+0.2793*imagen1[[2]] +0.4743*imagen1[[3]]+0.5585*imagen1[[4]]+ 0.5082*B10+0.1863*imagen1[[10]] \n\n #Tasselled Cap - Greeness\nGreeness &lt;- (-0.2848*imagen1[[1]])+(-0.2435*imagen1[[2]])+(-0.5436*imagen1[[3]]) +0.7243*imagen1[[8]]+0.0840*imagen1[[9]]+(-0.1800*imagen1[[10]]) \n#Tasselled Cap - Wetness \nWetness &lt;- 0.1509*imagen1[[1]]+0.1973*imagen1[[2]]+0.3279*imagen1[[3]] +0.3406*imagen1[[8]]+(-0.7112*imagen1[[9]])+(-0.4572*imagen1[[10]]) \n\nplot(Greeness)\n\n\n\n\n\nplot(Wetness)\n\n\n\n\n\n\n\n\n\n\n\n\nEste método se basa en la matriz de co-ocurrencias de tonos de gris (GLCM). Calcula diferentes métricas en ciertas direcciones. Es un método de “moving window”\n\n\nPrimero cargar la imagen y calcular el NDVI\n\n\nlibrary(raster)\nlibrary(glcm)\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-subset(imagen1, c(1:3,8))\nnames(imagen1)&lt;-c(\"B\",\"G\",\"R\",\"NIR\")\nNDVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R)\n\n\n\n\nAquí podemos indicar el tamaño de la ventana que vamos a utilizar para calcular la textura. Para que sólo un pixel obtenga el valor de la textura de la ventana hay que utilizar un tamaño non. El parámetro shift va decir cuántos pixeles se va a mover en X y en Y. En este caso el shift indica que se va a comparar cada pixel dentro de la ventana con el pixel que esté a una distancia de un pixel a la derecha y uno arriba.\n\n\nglcm_NE &lt;- glcm(NDVI, \n              window = c(9,9), \n              shift = c(1,1), \n              statistics = c(\"mean\", \"variance\", \"homogeneity\", \"contrast\", \n                             \"dissimilarity\", \"entropy\", \"second_moment\",  \"correlation\")\n              )\nplot(glcm_NE)\n\n\n\n\n\n\n\n\nDebido a que se puede calcular la textura en 4 direcciones, para obtener una medida sin efecto de dirección se ponen las cuatro posibilidades: (0,1); (1,1); (1,0); (1,-1)\n\n\nglcm_Alldir&lt;- glcm(NDVI, \n              window = c(9,9), \n              shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n              statistics = c(\"mean\", \"variance\", \"homogeneity\", \"contrast\", \n                             \"dissimilarity\", \"entropy\", \"second_moment\")\n              )\nplot(glcm_Alldir)\n\n\n\n\n\n\n\n\n\nEste método primero realiza una transformada de Fourier de la imagen y luego realiza una ordenación de estos datos. Por eso se llama Ordenación de la Transformada de Fourier (FOTO). La idea de este método es que caracteriza la textura a partir de la frecuencia de las ondas dominantes (r-spectrum). De tal manera, si una ventana presenta una textura dominante a una distancia de varios pixeles, estará caracterizado por ondas de frecuencia corta (pocos ciclos por km). En cambio, si una ventana presenta una textura dominante a una distancia de pocos pixeles, estará caracterizado por ondas de frecuencia largas (muchos ciclos por km). Este método se calcula por áreas de la imagen que correponden al tamaño de la ventana.\n\n\nEste método sólo permite calcularse para ventanas cuadradas. Por ello, sólo se indica el lado de la ventana cuadrada.\n\n\nlibrary(foto)\n\noutput &lt;- foto(NDVI,\n     plot = T,\n     window_size = 25,\n     method = \"zones\")"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#descargar-imagen",
    "href": "posts/2020-02-10-manejo-imagenes.html#descargar-imagen",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Para descargarla desde mi googleDrive vamos a utilizar los siguientes comandos\n\n\nlibrary(raster)\n\n## Loading required package: sp\n\nlibrary(curl)\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/imagen1.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=17PyQnEIICpjNtPP3v59gLEaoY3zzzEcR\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location)\n\n#Leer imagen\nimagen1 &lt;- raster(location)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#lectura-de-imágenes",
    "href": "posts/2020-02-10-manejo-imagenes.html#lectura-de-imágenes",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Recordar que:\n\n\n\n\nCargar paquete raster\n\n\n\n\nEscribir completa la ubicación del archivo\n\n\n\n\nIncluir extension\n\n\n\n\nPara ubicaciones de archivos “/” en lugar de “’'”\n\n\n\n\nA continuación, se puede graficar como cualquier gráfica en R\n\n\nplot(imagen1)\n\n\n\n\n\nSin embargo, aquí nada más se cargó una banda. Para cargar una imagen con más de una banda hay que utilizar otra función.\n\n\nlibrary(raster)\n\nimagen1&lt;-stack(location)\nplot(imagen1)\n\n\n\n\n\nTambién se puede utilizar la función brick\n\n\nimagen1&lt;-brick(location)\n\n\nplot(imagen1)\n\n\n\n\n\nRegresamos a la imagen importada con stack\n\n\nimagen1&lt;-stack(location)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#características-del-objeto",
    "href": "posts/2020-02-10-manejo-imagenes.html#características-del-objeto",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Ver las características del objeto ¿Qué es cada cosa?\n\n\nimagen1\n\n## class      : RasterStack \n## dimensions : 81, 103, 8343, 10  (nrow, ncol, ncell, nlayers)\n## resolution : 0.0001796631, 0.0001796631  (x, y)\n## extent     : -101.2353, -101.2168, 19.64364, 19.65819  (xmin, xmax, ymin, ymax)\n## crs        : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n## names      :    B2,    B3,    B4,    B5,    B6,    B7,    B8,   B8A,   B11,   B12 \n## min values :     0,     0,     0,     0,     0,     0,     0,     0,     0,     0 \n## max values : 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535, 65535\n\nnlayers(imagen1)\n\n## [1] 10\n\ncrs(imagen1)\n\n## CRS arguments:\n##  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\n\nMás características\n\n\nres(imagen1)\n\n## [1] 0.0001796631 0.0001796631\n\nncell(imagen1)\n\n## [1] 8343\n\ndim(imagen1)\n\n## [1]  81 103  10\n\nMás características\n\n\nnames(imagen1)\n\n##  [1] \"B2\"  \"B3\"  \"B4\"  \"B5\"  \"B6\"  \"B7\"  \"B8\"  \"B8A\" \"B11\" \"B12\"\n\nextent(imagen1)\n\n## class      : Extent \n## xmin       : -101.2353 \n## xmax       : -101.2168 \n## ymin       : 19.64364 \n## ymax       : 19.65819\n\n¿Qué es esto?\n\n\nimagen1[[1]]\n\n## class      : RasterLayer \n## band       : 1  (of  10  bands)\n## dimensions : 81, 103, 8343  (nrow, ncol, ncell)\n## resolution : 0.0001796631, 0.0001796631  (x, y)\n## extent     : -101.2353, -101.2168, 19.64364, 19.65819  (xmin, xmax, ymin, ymax)\n## crs        : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 \n## source     : D:/Descargas/imagen1.tif \n## names      : B2 \n## values     : 0, 65535  (min, max)\n\n¿y esto?\n\n\ndataType(imagen1)\n\n##  [1] \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\" \"INT2U\"\n## [10] \"INT2U\""
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#visualización",
    "href": "posts/2020-02-10-manejo-imagenes.html#visualización",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "También se puede ver la imagen con otros paquetes\n\n\nlibrary(rasterVis)\n\n## Loading required package: lattice\n## Loading required package: latticeExtra\n\nlibrary(ggplot2)\n\n## \n## Attaching package: 'ggplot2'\n## The following object is masked from 'package:latticeExtra':\n## \n##     layer\n\ngplot(imagen1)+ geom_tile(aes(fill = value))\n\n\n\n\n\nOtra forma de mostrar imagenes\n\n\nlibrary(tmap)\n\ntm_shape(imagen1)+ tm_raster()\n\n## Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3\n\n\n\n\ntm_shape(imagen1)+ tm_rgb(max.value = 2100)\n\n## Warning: Raster values found that are outside the range [0, 2100]"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#selección-de-ciertas-bandas",
    "href": "posts/2020-02-10-manejo-imagenes.html#selección-de-ciertas-bandas",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Se puede realizar de dos maneras\n\n\n\n\n\n\nimagenRGB &lt;- subset(imagen1,1:3)\n\n\n\n\n\n\nimagenRGB &lt;- imagen1[[1:3]]"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#corte",
    "href": "posts/2020-02-10-manejo-imagenes.html#corte",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "crop_imRGB &lt;- crop(imagenRGB, extent(-101.2358,-101.2150,19.64370,19.65809))"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#dem",
    "href": "posts/2020-02-10-manejo-imagenes.html#dem",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Primero cargar la imagen y calcular el NDVI\n\n\nlibrary(raster)\n\n#Ubicación para guardar la imagen descargada\nlocation_dem &lt;- \"D:/Descargas/img_DEM.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=1qOJxEaAFgYMr8PQNuIKJgcTYq_SyvhO0\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location_dem)\n\ndem&lt;-raster(location_dem)\n\nplot(dem)\n\n\n\n\n\ncrs(dem)\n\n## CRS arguments:\n##  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\n\nres(dem)\n\n## [1] 0.0002694946 0.0002694946\n\ndim(dem)\n\n## [1] 55 69  1\n\n\n\nslope &lt;- terrain(dem, \n                 opt = \"slope\", \n                 unit = \"degrees\", \n                 neighbors=4)\nplot(slope)\n\n\n\n\n\n\n\n\nslope &lt;- terrain(dem, \n                 opt = \"aspect\",\n                 unit = \"degrees\", \n                 neighbors = 4)\nplot(slope)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#indices-de-vegetación",
    "href": "posts/2020-02-10-manejo-imagenes.html#indices-de-vegetación",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "library(raster)\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-subset(imagen1, c(1:3,8))\n\n\n\n\nSR&lt;-imagen1$B8A / imagen1$B4\nplot(SR)\n\n\n\n\n\nOtras formas de realizar lo mismo\n\n\nSR&lt;-imagen1[[4]] / imagen1[[3]]\nplot(SR)\n\n\n\n\n\nnames(imagen1)&lt;-c(\"B\",\"G\",\"R\",\"NIR\")\nSR&lt;-imagen1$NIR / imagen1$R\nplot(SR)\n\n\n\n\n\n\n\n\nNDVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R)\nplot(NDVI)\n\n\n\n\n\n\n\n\nEVI &lt;- 2.5 * (imagen1$NIR - imagen1$R) / ((imagen1$NIR + 6 * imagen1$R - 7.5 * imagen1$B + 1))\nplot(EVI)\n\n\n\n\n\nNo se alcanza a distinguir nada. Se ven valores de -40 a 20. Probablemente hicimos algo mal. A veces es mejor pasar de la escala 0 - 10000 a una de 0 - 1 antes de hacer los cálculos de algunos de estos índices. Entonces dividimos cada banda entre 10000.\n\n\nEVI &lt;- 2.5 * (imagen1$NIR / 10000 - imagen1$R/ 10000) / ((imagen1$NIR/ 10000 + (6 * imagen1$R/ 10000) - (7.5 * imagen1$B/ 10000) + 1))\nplot(EVI)\n\n\n\n\n\n\n\n\nEVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R + 0.5) * (1.5)\nplot(EVI)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#índices-de-humedad",
    "href": "posts/2020-02-10-manejo-imagenes.html#índices-de-humedad",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Para calcular este índice requerimos otras bandas: B8 y B11, así que volvemos a cargar la imagen.\n\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-imagen1/10000\n\nNDWI &lt;- (imagen1[[8]] - imagen1[[9]]) / (imagen1[[8]] + imagen1[[9]])\nplot(NDWI)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#índices-de-cicatrices-de-incendios",
    "href": "posts/2020-02-10-manejo-imagenes.html#índices-de-cicatrices-de-incendios",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "NBR &lt;- (imagen1[[4]] - imagen1[[6]]) / (imagen1[[4]] + imagen1[[6]])\nplot(NBR)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#índices-n-dimensionales",
    "href": "posts/2020-02-10-manejo-imagenes.html#índices-n-dimensionales",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "#Tasselled Cap - Brightness\n#Ahorita no se va a calcular porque no tenemos la B10\n# Brightness &lt;- 0.3037*imagen1[[1]]+0.2793*imagen1[[2]] +0.4743*imagen1[[3]]+0.5585*imagen1[[4]]+ 0.5082*B10+0.1863*imagen1[[10]] \n\n #Tasselled Cap - Greeness\nGreeness &lt;- (-0.2848*imagen1[[1]])+(-0.2435*imagen1[[2]])+(-0.5436*imagen1[[3]]) +0.7243*imagen1[[8]]+0.0840*imagen1[[9]]+(-0.1800*imagen1[[10]]) \n#Tasselled Cap - Wetness \nWetness &lt;- 0.1509*imagen1[[1]]+0.1973*imagen1[[2]]+0.3279*imagen1[[3]] +0.3406*imagen1[[8]]+(-0.7112*imagen1[[9]])+(-0.4572*imagen1[[10]]) \n\nplot(Greeness)\n\n\n\n\n\nplot(Wetness)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#glcm",
    "href": "posts/2020-02-10-manejo-imagenes.html#glcm",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Este método se basa en la matriz de co-ocurrencias de tonos de gris (GLCM). Calcula diferentes métricas en ciertas direcciones. Es un método de “moving window”\n\n\nPrimero cargar la imagen y calcular el NDVI\n\n\nlibrary(raster)\nlibrary(glcm)\n\nimagen1&lt;-stack(location)\n\nimagen1&lt;-subset(imagen1, c(1:3,8))\nnames(imagen1)&lt;-c(\"B\",\"G\",\"R\",\"NIR\")\nNDVI &lt;- (imagen1$NIR - imagen1$R) / (imagen1$NIR + imagen1$R)\n\n\n\n\nAquí podemos indicar el tamaño de la ventana que vamos a utilizar para calcular la textura. Para que sólo un pixel obtenga el valor de la textura de la ventana hay que utilizar un tamaño non. El parámetro shift va decir cuántos pixeles se va a mover en X y en Y. En este caso el shift indica que se va a comparar cada pixel dentro de la ventana con el pixel que esté a una distancia de un pixel a la derecha y uno arriba.\n\n\nglcm_NE &lt;- glcm(NDVI, \n              window = c(9,9), \n              shift = c(1,1), \n              statistics = c(\"mean\", \"variance\", \"homogeneity\", \"contrast\", \n                             \"dissimilarity\", \"entropy\", \"second_moment\",  \"correlation\")\n              )\nplot(glcm_NE)\n\n\n\n\n\n\n\n\nDebido a que se puede calcular la textura en 4 direcciones, para obtener una medida sin efecto de dirección se ponen las cuatro posibilidades: (0,1); (1,1); (1,0); (1,-1)\n\n\nglcm_Alldir&lt;- glcm(NDVI, \n              window = c(9,9), \n              shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)), \n              statistics = c(\"mean\", \"variance\", \"homogeneity\", \"contrast\", \n                             \"dissimilarity\", \"entropy\", \"second_moment\")\n              )\nplot(glcm_Alldir)"
  },
  {
    "objectID": "posts/2020-02-10-manejo-imagenes.html#foto",
    "href": "posts/2020-02-10-manejo-imagenes.html#foto",
    "title": "Manejo de imágenes en R",
    "section": "",
    "text": "Este método primero realiza una transformada de Fourier de la imagen y luego realiza una ordenación de estos datos. Por eso se llama Ordenación de la Transformada de Fourier (FOTO). La idea de este método es que caracteriza la textura a partir de la frecuencia de las ondas dominantes (r-spectrum). De tal manera, si una ventana presenta una textura dominante a una distancia de varios pixeles, estará caracterizado por ondas de frecuencia corta (pocos ciclos por km). En cambio, si una ventana presenta una textura dominante a una distancia de pocos pixeles, estará caracterizado por ondas de frecuencia largas (muchos ciclos por km). Este método se calcula por áreas de la imagen que correponden al tamaño de la ventana.\n\n\nEste método sólo permite calcularse para ventanas cuadradas. Por ello, sólo se indica el lado de la ventana cuadrada.\n\n\nlibrary(foto)\n\noutput &lt;- foto(NDVI,\n     plot = T,\n     window_size = 25,\n     method = \"zones\")"
  },
  {
    "objectID": "posts/2020-02-06-clasificacion-supervisada.html",
    "href": "posts/2020-02-06-clasificacion-supervisada.html",
    "title": "Clasificación supervisada en R",
    "section": "",
    "text": "Vamos a ver cómo realizar tres tipos de clasificación de imágenes utilizando los siguientes algoritmos:\n\n\n\nMáxima verosimilitud\n\n\nÁrboles de decisión\n\n\nRandom Forests\n\n\nEvaluación del modelo y precisión\n\n\nEstadísticas básicas del resultado\n\n\n\n\n\n\n\nPara eso vamos a utilizar QGIS\n\n\n\n\n\nCargar los archivos que vamos a utilizar\n\n\nlibrary(raster)\n\n## Warning: package 'raster' was built under R version 3.6.3\n## Loading required package: sp\n\nlibrary(sf)\n\n## Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3\n\nlibrary(curl)\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/Training.zip\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=173AcNuclHuF5Jh39riiNVeg81IbMGtzB\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl::curl_download(dwnld_URL,\n                    destfile = location)\n\n#Extraer el archivo descargado\nunzip(location, \n      exdir = gsub(\"/Training.zip\",\"\",location))\n\n#Substituir .zip por .shp\nlocation &lt;- gsub(\".zip\",\".shp\",location)\n\n#Se pueden utilizar cualquiera de las dos funciones, pero optaremos por st_read\ntraining&lt;-shapefile(location)\n\ntraining&lt;-st_read(location)\n\n## Reading layer `Training' from data source `D:\\Descargas\\Training.shp' using driver `ESRI Shapefile'\n## Simple feature collection with 9 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2346 ymin: 19.64483 xmax: -101.2202 ymax: 19.65714\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/imagen1.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=17PyQnEIICpjNtPP3v59gLEaoY3zzzEcR\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location)\n\nS2&lt;-stack(location)\n\nnames(S2)&lt;-c(\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\n\ntraining\n\n## Simple feature collection with 9 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2346 ymin: 19.64483 xmax: -101.2202 ymax: 19.65714\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n##   id ClaseID     DescID                       geometry\n## 1  1       1 Vegetacion POLYGON ((-101.2292 19.6526...\n## 2  2       1 Vegetacion POLYGON ((-101.229 19.65152...\n## 3  3       1 Vegetacion POLYGON ((-101.2257 19.6571...\n## 4  4       2     Urbano POLYGON ((-101.2346 19.6456...\n## 5  5       2     Urbano POLYGON ((-101.2326 19.6504...\n## 6  6       2     Urbano POLYGON ((-101.2332 19.6522...\n## 7  7       3      Suelo POLYGON ((-101.2231 19.6455...\n## 8  8       3      Suelo POLYGON ((-101.2213 19.6557...\n## 9  9       3      Suelo POLYGON ((-101.221 19.65242...\n\nnames(training)\n\n## [1] \"id\"       \"ClaseID\"  \"DescID\"   \"geometry\"\n\ncrs(training)\n\n## [1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\nplot(S2)\n\n\n\n\n\nplot(training[3])\n\n\n\n\n\nplot(S2[[8]])\nplot(training[3], add = T)\n\n\n\n\n\nExtraer los valores de las áreas de entrenamiento ¿Qué es esto?\n\n\nextracted_info &lt;- raster::extract(S2,training)\nhead(extracted_info, n = 1)\n\n## [[1]]\n##       B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## [1,] 86 236 233 519  965 1393 1475 1530   866   533\n## [2,] 67 247 210 459 1167 1399 1448 1495   936   481\n## [3,] 94 215 220 482 1154 1529 1606 1682   892   473\n## [4,] 76 215 217 540 1400 1363 1449 1616   947   551\n\nConvertir la lista de valores a un data.frame\n\n\n#Se usa la notación :: para llamar funciones dentro de determinados paquetes sin necesidad de cargar el paquete mediante library(paquete)\n#Aquí hay que hacer un pequeño truco para poder pasar de list a data.frame\nextracted_info&lt;-purrr::map(1:length(extracted_info), function(i) as.data.frame(extracted_info[[i]]))\n\n#Ponerle nombres a cada lista de valores de acuerdo a la ClaseID\nnames(extracted_info)&lt;-training$DescID\nhead(extracted_info, n = 1)\n\n## $Vegetacion\n##    B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 86 236 233 519  965 1393 1475 1530   866   533\n## 2 67 247 210 459 1167 1399 1448 1495   936   481\n## 3 94 215 220 482 1154 1529 1606 1682   892   473\n## 4 76 215 217 540 1400 1363 1449 1616   947   551\n\n#Ya tenemos la información extraida\nextracted_info&lt;-dplyr::bind_rows(extracted_info, .id = \"id\")\nhead(extracted_info, n = 1)\n\n##           id  B   G   R NIR RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 86 236 233 519 965 1393 1475 1530   866   533\n\n#Cambiar los nombres de las columnas\ncolnames(extracted_info)&lt;-c(\"id\",\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\nhead(extracted_info, n = 1)\n\n##           id  B   G   R NIR RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 86 236 233 519 965 1393 1475 1530   866   533\n\nVeamos como se ven los datos por clase. Vamos a usar ggplot2 para graficar\n\n\nlibrary(ggplot2)\nggplot(extracted_info, aes(x = id, \n                           y = NIR,\n                           col = id)) + \n  geom_point(size = 3, alpha = 0.5) + \n  labs(x = \"DescID\", col = \"DescID\") +\n  theme_bw()\n\n\n\n\n\nPodríamos ver cómo se ven estos valores en cada una de las bandas\n\n\nlibrary(tidyr)\n\n## \n## Attaching package: 'tidyr'\n## The following object is masked from 'package:raster':\n## \n##     extract\n\nlibrary(ggplot2)\nextracted_info %&gt;%\n  pivot_longer(cols = -id, \n               names_to = \"bands\",\n               values_to = \"reflectance\") %&gt;%\nggplot( aes(x = bands, \n            y = reflectance,\n            col = id, \n            group = id)) + \n  geom_point(size = 3, alpha = 0.5) +\n  stat_summary(aes(y = reflectance)\n               , fun.y=mean,\n               geom=\"line\") +\n  labs(x = \"DescID\", \n       y = \"Reflectancia\",\n       col = \"DescID\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nlibrary(RStoolbox)\n\nClassMLC&lt;-superClass(img = S2,\n           trainData = as(training, 'Spatial'),\n           responseCol = \"DescID\",\n           model = \"mlc\")\n\n## Loading required package: lattice\n\nlibrary(tmap)\n\ntm_shape(ClassMLC$map)+ \n  tm_raster()+\n  tm_layout(scale = .8, \n            legend.position = c(\"right\",\"bottom\"),\n            legend.frame = T,\n            legend.bg.color = \"white\")\n\n\n\n\n\nSi queremos exportar el resultado para abrirlo en QGIS y compararlo con la imagen original\n\n\n# writeRaster(ClassMLC$map,\n#             filename = \"Clasificación_MLC.tif\",\n#             format = \"GTiff\",\n#             dadtaType = \"INT2S\")\n\n\n\n\n\nA partir de la información de entrenamiento se genera un agrupamiento de las categorías.\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ncartmodel &lt;- rpart(as.factor(id)~., \n                   data = extracted_info, \n                   method = 'class')\n\nprint(cartmodel)\n\n## n= 102 \n## \n## node), split, n, loss, yval, (yprob)\n##       * denotes terminal node\n## \n## 1) root 102 57 Suelo (0.44117647 0.36274510 0.19607843)  \n##   2) B&lt; 532.5 66 21 Suelo (0.68181818 0.01515152 0.30303030)  \n##     4) R&gt;=720 45  0 Suelo (1.00000000 0.00000000 0.00000000) *\n##     5) R&lt; 720 21  1 Vegetacion (0.00000000 0.04761905 0.95238095) *\n##   3) B&gt;=532.5 36  0 Urbano (0.00000000 1.00000000 0.00000000) *\n\nrpart.plot(cartmodel)\n\n\n\n\n\nAhora utilizamos la información obtenida de los datos de entrenamiento para extrapolarlos a toda la imagen y obtener la clasificación.\n\n\nClassCART &lt;- predict(S2,\n                     cartmodel, \n                     type = \"class\")\ncols &lt;- c(\"light blue\",\"orange\",\"dark green\")\nplot(ClassCART, col = cols)\nlegend(\"bottomright\", \n       legend=as.vector(t(ClassCART@data@attributes[[1]][2])), \n       fill=cols, bg=\"white\")\n\n\n\n\n\n\n\nOtra manera de clasificar utilizando random forest. Yo recomiendo esta opción.\n\n\nFase de entrenamiento\n\n\nlibrary(randomForest)\n\n## randomForest 4.6-14\n## Type rfNews() to see new features/changes/bug fixes.\n## \n## Attaching package: 'randomForest'\n## The following object is masked from 'package:ggplot2':\n## \n##     margin\n\nrfmodel &lt;- randomForest(as.factor(id) ~ ., \n                   method = \"rf\", \n                   data = extracted_info)\n\n#Ver help(train_model_list) para ver todos los modelos disponibles\n#Ver help(randomForest) para ver todos los argumentos disponibles\n\n\nYa obtuvimos el bosque modelos (ya se ajustaron los árboles) Ver el Out of the Bag Error rate de toda la clasificación\n\n\nprint(rfmodel)\n\n## \n## Call:\n##  randomForest(formula = as.factor(id) ~ ., data = extracted_info,      method = \"rf\") \n##                Type of random forest: classification\n##                      Number of trees: 500\n## No. of variables tried at each split: 3\n## \n##         OOB estimate of  error rate: 0.98%\n## Confusion matrix:\n##            Suelo Urbano Vegetacion class.error\n## Suelo         45      0          0  0.00000000\n## Urbano         0     36          1  0.02702703\n## Vegetacion     0      0         20  0.00000000\n\nVer los valores de importancia variable de acuerdo al decremente medio de la precisión. Las variables que tengan un mayor valor serán las que son más importantes para realizar la clasificación.\n\n\nimportance(rfmodel, type = 2)\n\n##       MeanDecreaseGini\n## B           13.8636821\n## G           12.0863197\n## R            7.9227143\n## NIR          7.5493199\n## RE1          1.3290514\n## RE2          0.3323111\n## RE3          0.3444938\n## NNIR         0.8942046\n## SWIR1       12.6556069\n## SWIR2        7.2739039\n\nplot(rfmodel, main=\"Random Forest\")\n\n\n\n\n\nAquí se puede ver el comportamiento del error por clase conforme se aumenta el número de árboles construidos (el tamaño del bosque). Vemos que hay un número en el cual el error se minimiza. Este parámetro se puede indicar a la hora de que construye el modelo (revisar el argumento de “ntree”). Los colores de cada clase están en el mismo orden en el que aparecen en el resumen del modelo; por lo tanto, suelo: se indica en rojo, urbano: azul y vegetación: verde.\n\n\n\n\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/Testing.zip\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=1fFX9lepmSWEm8wYDv2CEUnPH4LwMy19H\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl::curl_download(dwnld_URL,\n                    destfile = location)\n\n#Extraer el archivo descargado\nunzip(location, \n      exdir = gsub(\"/Testing.zip\",\"\",location))\n\n#Substituir .zip por .shp\nlocation &lt;- gsub(\".zip\",\".shp\",location)\n\ntesting&lt;-st_read(location)\n\n## Reading layer `Testing' from data source `D:\\Descargas\\Testing.shp' using driver `ESRI Shapefile'\n## Simple feature collection with 6 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2352 ymin: 19.64641 xmax: -101.2196 ymax: 19.65617\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n\nYa tenemos los datos de validación, así que vamos a correr el modelo para estos datos\n\n\nextracted_test &lt;- raster::extract(S2,testing)\n\n#Se usa la notación :: para llamar funciones dentro de determinados paquetes sin necesidad de cargar el paquete mediante library(paquete)\n#Aquí hay que hacer un pequeño truco para poder pasar de list a data.frame\nextracted_test&lt;-purrr::map(1:length(extracted_test), function(i) as.data.frame(extracted_test[[i]]))\n\n#Ponerle nombres a cada lista de valores de acuerdo a la ClaseID\nnames(extracted_test)&lt;-testing$DescID\nhead(extracted_test, n = 1)\n\n## $Vegetacion\n##     B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 103 297 248 544 1191 1459 1528 1648  1137   667\n## 2 156 311 284 535 1146 1336 1331 1384  1029   660\n## 3 114 227 235 391  684  784  794  843   832   573\n## 4 194 320 351 502  765  910  954 1056   887   637\n\n#Ya tenemos la información extraida\nextracted_test&lt;-dplyr::bind_rows(extracted_test, .id = \"id\")\nhead(extracted_test, n = 1)\n\n##           id   B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 103 297 248 544 1191 1459 1528 1648  1137   667\n\n#Cambiar los nombres de las columnas\ncolnames(extracted_test)&lt;-c(\"id\",\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\nhead(extracted_test, n = 1)\n\n##           id   B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 103 297 248 544 1191 1459 1528 1648  1137   667\n\nYa tenemos los datos extraidos del raster para la verificación, así que procedemos a correr el modelo para esos datos. Y vemos su matriz de error\n\n\nClassRF &lt;- predict(rfmodel, extracted_test)\nconfusion_matrix&lt;-table(ClassRF, extracted_test$id)\nconfusion_matrix\n\n##             \n## ClassRF      Suelo Urbano Vegetacion\n##   Suelo         19      0          0\n##   Urbano        10     20          0\n##   Vegetacion     0      0         11\n\n\n\n\nAquí ya obtenemos la imagen clasificada\n\n\nClassRF_raster &lt;- predict(S2,\n                     rfmodel)\nplot(ClassRF_raster)\n\n\n\n\n\nClassRF_raster@data@attributes[[1]]\n\n##   ID      value\n## 1  1      Suelo\n## 2  2     Urbano\n## 3  3 Vegetacion\n\n\n\n\nAhora ya que tenemos todo deberíamos conocer cuál es la precisión del método\n\n\n#Obtenemos el número de observaciones en los datos de validación\nn_test &lt;- nrow(extracted_test)\n#Obtenemos el número de clases en los datos de validación\nn_clases &lt;- length(levels(extracted_test$id))\n\noverall_accuracy &lt;- sum(diag(confusion_matrix)) / n_test\noverall_accuracy\n\n## [1] 0.8333333\n\n#Realizar sumas por renglones en la matriz de error\n#Obtener la precisión del usuario\nusers_accuracy &lt;- sapply(1:nrow(confusion_matrix), function(i){\n  confusion_matrix[i,i] / sum( confusion_matrix[i,])\n})\nnames(users_accuracy) &lt;- colnames(confusion_matrix)\nusers_accuracy\n\n##      Suelo     Urbano Vegetacion \n##  1.0000000  0.6666667  1.0000000\n\n#Obtener la precisión del producto\nproducers_accuracy &lt;- sapply(1:nrow(confusion_matrix), function(i){\n  confusion_matrix[i,i] / sum( confusion_matrix[,i])\n})\nnames(producers_accuracy) &lt;- row.names(confusion_matrix)\nproducers_accuracy\n\n##      Suelo     Urbano Vegetacion \n##  0.6551724  1.0000000  1.0000000\n\nUna forma que quizás sea más sencilla\n\n\n#Obtener kappa y la precisión total\ncaret::confusionMatrix(ClassRF, as.factor(extracted_test$id))\n\n## Confusion Matrix and Statistics\n## \n##             Reference\n## Prediction   Suelo Urbano Vegetacion\n##   Suelo         19      0          0\n##   Urbano        10     20          0\n##   Vegetacion     0      0         11\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.8333          \n##                  95% CI : (0.7148, 0.9171)\n##     No Information Rate : 0.4833          \n##     P-Value [Acc &gt; NIR] : 2.029e-08       \n##                                           \n##                   Kappa : 0.7423          \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: Suelo Class: Urbano Class: Vegetacion\n## Sensitivity                0.6552        1.0000            1.0000\n## Specificity                1.0000        0.7500            1.0000\n## Pos Pred Value             1.0000        0.6667            1.0000\n## Neg Pred Value             0.7561        1.0000            1.0000\n## Prevalence                 0.4833        0.3333            0.1833\n## Detection Rate             0.3167        0.3333            0.1833\n## Detection Prevalence       0.3167        0.5000            0.1833\n## Balanced Accuracy          0.8276        0.8750            1.0000\n\n\n\n\nSe pueden calcular estadísticas de las imágenes clasificadas.\n\n\nfreq(ClassRF_raster)\n\n##      value count\n## [1,]     1  1845\n## [2,]     2  4529\n## [3,]     3  1969\n\nhist(ClassRF_raster)\n\n\n\n\n\nSi quisieramos conocer el área ocupada por una categoría\n\n\n#Area en km2\nar&lt;-area(ClassRF_raster)\n\n#Area promedio por pixel en km2\narea_pix&lt;-mean(ar@data@values)\narea_pix\n\n## [1] 0.0003743235\n\n#tamaño lineal por lado del pixel\nsqrt(mean(ar@data@values))\n\n## [1] 0.01934744\n\nresul_areas&lt;-freq(ClassRF_raster)\nresul_areas\n\n##      value count\n## [1,]     1  1845\n## [2,]     2  4529\n## [3,]     3  1969\n\nstr(resul_areas)\n\n##  num [1:3, 1:2] 1 2 3 1845 4529 ...\n##  - attr(*, \"dimnames\")=List of 2\n##   ..$ : NULL\n##   ..$ : chr [1:2] \"value\" \"count\"\n\n#Convertir la lista a data.frame\nfreq_table&lt;-data.frame(matrix(unlist(resul_areas), \n                  nrow=3, \n                  byrow=F))\ncolnames(freq_table)&lt;-c(\"id\",\"num_pix\")\nfreq_table$area_ha &lt;- freq_table$num_pix * (area_pix * 100)\nfreq_table\n\n##   id num_pix   area_ha\n## 1  1    1845  69.06269\n## 2  2    4529 169.53113\n## 3  3    1969  73.70430"
  },
  {
    "objectID": "posts/2020-02-06-clasificacion-supervisada.html#tomar-áreas-de-entrenamiento",
    "href": "posts/2020-02-06-clasificacion-supervisada.html#tomar-áreas-de-entrenamiento",
    "title": "Clasificación supervisada en R",
    "section": "",
    "text": "Para eso vamos a utilizar QGIS"
  },
  {
    "objectID": "posts/2020-02-06-clasificacion-supervisada.html#extracción-de-valores-de-raster-por-polígonos",
    "href": "posts/2020-02-06-clasificacion-supervisada.html#extracción-de-valores-de-raster-por-polígonos",
    "title": "Clasificación supervisada en R",
    "section": "",
    "text": "Cargar los archivos que vamos a utilizar\n\n\nlibrary(raster)\n\n## Warning: package 'raster' was built under R version 3.6.3\n## Loading required package: sp\n\nlibrary(sf)\n\n## Linking to GEOS 3.6.1, GDAL 2.2.3, PROJ 4.9.3\n\nlibrary(curl)\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/Training.zip\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=173AcNuclHuF5Jh39riiNVeg81IbMGtzB\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl::curl_download(dwnld_URL,\n                    destfile = location)\n\n#Extraer el archivo descargado\nunzip(location, \n      exdir = gsub(\"/Training.zip\",\"\",location))\n\n#Substituir .zip por .shp\nlocation &lt;- gsub(\".zip\",\".shp\",location)\n\n#Se pueden utilizar cualquiera de las dos funciones, pero optaremos por st_read\ntraining&lt;-shapefile(location)\n\ntraining&lt;-st_read(location)\n\n## Reading layer `Training' from data source `D:\\Descargas\\Training.shp' using driver `ESRI Shapefile'\n## Simple feature collection with 9 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2346 ymin: 19.64483 xmax: -101.2202 ymax: 19.65714\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/imagen1.tif\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=17PyQnEIICpjNtPP3v59gLEaoY3zzzEcR\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl_download(dwnld_URL,\n                    destfile = location)\n\nS2&lt;-stack(location)\n\nnames(S2)&lt;-c(\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\n\ntraining\n\n## Simple feature collection with 9 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2346 ymin: 19.64483 xmax: -101.2202 ymax: 19.65714\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n##   id ClaseID     DescID                       geometry\n## 1  1       1 Vegetacion POLYGON ((-101.2292 19.6526...\n## 2  2       1 Vegetacion POLYGON ((-101.229 19.65152...\n## 3  3       1 Vegetacion POLYGON ((-101.2257 19.6571...\n## 4  4       2     Urbano POLYGON ((-101.2346 19.6456...\n## 5  5       2     Urbano POLYGON ((-101.2326 19.6504...\n## 6  6       2     Urbano POLYGON ((-101.2332 19.6522...\n## 7  7       3      Suelo POLYGON ((-101.2231 19.6455...\n## 8  8       3      Suelo POLYGON ((-101.2213 19.6557...\n## 9  9       3      Suelo POLYGON ((-101.221 19.65242...\n\nnames(training)\n\n## [1] \"id\"       \"ClaseID\"  \"DescID\"   \"geometry\"\n\ncrs(training)\n\n## [1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\nplot(S2)\n\n\n\n\n\nplot(training[3])\n\n\n\n\n\nplot(S2[[8]])\nplot(training[3], add = T)\n\n\n\n\n\nExtraer los valores de las áreas de entrenamiento ¿Qué es esto?\n\n\nextracted_info &lt;- raster::extract(S2,training)\nhead(extracted_info, n = 1)\n\n## [[1]]\n##       B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## [1,] 86 236 233 519  965 1393 1475 1530   866   533\n## [2,] 67 247 210 459 1167 1399 1448 1495   936   481\n## [3,] 94 215 220 482 1154 1529 1606 1682   892   473\n## [4,] 76 215 217 540 1400 1363 1449 1616   947   551\n\nConvertir la lista de valores a un data.frame\n\n\n#Se usa la notación :: para llamar funciones dentro de determinados paquetes sin necesidad de cargar el paquete mediante library(paquete)\n#Aquí hay que hacer un pequeño truco para poder pasar de list a data.frame\nextracted_info&lt;-purrr::map(1:length(extracted_info), function(i) as.data.frame(extracted_info[[i]]))\n\n#Ponerle nombres a cada lista de valores de acuerdo a la ClaseID\nnames(extracted_info)&lt;-training$DescID\nhead(extracted_info, n = 1)\n\n## $Vegetacion\n##    B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 86 236 233 519  965 1393 1475 1530   866   533\n## 2 67 247 210 459 1167 1399 1448 1495   936   481\n## 3 94 215 220 482 1154 1529 1606 1682   892   473\n## 4 76 215 217 540 1400 1363 1449 1616   947   551\n\n#Ya tenemos la información extraida\nextracted_info&lt;-dplyr::bind_rows(extracted_info, .id = \"id\")\nhead(extracted_info, n = 1)\n\n##           id  B   G   R NIR RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 86 236 233 519 965 1393 1475 1530   866   533\n\n#Cambiar los nombres de las columnas\ncolnames(extracted_info)&lt;-c(\"id\",\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\nhead(extracted_info, n = 1)\n\n##           id  B   G   R NIR RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 86 236 233 519 965 1393 1475 1530   866   533\n\nVeamos como se ven los datos por clase. Vamos a usar ggplot2 para graficar\n\n\nlibrary(ggplot2)\nggplot(extracted_info, aes(x = id, \n                           y = NIR,\n                           col = id)) + \n  geom_point(size = 3, alpha = 0.5) + \n  labs(x = \"DescID\", col = \"DescID\") +\n  theme_bw()\n\n\n\n\n\nPodríamos ver cómo se ven estos valores en cada una de las bandas\n\n\nlibrary(tidyr)\n\n## \n## Attaching package: 'tidyr'\n## The following object is masked from 'package:raster':\n## \n##     extract\n\nlibrary(ggplot2)\nextracted_info %&gt;%\n  pivot_longer(cols = -id, \n               names_to = \"bands\",\n               values_to = \"reflectance\") %&gt;%\nggplot( aes(x = bands, \n            y = reflectance,\n            col = id, \n            group = id)) + \n  geom_point(size = 3, alpha = 0.5) +\n  stat_summary(aes(y = reflectance)\n               , fun.y=mean,\n               geom=\"line\") +\n  labs(x = \"DescID\", \n       y = \"Reflectancia\",\n       col = \"DescID\") +\n  theme_bw()"
  },
  {
    "objectID": "posts/2020-02-06-clasificacion-supervisada.html#clasificación-máxima-verosimilitud-maximum-likelihood",
    "href": "posts/2020-02-06-clasificacion-supervisada.html#clasificación-máxima-verosimilitud-maximum-likelihood",
    "title": "Clasificación supervisada en R",
    "section": "",
    "text": "library(RStoolbox)\n\nClassMLC&lt;-superClass(img = S2,\n           trainData = as(training, 'Spatial'),\n           responseCol = \"DescID\",\n           model = \"mlc\")\n\n## Loading required package: lattice\n\nlibrary(tmap)\n\ntm_shape(ClassMLC$map)+ \n  tm_raster()+\n  tm_layout(scale = .8, \n            legend.position = c(\"right\",\"bottom\"),\n            legend.frame = T,\n            legend.bg.color = \"white\")\n\n\n\n\n\nSi queremos exportar el resultado para abrirlo en QGIS y compararlo con la imagen original\n\n\n# writeRaster(ClassMLC$map,\n#             filename = \"Clasificación_MLC.tif\",\n#             format = \"GTiff\",\n#             dadtaType = \"INT2S\")"
  },
  {
    "objectID": "posts/2020-02-06-clasificacion-supervisada.html#clasificación-árboles-de-decisión",
    "href": "posts/2020-02-06-clasificacion-supervisada.html#clasificación-árboles-de-decisión",
    "title": "Clasificación supervisada en R",
    "section": "",
    "text": "A partir de la información de entrenamiento se genera un agrupamiento de las categorías.\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ncartmodel &lt;- rpart(as.factor(id)~., \n                   data = extracted_info, \n                   method = 'class')\n\nprint(cartmodel)\n\n## n= 102 \n## \n## node), split, n, loss, yval, (yprob)\n##       * denotes terminal node\n## \n## 1) root 102 57 Suelo (0.44117647 0.36274510 0.19607843)  \n##   2) B&lt; 532.5 66 21 Suelo (0.68181818 0.01515152 0.30303030)  \n##     4) R&gt;=720 45  0 Suelo (1.00000000 0.00000000 0.00000000) *\n##     5) R&lt; 720 21  1 Vegetacion (0.00000000 0.04761905 0.95238095) *\n##   3) B&gt;=532.5 36  0 Urbano (0.00000000 1.00000000 0.00000000) *\n\nrpart.plot(cartmodel)\n\n\n\n\n\nAhora utilizamos la información obtenida de los datos de entrenamiento para extrapolarlos a toda la imagen y obtener la clasificación.\n\n\nClassCART &lt;- predict(S2,\n                     cartmodel, \n                     type = \"class\")\ncols &lt;- c(\"light blue\",\"orange\",\"dark green\")\nplot(ClassCART, col = cols)\nlegend(\"bottomright\", \n       legend=as.vector(t(ClassCART@data@attributes[[1]][2])), \n       fill=cols, bg=\"white\")\n\n\n\n\n\n\n\nOtra manera de clasificar utilizando random forest. Yo recomiendo esta opción.\n\n\nFase de entrenamiento\n\n\nlibrary(randomForest)\n\n## randomForest 4.6-14\n## Type rfNews() to see new features/changes/bug fixes.\n## \n## Attaching package: 'randomForest'\n## The following object is masked from 'package:ggplot2':\n## \n##     margin\n\nrfmodel &lt;- randomForest(as.factor(id) ~ ., \n                   method = \"rf\", \n                   data = extracted_info)\n\n#Ver help(train_model_list) para ver todos los modelos disponibles\n#Ver help(randomForest) para ver todos los argumentos disponibles\n\n\nYa obtuvimos el bosque modelos (ya se ajustaron los árboles) Ver el Out of the Bag Error rate de toda la clasificación\n\n\nprint(rfmodel)\n\n## \n## Call:\n##  randomForest(formula = as.factor(id) ~ ., data = extracted_info,      method = \"rf\") \n##                Type of random forest: classification\n##                      Number of trees: 500\n## No. of variables tried at each split: 3\n## \n##         OOB estimate of  error rate: 0.98%\n## Confusion matrix:\n##            Suelo Urbano Vegetacion class.error\n## Suelo         45      0          0  0.00000000\n## Urbano         0     36          1  0.02702703\n## Vegetacion     0      0         20  0.00000000\n\nVer los valores de importancia variable de acuerdo al decremente medio de la precisión. Las variables que tengan un mayor valor serán las que son más importantes para realizar la clasificación.\n\n\nimportance(rfmodel, type = 2)\n\n##       MeanDecreaseGini\n## B           13.8636821\n## G           12.0863197\n## R            7.9227143\n## NIR          7.5493199\n## RE1          1.3290514\n## RE2          0.3323111\n## RE3          0.3444938\n## NNIR         0.8942046\n## SWIR1       12.6556069\n## SWIR2        7.2739039\n\nplot(rfmodel, main=\"Random Forest\")\n\n\n\n\n\nAquí se puede ver el comportamiento del error por clase conforme se aumenta el número de árboles construidos (el tamaño del bosque). Vemos que hay un número en el cual el error se minimiza. Este parámetro se puede indicar a la hora de que construye el modelo (revisar el argumento de “ntree”). Los colores de cada clase están en el mismo orden en el que aparecen en el resumen del modelo; por lo tanto, suelo: se indica en rojo, urbano: azul y vegetación: verde.\n\n\n\n\n\n#Ubicación para guardar la imagen descargada\nlocation &lt;- \"D:/Descargas/Testing.zip\"\n\n#Copiar el link para compartir desde google drive\nGD_share_URL = \"https://drive.google.com/open?id=1fFX9lepmSWEm8wYDv2CEUnPH4LwMy19H\"\n\n# Reemplazar \"open?\" con \"us?export=download&\"\ndwnld_URL &lt;- gsub(\"open\\\\?\", \"uc\\\\?export=download\\\\&\", GD_share_URL )\ndl &lt;- curl::curl_download(dwnld_URL,\n                    destfile = location)\n\n#Extraer el archivo descargado\nunzip(location, \n      exdir = gsub(\"/Testing.zip\",\"\",location))\n\n#Substituir .zip por .shp\nlocation &lt;- gsub(\".zip\",\".shp\",location)\n\ntesting&lt;-st_read(location)\n\n## Reading layer `Testing' from data source `D:\\Descargas\\Testing.shp' using driver `ESRI Shapefile'\n## Simple feature collection with 6 features and 3 fields\n## geometry type:  POLYGON\n## dimension:      XY\n## bbox:           xmin: -101.2352 ymin: 19.64641 xmax: -101.2196 ymax: 19.65617\n## epsg (SRID):    4326\n## proj4string:    +proj=longlat +datum=WGS84 +no_defs\n\nYa tenemos los datos de validación, así que vamos a correr el modelo para estos datos\n\n\nextracted_test &lt;- raster::extract(S2,testing)\n\n#Se usa la notación :: para llamar funciones dentro de determinados paquetes sin necesidad de cargar el paquete mediante library(paquete)\n#Aquí hay que hacer un pequeño truco para poder pasar de list a data.frame\nextracted_test&lt;-purrr::map(1:length(extracted_test), function(i) as.data.frame(extracted_test[[i]]))\n\n#Ponerle nombres a cada lista de valores de acuerdo a la ClaseID\nnames(extracted_test)&lt;-testing$DescID\nhead(extracted_test, n = 1)\n\n## $Vegetacion\n##     B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 103 297 248 544 1191 1459 1528 1648  1137   667\n## 2 156 311 284 535 1146 1336 1331 1384  1029   660\n## 3 114 227 235 391  684  784  794  843   832   573\n## 4 194 320 351 502  765  910  954 1056   887   637\n\n#Ya tenemos la información extraida\nextracted_test&lt;-dplyr::bind_rows(extracted_test, .id = \"id\")\nhead(extracted_test, n = 1)\n\n##           id   B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 103 297 248 544 1191 1459 1528 1648  1137   667\n\n#Cambiar los nombres de las columnas\ncolnames(extracted_test)&lt;-c(\"id\",\"B\",\"G\",\"R\",\"NIR\",\"RE1\",\"RE2\",\"RE3\",\"NNIR\",\"SWIR1\",\"SWIR2\")\nhead(extracted_test, n = 1)\n\n##           id   B   G   R NIR  RE1  RE2  RE3 NNIR SWIR1 SWIR2\n## 1 Vegetacion 103 297 248 544 1191 1459 1528 1648  1137   667\n\nYa tenemos los datos extraidos del raster para la verificación, así que procedemos a correr el modelo para esos datos. Y vemos su matriz de error\n\n\nClassRF &lt;- predict(rfmodel, extracted_test)\nconfusion_matrix&lt;-table(ClassRF, extracted_test$id)\nconfusion_matrix\n\n##             \n## ClassRF      Suelo Urbano Vegetacion\n##   Suelo         19      0          0\n##   Urbano        10     20          0\n##   Vegetacion     0      0         11\n\n\n\n\nAquí ya obtenemos la imagen clasificada\n\n\nClassRF_raster &lt;- predict(S2,\n                     rfmodel)\nplot(ClassRF_raster)\n\n\n\n\n\nClassRF_raster@data@attributes[[1]]\n\n##   ID      value\n## 1  1      Suelo\n## 2  2     Urbano\n## 3  3 Vegetacion\n\n\n\n\nAhora ya que tenemos todo deberíamos conocer cuál es la precisión del método\n\n\n#Obtenemos el número de observaciones en los datos de validación\nn_test &lt;- nrow(extracted_test)\n#Obtenemos el número de clases en los datos de validación\nn_clases &lt;- length(levels(extracted_test$id))\n\noverall_accuracy &lt;- sum(diag(confusion_matrix)) / n_test\noverall_accuracy\n\n## [1] 0.8333333\n\n#Realizar sumas por renglones en la matriz de error\n#Obtener la precisión del usuario\nusers_accuracy &lt;- sapply(1:nrow(confusion_matrix), function(i){\n  confusion_matrix[i,i] / sum( confusion_matrix[i,])\n})\nnames(users_accuracy) &lt;- colnames(confusion_matrix)\nusers_accuracy\n\n##      Suelo     Urbano Vegetacion \n##  1.0000000  0.6666667  1.0000000\n\n#Obtener la precisión del producto\nproducers_accuracy &lt;- sapply(1:nrow(confusion_matrix), function(i){\n  confusion_matrix[i,i] / sum( confusion_matrix[,i])\n})\nnames(producers_accuracy) &lt;- row.names(confusion_matrix)\nproducers_accuracy\n\n##      Suelo     Urbano Vegetacion \n##  0.6551724  1.0000000  1.0000000\n\nUna forma que quizás sea más sencilla\n\n\n#Obtener kappa y la precisión total\ncaret::confusionMatrix(ClassRF, as.factor(extracted_test$id))\n\n## Confusion Matrix and Statistics\n## \n##             Reference\n## Prediction   Suelo Urbano Vegetacion\n##   Suelo         19      0          0\n##   Urbano        10     20          0\n##   Vegetacion     0      0         11\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.8333          \n##                  95% CI : (0.7148, 0.9171)\n##     No Information Rate : 0.4833          \n##     P-Value [Acc &gt; NIR] : 2.029e-08       \n##                                           \n##                   Kappa : 0.7423          \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: Suelo Class: Urbano Class: Vegetacion\n## Sensitivity                0.6552        1.0000            1.0000\n## Specificity                1.0000        0.7500            1.0000\n## Pos Pred Value             1.0000        0.6667            1.0000\n## Neg Pred Value             0.7561        1.0000            1.0000\n## Prevalence                 0.4833        0.3333            0.1833\n## Detection Rate             0.3167        0.3333            0.1833\n## Detection Prevalence       0.3167        0.5000            0.1833\n## Balanced Accuracy          0.8276        0.8750            1.0000\n\n\n\n\nSe pueden calcular estadísticas de las imágenes clasificadas.\n\n\nfreq(ClassRF_raster)\n\n##      value count\n## [1,]     1  1845\n## [2,]     2  4529\n## [3,]     3  1969\n\nhist(ClassRF_raster)\n\n\n\n\n\nSi quisieramos conocer el área ocupada por una categoría\n\n\n#Area en km2\nar&lt;-area(ClassRF_raster)\n\n#Area promedio por pixel en km2\narea_pix&lt;-mean(ar@data@values)\narea_pix\n\n## [1] 0.0003743235\n\n#tamaño lineal por lado del pixel\nsqrt(mean(ar@data@values))\n\n## [1] 0.01934744\n\nresul_areas&lt;-freq(ClassRF_raster)\nresul_areas\n\n##      value count\n## [1,]     1  1845\n## [2,]     2  4529\n## [3,]     3  1969\n\nstr(resul_areas)\n\n##  num [1:3, 1:2] 1 2 3 1845 4529 ...\n##  - attr(*, \"dimnames\")=List of 2\n##   ..$ : NULL\n##   ..$ : chr [1:2] \"value\" \"count\"\n\n#Convertir la lista a data.frame\nfreq_table&lt;-data.frame(matrix(unlist(resul_areas), \n                  nrow=3, \n                  byrow=F))\ncolnames(freq_table)&lt;-c(\"id\",\"num_pix\")\nfreq_table$area_ha &lt;- freq_table$num_pix * (area_pix * 100)\nfreq_table\n\n##   id num_pix   area_ha\n## 1  1    1845  69.06269\n## 2  2    4529 169.53113\n## 3  3    1969  73.70430"
  },
  {
    "objectID": "GEE.html",
    "href": "GEE.html",
    "title": "GEE",
    "section": "",
    "text": "I made a Google Earth Manual in Spanish, which can be consulted at the following link:\n\nCómo usar Google Earth Engine y no fallar en el intento\n\nThe GitHub page version, as well as the complete files used to build the book, can be consulted in the following repository:\n\nManual de Google Earth Engine\n\nI gave a Google Earth Engine Workshop along with Gabriel Perilla, organized by SELPER - México in July 2021. The videos of this workshop can be seen in the following YouTube link:\n\nGoogle Earth Engine Workshop\n\nAlso, I gave a short course on how to detect floods using Sentinel-1 data in GEE.\n\nGEE floods\n\nI made some Google Earth Engine scripts that can be used to perform cloudless annual mosaics using Landsat 4, 5, 7, and 8 surface reflectance collections, or obtain the number of cloudless observations per pixel using Sentinel-2 images or both Landsat and Sentinel.\n\nCloudlessMosaics\nPerPixelSentinel-2Obs\nLandsat-Sentinel-Obs"
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "My teaching experience includes:\nProfessor at Escuela Nacional de Estudios Superiores Morelia, Universidad Nacional Autónoma de México:\n\nLandscape Cartography.\nGeographic Information Systems II.\n\nProfessor assistant at Escuela Nacional de Estudios Superiores Morelia and Facultad de Ciencias, Universidad Nacional Autónoma de México:\n\nSpatial analysis and modeling.\nSpatial analysis tools.\nGeographic Information Systems and Cartography.\nGeographic Information Systems II.\nApplies Statistics.\nBiostatistics.\n\nAlso, I gave some basic courses to learn R and to use it to perform image processing and analysis. All the courses are in Spanish.\n\nQGIS\nIntroducción a R. Datos de biodiversidad: Repositorio del curso y videos del curso.\nCurso básico de R\nPruebas estadísticas en R"
  },
  {
    "objectID": "figs.html",
    "href": "figs.html",
    "title": "Figures and photos",
    "section": "",
    "text": "Here are some photos, maps or figures I have made:\n\n\n\nCloudless MODIS composite (2015 - 2017) of the Usumacinta basin and surrounding areas. Figure was made in collaboration with C. Peralta-Carreta and can be seen in the Museo de Historia Natural, CDMX, Mexico\n\n\n\n\n\nGoodness-of-fit of the best models (black points) and its corresponding maximum goodness-of-fit distribution expected at random (boxes) for each tropical dry forest attribute (structural and diversity). Models were constructed using GLCM texture metrics calculated from multispectral bands (MS) and panchromatic (Pan) as explanatory variables. Figure from Solórzano et al. (2017).\n\n\n\n\n\nObserved versus modeled values and its corresponding linear fit (dashed line) of the best model for each vegetation attribute (ln-transformed) of a Tropical Swamp Forest. Models were fitted using image GLCM texture metric as explanatory variables. Figure from Solórzano et al. (2018).\n\n\n\n\n\nRDA ordination showing the scores of the species abundance (gray letters), plots (black numbers) and environmental proxies (black letters) according to the RDA first two principal axes; although, the second axis was not significant. Environmental proxies included distance to water bodies and microtopography variables. Figure from Solórzano et al. (2020).\n\n\n\n\n\nTree cover area lost between 2000 and 2016 according to the Global Forest Change data in the Usumacinta River basin. Data are grouped by land cover / land use (Serie II, INEGI 2001) and part of the basin (low, mid, high). Figure from Peralta-Carreta et al. (2019).\n\n\n\n\n\nNumber of available Landsat (4-8) images by path (upper border) and row (right border) of Mexico’s surface between 1972 - 2017. Additionally, the percentage of images by cloud cover percentage is shown by the bar color. Figure from Solórzano et al. (2020).\n\n\n\n\n\nPlots location where conserved and degraded tropical dry forest was sampled in the Ayuquila River basin. Figure from Gao et al. (2020).\n\n\n\n\n\nLand use land cover map obtained using Sentinel-1 and Sentinel-2 imagery and a U-net architecture. Figure from Solórzano et al. (2021).\n\n\n\n\n\nRGB hillshade of Mexico.\n\n\n\n\n\nMexico’s highest peaks - 3D plot (missing the Nevado de Colima).\n\n\n\n\n\nComparison among different deforestation detection methods using U-Net and SVM with Sentinel-2 (MS) and -1 images (SAR)\n\n\n\n\n\nExample of four NDVI time series where changes were detected using BFAST\n\n\n\n\n\nSpectrograms obtained using different thresholds (columns) for three different hours (rows) and its effect over a acoustic diversity index (final row)\n\n\n\n\n\nTrajectory analysis for land use land cover change associated with avocado orchards using CCDC and landsat images\n\n\n\n\n\nAboveground biomass predictions and its variation based on LiDAR metrics (ALS) using a random forest algorithm."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I am a biologist/geographer interested in studying tropical forests and their changes using remote sensing, from a discrete perspective (land use/land cover) to a continuous one (modeling forest attributes, such as aboveground biomass density [AGBD]). I am currently working as an Associate Researcher at the Centro de Investigaciones en Geografía Ambiental (CIGA), Universidad Nacional Autónoma de México (UNAM).\nI obtained my Bachelor’s and Master’s degrees in Biology, and a PhD in Geography from the UNAM. My research includes evaluating the use of remote sensing information to model structural and diversity forest attributes, and monitor deforestation and forest degradation. I have experience in acquiring in-field forest data, visually interpreting images, working with different types of remote sensing information (e.g., multispectral, SAR and LiDAR point clouds), obtaining different remote sensing metrics (e.g., spectral indices, calculating GLCM and FOTO texture, percentiles), as well as working with different modeling algorithms or techniques (e.g., linear/non-linear models, machine learning and deep learning algorithms).\nI prefer using R or other freely available analysis tools such as QGIS and Google Earth Engine. I believe that using these tools helps in making analyses more transparent and reproducible.\nI made a simple wordcloud plot of the most frequent terms in my publications to give a better idea of my research interests.\n\n\n\nWord cloud analysis of my publications"
  },
  {
    "objectID": "posts/2020-02-06-DEM.html",
    "href": "posts/2020-02-06-DEM.html",
    "title": "Modelos digitales de elevación en R",
    "section": "",
    "text": "Primero cargar la imagen y calcular el NDVI\n\nlibrary(raster)\n## Loading required package: sp\nplot(dem)\n\n\n\ncrs(dem)\n## Coordinate Reference System:\n## Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs \n## WKT2 2019 representation:\n## GEOGCRS[\"WGS 84 (with axis order normalized for visualization)\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"geodetic longitude (Lon)\",east,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433,\n##                 ID[\"EPSG\",9122]]],\n##         AXIS[\"geodetic latitude (Lat)\",north,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433,\n##                 ID[\"EPSG\",9122]]]]\nres(dem)\n## [1] 0.0002694946 0.0002694946\ndim(dem)\n## [1] 55 69  1\n\n\nslope &lt;- terrain(dem, \n                 \"slope\", \n                 unit = \"degrees\", \n                 neighbors=4)\nplot(slope)\n\n\n\n\n\n\nslope &lt;- terrain(dem, \n                 unit = \"degrees\", \n                 neighbors = 4)\nplot(slope)"
  },
  {
    "objectID": "posts/2020-02-06-DEM.html#dem",
    "href": "posts/2020-02-06-DEM.html#dem",
    "title": "Modelos digitales de elevación en R",
    "section": "",
    "text": "Primero cargar la imagen y calcular el NDVI\n\nlibrary(raster)\n## Loading required package: sp\nplot(dem)\n\n\n\ncrs(dem)\n## Coordinate Reference System:\n## Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs \n## WKT2 2019 representation:\n## GEOGCRS[\"WGS 84 (with axis order normalized for visualization)\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"geodetic longitude (Lon)\",east,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433,\n##                 ID[\"EPSG\",9122]]],\n##         AXIS[\"geodetic latitude (Lat)\",north,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433,\n##                 ID[\"EPSG\",9122]]]]\nres(dem)\n## [1] 0.0002694946 0.0002694946\ndim(dem)\n## [1] 55 69  1\n\n\nslope &lt;- terrain(dem, \n                 \"slope\", \n                 unit = \"degrees\", \n                 neighbors=4)\nplot(slope)\n\n\n\n\n\n\nslope &lt;- terrain(dem, \n                 unit = \"degrees\", \n                 neighbors = 4)\nplot(slope)"
  },
  {
    "objectID": "posts/2021-08-23-calculating-image-texture.html",
    "href": "posts/2021-08-23-calculating-image-texture.html",
    "title": "Calculating image texture in R",
    "section": "",
    "text": "Image texture in R\nIn this post I will show you how to calculate image texture in R. These textures have been used to model diversity and structural attributes of different forests with intermediate to very high R^2 values. Image textures are metrics that summarise the pixel’s tone variability in neighboring pixels using a particular window size. Thus, most of these metrics can be thought of variables sensing tone heterogeneity (or homogeneity) in space.\n\n\nImage data\nFirst we will create some dummy data just to make everything reproducible.\nlibrary(raster)\n\n# Multispectral image\nimgmul &lt;- stack(list(raster(matrix(rnorm(25,0.3,0.1),nrow = 5)),\n                     raster(matrix(rnorm(25,0.3,0.05),nrow = 5)),\n                     raster(matrix(rnorm(25,0.2,0.05),nrow = 5)),\n                     raster(matrix(rnorm(25,0.8,0.05),nrow = 5))))\n\n# Get bands of interest, e.g., R and NIR\nimgR&lt;-imgmul[[3]]\nimgNIR&lt;-imgmul[[4]]\nHere’s a preview of the dummy image: imgR.\n\n\n\nDummy image\n\n\n\n\nFOTO\nFourier transformed ordination is a method to calculate image texture that first uses the Fourier transform to summarise the spatial variation using harmonic waves (similar to sin and cos functions). Then, it applies a principal components analysis (PCA) over the previous data and usually works with the first three. Then, the PCA scores of the images are used as independent variables to model the forest attributes (usually measured in-field).\n# Load library\nlibrary(foto)\n\n# Set sizes of moving window size in pixels\nvec_ventMS&lt;-5 \n\n# Calculate FOTO texture metrics\nfoto_resul &lt;- foto(imgR, \n                   window_size = vec_ventMS, \n                   method=\"zones\")\nAfter doing these steps, you will get an object containing three entries: 1) zones, 2) radial spectra and 3) rgb. The first one contains the zones in which the image was divided to calculate the FOTO, the second one contains the radial spectra of the FOTO and finally, the third one contains the three first PCA components. The latter one, the PCA image, contains the information to model the forest’s attributes, so that image is the one that is going to be exported as raster.\n# Make optional plots\n# plot(PC.3)\n# plotRGB(PC_stack,3,2,1,stretch=\"hist\")\n# plotRGB(PC_stack,3,2,1,scale=1)\n\n# Write raster to disk  \nwriteRaster(foto_resul$rgb,\n            paste0(\"R_DN_FOTO_nopad\",vec_ventMS),\n            type=\"INT2S\",\n            format=\"GTiff\",\n            overwrite=T)\nHere’s a preview of the FOTO image.\n\n\n\nFOTO images\n\n\n\n\nGLCM\nGray level co-ocurrence matrix texture is another apporach to calculate image texture. In this approach, the spatial heterogeneity is summarised by eight possible metrics: mean, variance, homogeneity, dissimilarity, contrast, entropy, asymptotic second moment and correlation. Each metric summarises a differnt aspect of image texture. The used approach will calculate these textures in the four possible directions (0°, 45°, 90° and 135 °) from a focal pixel. The other possible directions (180° - 360°) are mirrors of the previous directions. Then, the metrics calculated for each direction are averaged to obtain a single directionless metric.\n# Load library\nlibrary(glcm)\n\n# Set window size: horizontal and vertical dimensions\nventana_h&lt;-9\nventana_v&lt;-9\n\n# Calculate glcm in the four possible directions, transforming the data into 64 levels of gray and using the previously set window\nglcm_R&lt;-glcm(imgR,shift=list(c(0,1), c(1,1), c(1,0), c(1,-1)),\n             n_grey=64,\n             window=c(ventana_v,ventana_h))\n\n# Write to disk\n# This image has 8 bands\nwriteRaster(glcm_R,\n            paste0(\"R_DN_txts\",ventana_h,\"_\",ventana_v),\n            format=\"GTiff\",\n            datatype=\"FLT4S\",\n            overwrite=T)\nHere’s a preview of the GLCM image.\n]"
  },
  {
    "objectID": "posts/2022-02-04-making-maps-in-r.html",
    "href": "posts/2022-02-04-making-maps-in-r.html",
    "title": "Making maps in R",
    "section": "",
    "text": "Making a map in R\nIn this post I will show you how to make a map with a reference map of the location of the study site. To achieve the desired map you will need to load several packages.\ntmap is a package that lets you create plots from spatial information. sf is a package that has a lot of tools to work with vector information. tidyverse contains several packages such as tidyr, dplyr, ggplot2, which contain great functions to wrangle, plot and clean data. stars is a package that contains functions to work with raster information. RStoolbox is a package designed to work with remote sensing information, mainly rasters. cowplot is a package that easily lets you join several plots into a single one. Finally, gridExtra contains several functions designed to conver objects into graphical objects (grob) and arrange several plots into a single one.\nlibrary(tmap)\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(stars)\nlibrary(RStoolbox)\nlibrary(cowplot)\nlibrary(gridExtra)\nThe next step is to load the vector and raster information used for the map. In this case, I will load a Sentinel-2 4 band image (R, G, B, NIR) and several shapes containing the world’s countries, Mexico and Guatemala polygons and a deforested areas shapefile. Finally, I am using st_make_valid to fix invalid geometries in the Guatemala and defor shapefiles.\nmasterIm &lt;- read_stars(\"Sentinel-2_4B.tif\")\n\nworld &lt;- st_read(\"WorldWithoutMX.shp\")\nmx &lt;- st_read(\"Mexico.shp\")\ngt &lt;- st_read(\"Guatemala.shp\")\ngt &lt;- st_make_valid(gt)\n\ndefor &lt;- st_read(\"deforestation.shp\")\ndefor &lt;- st_make_valid(defor)\nNext, I will transform the Sentinel-2 image into a stars object. Sometimes, very large rasters will be read as stars proxy objects, so you need to cast them into a stars object to apply several transformations. Finally, I define an RGB image from the Sentinel-2 one.\n# Transform proxy object into stars\nrgbIm &lt;- st_as_stars(masterIm[,,,3:1])\nrgbIm &lt;- st_rgb(rgbIm,\n                dimension = \"band\",\n                maxColorValue = 6000,\n                use_alpha = FALSE,\n                probs = c(0.02, 0.98), #Probabilities for percent clip\n                stretch = TRUE)\nAdditionally, I wish to create a bounding box polygon so the area covered by the image can be shown in the reference map.\nbox &lt;- st_bbox(rgbIm)\nbox &lt;- c(box[1]+0.2,box[2]+0.2,box[3]-0.2,box[4]-0.2)\nAfterward, the main map is created. Each element will be added to the map by using the tm_shape functions to indicate the source data to plot, followed by a tm_* function indicating the type of object, i.e., raster or filled polygons (tm_fill). Then, the graticules of the map are added using tm_graticules and the scale bar, using tm_scale_bar. Finally, you can make further customisations to the default theme, using tm_layout. Finally, the map is converted to a graphical object (grob) using tmap_grob()\n# Normal map\nplot_im &lt;- tm_shape(rgbIm,\n                    bbox = box) +\n            tm_raster() +\n            tm_shape(gt) +\n            tm_fill(col = \"gray90\",\n                    alpha = 0.95) +\n            tm_shape(defor) +\n            tm_fill(col = \"finid\",\n                    border.col = \"transparent\",\n                    lwd = 2,\n                    legend.show = F,\n                    palette = c(\"1\" = \"firebrick2\", \"2\" = \"yellow2\", \"3\" = \"royalblue\")) +\n            tm_graticules(n.x = 5,\n                          n.y = 5,\n                          labels.show = T,\n                          labels.format = list(fun = function(x){                  \n                            degs &lt;- floor(x)\n                            decs &lt;- (x %% 1)\n                            mins &lt;- floor(decs*60)     \n                            paste0(degs, \"°\", mins, \"\\'\")}),\n                          labels.rot = c(90,0),\n                          labels.cardinal = T,\n                          ticks = T,\n                          lines = F) +\n            tm_layout(legend.only = F,\n                      legend.outside = T,\n                      attr.outside = F,\n                      legend.outside.position = \"right\",\n                      # legend.position = c(0.1,0.7),\n                      # attr.position = c(1.2, -0.05),\n                      between.margin = c(0),\n                      outer.margins = c(0.1),\n                      inner.margins = c(0.1),\n                      fontface = \"bold\",\n                      fontfamily = \"sans\")  +\n            tm_scale_bar(breaks = seq(0,10,5),\n                         position = c(0.35, 0.001),\n                         text.size = 0.6,\n                         text.color = \"white\",\n                         color.dark = \"gray10\",\n                         color.light = \"white\",\n                         just = \"right\",\n                         bg.color = \"gray90\",\n                         bg.alpha = 0.2)\n\nplot_im &lt;- tmap_grob(plot_im)\nOnce the main map has been created, you will need to create the legend of the map. So you can place it in the desired position outside the main map. To do this, you need to draw a map containing the information shown in the legend. Notice that the tm_layout enables a legend.only option to just create an object containing the legend. Then, the legend is converted to a grob.\nlegend_im &lt;- tm_shape(defor) +\n  tm_fill(col = \"finid\",\n          border.col = \"transparent\",\n          lwd = 2,\n          title = \"Type of observation\",\n          labels = c(\"Old-growth forest loss\",\n                     \"Secondary forest or plantation loss\",\n                     \"Loss in the next year\"),\n          palette = c(\"1\" = \"firebrick2\", \"2\" = \"yellow2\", \"3\" = \"royalblue\")) +\n  tm_layout(legend.only = T,\n            legend.outside = T,\n            legend.outside.size = 0.5,\n            attr.outside = F,\n            legend.outside.position = \"right\",\n            # legend.position = c(0.1,0.7),\n            # attr.position = c(1.2, -0.05),\n            between.margin = c(0),\n            outer.margins = c(0.1),\n            inner.margins = c(0.1))  \n\nlegend_im &lt;- tmap_grob(legend_im)\nThen, you will need the bounding box as a spatial feature, so it can be added to the map. Additionally, you need to create an object containing the bounding box to be drawn on the reference map (mx_box).\nbox_shape &lt;- st_bbox(rgbIm) |&gt; \n              st_as_sfc()\n\nmx_box &lt;- st_bbox(mx)\nThe next step is to create the reference or inset map that will show the context of the study area. In this case, this map will show neighboring countries of Mexico, as well as the study site location. Similar to the first map, the result is converted to a grob.\ninset_im &lt;- tm_shape(world,\n                     bbox = mx_box)+\n  tm_polygons(col = \"gray90\") +\n  tm_shape(mx) +\n  tm_polygons(col = \"gray75\") +\n  tm_text(\"COUNTRY\", size = 0.5) +\n  tm_shape(box_shape) +\n  tm_borders(col = \"firebrick2\",\n             lwd = 2) \n\ninset_im &lt;- tmap_grob(inset_im)\nTo have better control of the position of every element in the map, you will need to create an empty plot as base plot, so afterward, all the other elements will be placed over this empty plot. Additionally, you need to create an additional grob with text that shows the datum of the showed data.\n# Create empty plot as base\np1 &lt;- ggplot() +\n  geom_blank() +\n  theme_void()\n\ntexto &lt;- text_grob(label = \"WGS 84\",\n                   size = 8) \nNext, you need to draw all the elements on the empty plot and set its x and y positions, as well as width and height values. All these values are limited to a 0-1 range. However, negative values can be used to reduce the size of certain margins and obtain the desired position.\nexp_plot &lt;- ggdraw(p1) +\n  draw_plot(plot_im,\n            x = -0.17,\n            y = -0.14,\n            hjust = 0,\n            vjust = 0,\n            width = 1,\n            height = 1.2) +\n  draw_plot(inset_im,\n          x = 0.75,\n          y = 0.72,\n          hjust = 0,\n          vjust = 0,\n          width = 0.2,\n          height = 0.2) +\n  draw_plot(legend_im,\n            x = 0.55,\n            y = -0.12,\n            hjust = 0,\n            vjust = 0,\n            width = 0.5,\n            height = 0.8) +\n  draw_plot(texto,\n            x = 0.73,\n            y = 0.1,\n            hjust = 0,\n            vjust = 0,\n            width = 0.2,\n            height = 0.2)\nFinally, you can export the resulting map using save_plot.\nsave_plot(exp_plot,\n          # asp = 1.5,\n          base_width = 20,\n          base_height = 15,\n          units = \"cm\",\n          dpi = 300,\n          filename = \"Map/Map1.jpeg\")\nHere is the resulting map.\n\n\n\nMap of the study site with an inset map."
  },
  {
    "objectID": "posts/2022-02-09-wordcloud-in-r.html",
    "href": "posts/2022-02-09-wordcloud-in-r.html",
    "title": "Wordcloud in R",
    "section": "",
    "text": "Wordclouds in R\nWordclouds are a great way of visualizing the most frequent terms in texts. Additionally, R provides some great tools to convert pdfs into text files and clean the texts, so non-informative terms are ignored (e.g., articles, prepositions, etc.).\n\n\nConverting data from pdf to text\nlibrary(pdftools)\nlibrary(wordcloud)\nlibrary(tm)\nlibrary(tidyverse)\n\n\n# Convert pdf 2 text function\nfiles &lt;- list.files(\"pdf/\",\n                    \"*.pdf\",\n                    full.names = T)\npdfs &lt;- sapply(files, function(x){\n  pdftools::pdf_text(x) %&gt;%\n    paste(sep = \" \") %&gt;%\n    # Remove special characters\n    stringr::str_replace_all(fixed(\"\\n\"), \" \") %&gt;%\n    stringr::str_replace_all(fixed(\"\\r\"), \" \") %&gt;%\n    stringr::str_replace_all(fixed(\"\\t\"), \" \") %&gt;%\n    stringr::str_replace_all(fixed(\"\\\"\"), \" \") %&gt;%\n    paste(sep = \" \", collapse = \" \") %&gt;%\n    stringr::str_squish() %&gt;%\n    stringr::str_replace_all(\"- \", \"\") \n})\n\n# Clean text by removing numbers, spaces, punctuation, etc.\narts_text_clean &lt;- Corpus(VectorSource(pdfs))\n\n# Remove punctutation\narts_text_clean &lt;- tm_map(arts_text_clean, removePunctuation)\n# Pass all word to lowercase\narts_text_clean &lt;- tm_map(arts_text_clean, content_transformer(tolower))\n# Remove numbers\narts_text_clean &lt;- tm_map(arts_text_clean, removeNumbers)\n# Remove spaces\narts_text_clean &lt;- tm_map(arts_text_clean, stripWhitespace)\n# Remove stopwords\narts_text_clean &lt;- tm_map(arts_text_clean, removeWords, stopwords('english'))\narts_text_clean &lt;- tm_map(arts_text_clean, removeWords, stopwords('spanish'))\narts_text_clean &lt;- tm_map(arts_text_clean, removeWords, stopwords('portuguese'))\n\n# Create matrix\narts_text_clean &lt;- TermDocumentMatrix(arts_text_clean) \narts_text_clean &lt;- as.matrix(arts_text_clean) \narts_text_clean &lt;- sort(rowSums(arts_text_clean),decreasing=TRUE) \ndf &lt;- data.frame(word = names(arts_text_clean),freq=arts_text_clean)\n\n# Remove leftover punctuations and words that wish to be omitted\ndf &lt;- df |&gt;\n  # Need to add the freq as I can't remove the hyphen\n  filter(word != \"–\" & word != \"−\" & word != \"•\" & freq != 466 &\n           word != \"crossref\" & word != \"doi\" & word != \"thus\" & word != \"two\" &\n           word != \"one\" & word != \"fig\" & word != \"three\" & word != \"can\" & \n           word != \"may\" & word != \"therefore\" & word != \"first\" & word != \"also\" &\n           word != \"author\" & word != \"journal\" & word != \"among\" & word != \"figure\" &\n           word != \"solórzano\" & word != \"gallardocruz\" & word != \"jiménezlópez\" &\n           word != \"springer\" & word != \"although\" & word != \"however\" & word != \"authors\") |&gt;\n  mutate_at(vars(word), function(x) ifelse(x == \"ecol\", \"ecology\", x)) |&gt;\n  mutate_at(vars(word), function(x) ifelse(x == \"sens\", \"sensing\", x)) |&gt;\n  mutate_at(vars(word), function(x) ifelse(x == \"environ\", \"environment\", x)) |&gt;\n  group_by(word) |&gt;\n  summarise(freq2 = sum(freq))\n\n\nWordcloud\nTo do the wordcloud you will need a dataframe containing the words and its corresponding frequency of appearance. In this case that object is saved as df and contains two columns word and freq2. The rest of the arguments let you choose the minimum frequency shown in the wordplot, the maximum number of words shown in the plot, if a random order should be used, rotation percentage and the colors of the words.\nset.seed(1234) # for reproducibility \n\npng(\"wordcloud.png\",\n    width = 10,\n    height = 10,\n    units = \"cm\",\n    res = 300)\nwordcloud(words = df$word, \n          freq = df$freq2, \n          scale=c(3.5,0.25),\n          min.freq = 20,\n          max.words=200, \n          random.order=FALSE, \n          rot.per=0.35,\n          colors=rev(brewer.pal(6, \"Dark2\")))\ndev.off()\nAn example of a wordplot.\n\n\n\nWordcloud of my publications"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html",
    "href": "posts/2022-02-16-vectores-con-sf.html",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Existen varios paquetes en R que permiten manejar datos espaciales, ya sea en formato de vector o raster. Algunos de ellos incluyen: sp, rgdal, rgeos, sf, stars, raster, terra. Sin embargo, en este curso nos enfocaremos en utilizar sf para el manejo de información vectorial y stars para el manejo de rasters.\n\n\n\n\nsf es un paquete creado para trabajar de manera sencilla con información vectorial.\n\n\n\n\nEl objeto básico en sf es un feature, es decir un rasgo o una característica. Este objeto usualmente contiene una geometría que describe la localización en el espacio de dicho rasgo y que puede contener más atributos que describen otras propiedades del mismo.\n\n\nExisten varios tipos de features de acuerdo a su geometría, los básicos y más comunes son:\n\n\n\nPunto (Point).\n\n\nLínea (Linestring).\n\n\nPolígono (Polygons).\n\n\nMultipunto (Multipoint).\n\n\nMultilínea (Multilinestring).\n\n\nMulitpolígono (Multipolygon).\n\n\nColección de geometrías (Geometrycollection).\n\n\n\nAhora, la geometría de cada rasgo va a estar asociado a un sistema de coordenadas de referencia (CRS). Por lo cual, dicho CRS indicará la proyección de los datos y el datum.\n\n\n\n\n\nTodas las funciones en sf estarán precedidas por st_ que significa spatial type.\n\n\n\n\n\nLos features van a estar organizados en un formato de data.frame, es decir, de una tabla o cuadro de datos. Sin embargo, como las geometrías usualmente no contienen un solo valor, se guardarán en una lista.\n\n\nPara ver un ejemplos carguemos un archivo shapefile.\n\nlibrary(sf)\n## Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package=\"sf\"))\n## Reading layer `nc' from data source \n##   `D:\\JonathanVSV\\Documents\\R\\win-library\\4.2\\sf\\shape\\nc.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\nnc\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\n## First 10 features:\n##     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n## 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n## 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n## 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n## 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n## 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n## 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n## 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n## 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n## 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n## 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n##    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n## 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n## 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n## 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n## 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n## 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n## 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n## 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n## 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n## 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n## 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\nAquí podemos ver la tabla de atributos del archivo, así como el tipo de geometría (multipolígono) y las geometrías de cada entrada. A partir de esta información podemos ver que se trata de una tabla con 100 rasgos con 14 atributos + 1 columna con las geometrías de cada rasgo. Cada renglón de la tabla constituye un simple feature (sf), es decir un rasgo con ciertos atributos y su geometría. La geometría de cada rasgo constituye un simple feature geometry (sfg), mientras que la columna con todas las geometrías de los rasgos, una simple feature geometry list-column (sfc).\n\n\n\n\n\nUn tipo de conversión bastante común es que contemos con una tabla de datos con coordenadas geográficas y ciertos atributos extra que deseamos convertir a sf. Para realizar dicha operación se puede usar la función st_as_sf.\n\n\nPrimero se creará un conjunto de datos de coordenadas y atributos.\n\ntabla &lt;- data.frame(lon = c(-101.2737, -101.0627, -101.15), \n                    lat = c(19.99155, 19.96613, 19.98),\n                    Atributo1 = c(\"A\", \"B\", \"C\"))\ntabla\n##         lon      lat Atributo1\n## 1 -101.2737 19.99155         A\n## 2 -101.0627 19.96613         B\n## 3 -101.1500 19.98000         C\n\nDespués se convierte a sf. Para ello, hay que indicar el CRS de la información, para lo cual se puede consultar los códigos EPSG en https://epsg.io/.\n\nvec1 &lt;- st_as_sf(tabla, \n                 # Nombre de las columnas con coordenadas x y\n                 coords = c( \"lon\", \"lat\"),\n                 # CRS en código EPSG\n                 crs = 4326,\n                 # ¿Quitar columnas con información espacial?\n                 remove = T)\nvec1\n## Simple feature collection with 3 features and 1 field\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -101.2737 ymin: 19.96613 xmax: -101.0627 ymax: 19.99155\n## Geodetic CRS:  WGS 84\n##   Atributo1                   geometry\n## 1         A POINT (-101.2737 19.99155)\n## 2         B POINT (-101.0627 19.96613)\n## 3         C      POINT (-101.15 19.98)\n\nAhora supongamos que queremos hacer un polígono a partir de ese vector.\n\npoly1 &lt;- vec1 %&gt;% \n  # Si se hacen varios polígonos de acuerdo a un atributo\n  # dplyr::group_by() %&gt;% \n  dplyr::summarise() %&gt;%\n  st_cast(\"POLYGON\")\npoly1\n## Simple feature collection with 1 feature and 0 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.2737 ymin: 19.96613 xmax: -101.0627 ymax: 19.99155\n## Geodetic CRS:  WGS 84\n##                         geometry\n## 1 POLYGON ((-101.15 19.98, -1...\n\n\n\n\nPara leer y escribir datos desde archivos externos se utilizan las funciones st_read y st_write. Por ejemplo, carguemos un archivo que viene en el paquete sf:\n\nfilename &lt;- system.file(\"shape/nc.shp\", package=\"sf\")\nnc &lt;- st_read(filename)\n## Reading layer `nc' from data source \n##   `D:\\JonathanVSV\\Documents\\R\\win-library\\4.2\\sf\\shape\\nc.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\nnc\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\n## First 10 features:\n##     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n## 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n## 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n## 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n## 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n## 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n## 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n## 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n## 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n## 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n## 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n##    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n## 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n## 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n## 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n## 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n## 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n## 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n## 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n## 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n## 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n## 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\nPara escribir un vector al disco:\n\nst_write(nc, \n         \"nc_exp.shp\",\n         # sobreescribir si ya existe\n         append = F)\n## Deleting layer `nc_exp' using driver `ESRI Shapefile'\n## Writing layer `nc_exp' to data source `nc_exp.shp' using driver `ESRI Shapefile'\n## Writing 100 features with 14 fields and geometry type Multi Polygon.\n\nLas funciones st_read y st_write contienen más argumentos para definir\n\n\n\n\n\nPor último, el visualizar los datos nos puede dar una muy buena idea de los productos intermedios en un flujo de trabajo o verificar que la información que importamos o exportamos es la correcta. Para ver el objecto sf con todos sus atributos:\n\nplot(nc)\n## Warning: plotting the first 10 out of 14 attributes; use max.plot = 14 to plot\n## all\n\n\n\n\nO para ver algún atributo en particular.\n\nplot(nc[\"AREA\"])\n\n\n\n\n\n\n\n\n\n\nPrimero vamos a cargar información desde mi github.\n\n## [1] \"D:\\\\Descargas\\\\SIGmaterial\\\\16mun.zip\"       \n## [2] \"D:\\\\Descargas\\\\SIGmaterial\\\\MX.zip\"          \n## [3] \"D:\\\\Descargas\\\\SIGmaterial\\\\Mich.zip\"        \n## [4] \"D:\\\\Descargas\\\\SIGmaterial\\\\SerieVI_Mich.zip\"\n##      [,1]                                                              \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.shx\"\n##      [,2]                                                               \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.shx\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.cpg\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.dbf\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.prj\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.shp\"\n##      [,3]                                                             \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.shx\"\n##      [,4]                                                                     \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.shx\"\n\nVeamos qué descargamos.\n\n# Ver qué archivos en la carpeta indicada cumplen con el patrón de \".shp\"\nfiles &lt;- list.files(paste0(getwd(), \"/Data\"), \".shp\")\nfiles\n## [1] \"16mun.shp\"        \"Mexico.shp\"       \"Mich.shp\"         \"roi.shp\"         \n## [5] \"SerieVI_Mich.shp\"\n# Leer los archivos\nmun &lt;- st_read(paste0(getwd(), \"/Data/\",\"16mun.shp\"))\n## Reading layer `16mun' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\16mun.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 113 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -50.89613 ymin: 1983660 xmax: 388695.4 ymax: 2258033\n## Projected CRS: WGS 84 / UTM zone 14N\nmx &lt;- st_read(paste0(getwd(), \"/Data/\",\"Mexico.shp\"))\n## Reading layer `Mexico' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\Mexico.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\nmich &lt;- st_read(paste0(getwd(), \"/Data/\",\"Mich.shp\"))\n## Reading layer `Mich' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\Mich.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\nveg &lt;- st_read(paste0(getwd(), \"/Data/\",\"SerieVI_Mich.shp\"))\n## Reading layer `SerieVI_Mich' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\SerieVI_Mich.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 6529 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\nmun\n## Simple feature collection with 113 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -50.89613 ymin: 1983660 xmax: 388695.4 ymax: 2258033\n## Projected CRS: WGS 84 / UTM zone 14N\n## First 10 features:\n##    CVEGEO CVE_ENT CVE_MUN         NOMGEO                       geometry\n## 1   16001      16     001       Acuitzio MULTIPOLYGON (((256032.1 21...\n## 2   16002      16     002      Aguililla MULTIPOLYGON (((113031.8 21...\n## 3   16003      16     003 Álvaro Obregón MULTIPOLYGON (((290455.6 22...\n## 4   16004      16     004   Angamacutiro MULTIPOLYGON (((222887 2240...\n## 5   16005      16     005      Angangueo MULTIPOLYGON (((365943.8 21...\n## 6   16006      16     006     Apatzingán MULTIPOLYGON (((160165.4 21...\n## 7   16007      16     007          Aporo MULTIPOLYGON (((355615.2 21...\n## 8   16008      16     008         Aquila MULTIPOLYGON (((20860.2 207...\n## 9   16009      16     009           Ario MULTIPOLYGON (((221485.2 21...\n## 10  16010      16     010        Arteaga MULTIPOLYGON (((173820.4 20...\nmx\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\n##   COUNTRY                       geometry\n## 1  Mexico MULTIPOLYGON (((-97.77687 2...\nmich\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\n##   CODIGO    ESTADO                       geometry\n## 1   MX16 Michoacán POLYGON ((-103.4796 18.9672...\nveg\n## Simple feature collection with 6529 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO CLAVE            TIP_ECOV\n## 1                       OTRO RASGO    AH        NO APLICABLE\n## 2                       OTRO RASGO    AH        NO APLICABLE\n## 3                       OTRO RASGO    AH        NO APLICABLE\n## 4                       OTRO RASGO    AH        NO APLICABLE\n## 5                       OTRO RASGO    AH        NO APLICABLE\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BA BOSQUE DE CONÍFERAS\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BP BOSQUE DE CONÍFERAS\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BP BOSQUE DE CONÍFERAS\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA   BPQ BOSQUE DE CONÍFERAS\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA   BPQ BOSQUE DE CONÍFERAS\n##                  TIP_VEG       DESVEG      FASE_VS             OTROS    CAL_POS\n## 1           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 2           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 3           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 4           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 5           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 6       BOSQUE DE OYAMEL     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 7         BOSQUE DE PINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 8         BOSQUE DE PINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 9  BOSQUE DE PINO-ENCINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 10 BOSQUE DE PINO-ENCINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3781 1...\n## 2  MULTIPOLYGON (((-101.3348 1...\n## 3  MULTIPOLYGON (((-101.3585 1...\n## 4  MULTIPOLYGON (((-101.3107 1...\n## 5  MULTIPOLYGON (((-101.4364 1...\n## 6  MULTIPOLYGON (((-101.42 19....\n## 7  MULTIPOLYGON (((-101.2158 1...\n## 8  MULTIPOLYGON (((-100.7489 1...\n## 9  MULTIPOLYGON (((-101.3228 1...\n## 10 MULTIPOLYGON (((-101.3273 1...\n\nVer los gráficos de la información.\n\nplot(mun)\n\n\n\nplot(mx)\n\n\n\nplot(mich)\n\n\n\n# Como está pesada esta capa mostrar sólo un atributo\nplot(veg[\"TIP_ECOV\"])\n\n\n\n\n\n\n\nEn sf existe un conjunto de funciones diseñadas para realizar operaciones con las geometrías de los objetos sf. Aquí revisaremos algunas de las más utilizadas.\n\n\n\n\nComprobar que contiene geometrías válidas\n\nst_is_valid(mx)\n## [1] TRUE\n\nEn caso de que haya geometrías no válidas se puede forzar la eliminación de geometrías no válidas mediante st_make_valid.\n\n\n\n\n\nPara reproyectar una capa a otro CRS simplemente se puede indicar el CRS objetivo o utilizar otra capa para extraer el CRS objetivo mediante st_crs. En este ejemplo, primero veamos el CRS de las capas mun y las demás.\n\nst_crs(mun)\n## Coordinate Reference System:\n##   User input: WGS 84 / UTM zone 14N \n##   wkt:\n## PROJCRS[\"WGS 84 / UTM zone 14N\",\n##     BASEGEOGCRS[\"WGS 84\",\n##         DATUM[\"World Geodetic System 1984\",\n##             ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##                 LENGTHUNIT[\"metre\",1]]],\n##         PRIMEM[\"Greenwich\",0,\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         ID[\"EPSG\",4326]],\n##     CONVERSION[\"UTM zone 14N\",\n##         METHOD[\"Transverse Mercator\",\n##             ID[\"EPSG\",9807]],\n##         PARAMETER[\"Latitude of natural origin\",0,\n##             ANGLEUNIT[\"Degree\",0.0174532925199433],\n##             ID[\"EPSG\",8801]],\n##         PARAMETER[\"Longitude of natural origin\",-99,\n##             ANGLEUNIT[\"Degree\",0.0174532925199433],\n##             ID[\"EPSG\",8802]],\n##         PARAMETER[\"Scale factor at natural origin\",0.9996,\n##             SCALEUNIT[\"unity\",1],\n##             ID[\"EPSG\",8805]],\n##         PARAMETER[\"False easting\",500000,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8806]],\n##         PARAMETER[\"False northing\",0,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8807]]],\n##     CS[Cartesian,2],\n##         AXIS[\"(E)\",east,\n##             ORDER[1],\n##             LENGTHUNIT[\"metre\",1]],\n##         AXIS[\"(N)\",north,\n##             ORDER[2],\n##             LENGTHUNIT[\"metre\",1]],\n##     ID[\"EPSG\",32614]]\nst_crs(mx)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\nst_crs(mich)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\nst_crs(veg)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\n\nVemos que mun está en otro CRS. Para transformar la capa al mismo CRS que las demás capas.\n\nmun &lt;- st_transform(mun, st_crs(mx))\nst_crs(mun)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\n\nVemos que ya se realizó la transformación deseada.\n\n\n\n\n\nPara calcular el área:\n\n# Normalmente el valor de área está en m^2\nst_area(mx)\n## 1.961269e+12 [m^2]\nst_area(mich)\n## 59654936304 [m^2]\n\nRecuerden que estamos trabajando con datos en coordenadas geográficas (no proyectados), por lo que sería mejor idea primero proyectarlos y después calcular su área para obtener medidas cómo el área o distancia. Esto se podría hacer mediante:\n\n# Normalmente el valor de área está en m^2\nmx |&gt;\n  st_transform(32614) |&gt;\n  st_area()\n## 1.98135e+12 [m^2]\n\nMás adelante explicaremos a qué se refiere el operador |&gt; pero por el momento lo podemos interpretar como una función que permite encadenar procesos.\n\n\n\n\n\nRevisar si existe intersección entre dos sf.\n\nst_intersects(mx, mich)\n## Sparse geometry binary predicate list of length 1, where the predicate\n## was `intersects'\n##  1: 1\n\nRetorna un valor por cada feature que contiene cada objeto. Si la salida es (empty) implica que no se intersectan, mientras que cuando la salida contiene números, estos indican para cada feature del objeto 1 con qué features del objeto2 se intersectan.\n\n\nPor el contrario, si se desea extraer la intersección entre dos objetos se usa st_intersection\n\nint_mx_mich &lt;- st_intersection(mx, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\n\n¿Qué creen que será el resultado?\n\nplot(int_mx_mich)\n\n\n\nint_mx_mich\n## Simple feature collection with 1 feature and 3 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\n##   COUNTRY CODIGO    ESTADO                       geometry\n## 1  Mexico   MX16 Michoacán POLYGON ((-103.5775 18.8816...\n\nNoten que la tabla de atributos contiene los atributos del objeto 1 (mx) y del objeto 2 (mich).\n\n\n\n\n\nPara calcular la diferencia:\n\nmx_sin_mich &lt;- st_difference(mx, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\nplot(mx_sin_mich[\"COUNTRY\"])\n\n\n\n\n\n\n\nPara unir varias geometrías en una sola.\n\nmx_con_mich &lt;- st_union(mx_sin_mich, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\nplot(mx_con_mich[\"COUNTRY\"])\n\n\n\n\n\n\n\nPara unir varios polígonos o rasgos espaciales dentro de una misma colección se utiliza la notación de tidyverse para unir tablas, es decir, bind_rows.\n\nmx_con_mich_sinunion &lt;- dplyr::bind_rows(mx_sin_mich, mich)\nmx_con_mich_sinunion\n## Simple feature collection with 2 features and 3 fields\n## Geometry type: GEOMETRY\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\n##   COUNTRY CODIGO    ESTADO                       geometry\n## 1  Mexico   MX16 Michoacán MULTIPOLYGON (((-103.5508 1...\n## 2    &lt;NA&gt;   MX16 Michoacán POLYGON ((-103.4796 18.9672...\nplot(mx_con_mich_sinunion[\"COUNTRY\"])\n\n\n\n\nRegresa Michoacán al polígono completo de México, aunque noten que quedan algunos polígonos basura.\n\n\n\n\n\nSe puede calcular el centroide de un polígono.\n\nmich_centroid &lt;- st_centroid(mich)\n## Warning in st_centroid.sf(mich): st_centroid assumes attributes are constant\n## over geometries of x\nplot(mich_centroid)\n\n\n\n\n\n\n\nAdemás, se puede calcular buffers.\n\n# Normalmente el valor de buffer está en m\nmich_centr_buff &lt;- st_buffer(mich_centroid, \n                             10000)\nplot(mich_centr_buff)\n\n\n\n\n\n\n\n\n\n\nEsta función es bastante utilizada para muestrear una superficie, lo cual es muy utilizado para verificar mapas clasificados u productos similares. Para realizar este muestreo se utiliza la función st_sample.\n\n\n\n\n\n\nEn sf existe un conjunto de funciones diseñadas para realizar operaciones con basados en los atributos de los objetos sf. Aquí revisaremos algunas de las más utilizadas.\n\n\n\n\nEn R existe un paquete llamado tidyverse que contiene un conjunto de paquetes muy útiles para gráficas (ggplot2), limpiar y arreglar bases de datos (tidyr y dplyr), los cuales hacen uso del operador %&gt;% o pipe para concatenar varias funciones de manera más resumida. Esta sintaxis será de mucha ayuda para concatenar un flujo de trabajo o para simplificar el código, lo cual muchas veces facilita su lectura. Por ello, para la mayoría de las operaciones basadas en atributos usaremos el operador %&gt;% para realizar las operaciones. Actualmente, en R &gt; 4.0.0, dicho operador fue incluido en R base como |&gt;.\n\n\n\n\n\nPrimero revisemos parte de los datos, así como los niveles de un atributo. Para consultar los niveles de un atributo lo podemos hacer con la sintaxis tradicional de R o a la manera tidyverse.\n\nlibrary(tidyverse)\n## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n## v ggplot2 3.3.5     v purrr   0.3.4\n## v tibble  3.1.6     v dplyr   1.0.7\n## v tidyr   1.1.4     v stringr 1.4.0\n## v readr   2.1.1     v forcats 0.5.1\n## -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n## x dplyr::filter()     masks stats::filter()\n## x dplyr::lag()        masks stats::lag()\n## x readr::parse_date() masks curl::parse_date()\nhead(veg)\n## Simple feature collection with 6 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.4439 ymin: 19.40706 xmax: -101.3107 ymax: 19.54956\n## Geodetic CRS:  WGS 84\n##                          TIP_INFO CLAVE            TIP_ECOV          TIP_VEG\n## 1                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 2                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 3                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 4                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 5                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 6 ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BA BOSQUE DE CONÍFERAS BOSQUE DE OYAMEL\n##         DESVEG      FASE_VS             OTROS    CAL_POS\n## 1 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 2 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 3 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 4 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 5 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 6     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n##                         geometry\n## 1 MULTIPOLYGON (((-101.3781 1...\n## 2 MULTIPOLYGON (((-101.3348 1...\n## 3 MULTIPOLYGON (((-101.3585 1...\n## 4 MULTIPOLYGON (((-101.3107 1...\n## 5 MULTIPOLYGON (((-101.4364 1...\n## 6 MULTIPOLYGON (((-101.42 19....\n# Ver niveles únicos del atributo TIP_ECOV\nunique(veg$TIP_ECOV)\n##  [1] \"NO APLICABLE\"               \"BOSQUE DE CONÍFERAS\"       \n##  [3] \"BOSQUE DE ENCINO\"           \"VEGETACIÓN INDUCIDA\"       \n##  [5] \"SELVA CADUCIFOLIA\"          \"PASTIZAL\"                  \n##  [7] \"VEGETACIÓN HIDRÓFILA\"       \"MATORRAL XERÓFILO\"         \n##  [9] \"SELVA SUBCADUCIFOLIA\"       \"BOSQUE MESÓFILO DE MONTAÑA\"\n## [11] \"SELVA ESPINOSA\"\n# Lo mismo pero en forma tidyverse\nveg |&gt;\n  select(TIP_ECOV) |&gt;\n  distinct(TIP_ECOV)\n##                      TIP_ECOV\n## 1                NO APLICABLE\n## 2         BOSQUE DE CONÍFERAS\n## 3            BOSQUE DE ENCINO\n## 4         VEGETACIÓN INDUCIDA\n## 5           SELVA CADUCIFOLIA\n## 6                    PASTIZAL\n## 7        VEGETACIÓN HIDRÓFILA\n## 8           MATORRAL XERÓFILO\n## 9        SELVA SUBCADUCIFOLIA\n## 10 BOSQUE MESÓFILO DE MONTAÑA\n## 11             SELVA ESPINOSA\n\nSeleccionemos entonces todos los polígonos de selva caducifolia.\n\n# Lo mismo pero en forma tidyverse\nsbc &lt;- veg |&gt;\n  filter(TIP_ECOV == \"SELVA CADUCIFOLIA\")\nsbc\n## Simple feature collection with 1286 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3513 1...\n## 2  MULTIPOLYGON (((-101.4022 1...\n## 3  MULTIPOLYGON (((-102.8018 1...\n## 4  MULTIPOLYGON (((-102.8374 1...\n## 5  MULTIPOLYGON (((-102.7461 1...\n## 6  MULTIPOLYGON (((-102.7968 1...\n## 7  MULTIPOLYGON (((-102.685 18...\n## 8  MULTIPOLYGON (((-102.7767 1...\n## 9  MULTIPOLYGON (((-102.7778 1...\n## 10 MULTIPOLYGON (((-102.7534 1...\n# Para hacer lo mismo en sintaxis tradicional\nveg[veg$TIP_ECOV == \"SELVA CADUCIFOLIA\",]\n## Simple feature collection with 1286 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                            TIP_INFO   CLAVE          TIP_ECOV\n## 66  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 67  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 192 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 193 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 194 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 262 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 263 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 264 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 265 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 266 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                    TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 66  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 67  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 192 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 193 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 194 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 262 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 263 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 264 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 265 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 266 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                           geometry\n## 66  MULTIPOLYGON (((-101.3513 1...\n## 67  MULTIPOLYGON (((-101.4022 1...\n## 192 MULTIPOLYGON (((-102.8018 1...\n## 193 MULTIPOLYGON (((-102.8374 1...\n## 194 MULTIPOLYGON (((-102.7461 1...\n## 262 MULTIPOLYGON (((-102.7968 1...\n## 263 MULTIPOLYGON (((-102.685 18...\n## 264 MULTIPOLYGON (((-102.7767 1...\n## 265 MULTIPOLYGON (((-102.7778 1...\n## 266 MULTIPOLYGON (((-102.7534 1...\n\nA partir de ahora utilizaremos únicamente la notación “tidy”. También podemos seleccionar entradas a partir de uno o más niveles de algún atributo. El operador %in% indica que se busquen las entradas donde su atributo TIP_ECOV sea alguna de las entradas indicadas en el vector siguiente, es decir: SELVA CADUCIFOLIA o BOSQUE DE CONÍFERAS.\n\n# Lo mismo pero en forma tidyverse\nsbc_bc &lt;- veg |&gt;\n  filter(TIP_ECOV %in% c(\"SELVA CADUCIFOLIA\", \"BOSQUE DE CONÍFERAS\"))\nsbc_bc\n## Simple feature collection with 2346 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.1266 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO  CLAVE            TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BA BOSQUE DE CONÍFERAS\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BP BOSQUE DE CONÍFERAS\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BP BOSQUE DE CONÍFERAS\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/BA BOSQUE DE CONÍFERAS\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/BP BOSQUE DE CONÍFERAS\n##                  TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1       BOSQUE DE OYAMEL   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 2         BOSQUE DE PINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3         BOSQUE DE PINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 7  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 8  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 9       BOSQUE DE OYAMEL SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10        BOSQUE DE PINO SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.42 19....\n## 2  MULTIPOLYGON (((-101.2158 1...\n## 3  MULTIPOLYGON (((-100.7489 1...\n## 4  MULTIPOLYGON (((-101.3228 1...\n## 5  MULTIPOLYGON (((-101.3273 1...\n## 6  MULTIPOLYGON (((-101.2634 1...\n## 7  MULTIPOLYGON (((-101.4312 1...\n## 8  MULTIPOLYGON (((-101.2528 1...\n## 9  MULTIPOLYGON (((-101.4514 1...\n## 10 MULTIPOLYGON (((-101.3691 1...\n\n\n\n\nPara agregar una nueva columna o un nuevo atributo se utiliza la función mutate seguido del nombre del nuevo atributo y de la definición del nuevo atributo de acuerdo a una función o un único valor.\n\nsbc &lt;- sbc |&gt;\n  # as.numeric se utiliza para convertir los valores a numéricos y quitarle la propiedad de units (ver sección cálculo de área). Además, al dividir entre 10000 se pasa de m2 a ha.\n  mutate(area_ha = as.numeric(st_area(sbc)/10000))\nsbc\n## Simple feature collection with 1286 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry    area_ha\n## 1  MULTIPOLYGON (((-101.3513 1...   57.60691\n## 2  MULTIPOLYGON (((-101.4022 1...  156.68668\n## 3  MULTIPOLYGON (((-102.8018 1...  125.93153\n## 4  MULTIPOLYGON (((-102.8374 1...  557.72104\n## 5  MULTIPOLYGON (((-102.7461 1... 2433.63242\n## 6  MULTIPOLYGON (((-102.7968 1...  122.14498\n## 7  MULTIPOLYGON (((-102.685 18... 2680.84067\n## 8  MULTIPOLYGON (((-102.7767 1...   31.28422\n## 9  MULTIPOLYGON (((-102.7778 1...  331.41608\n## 10 MULTIPOLYGON (((-102.7534 1...  102.77817\n\n\n\n\nAhora vamos a filtrar usando variables numéricas. En este caso, para quedarnos con entradas con un área entre 100 y 5000 ha.\n\nsbc_filt &lt;- sbc |&gt;\n  filter(area_ha &lt;= 5000 & area_ha &gt;= 100)\nsbc_filt\n## Simple feature collection with 855 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.9907 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry   area_ha\n## 1  MULTIPOLYGON (((-101.4022 1...  156.6867\n## 2  MULTIPOLYGON (((-102.8018 1...  125.9315\n## 3  MULTIPOLYGON (((-102.8374 1...  557.7210\n## 4  MULTIPOLYGON (((-102.7461 1... 2433.6324\n## 5  MULTIPOLYGON (((-102.7968 1...  122.1450\n## 6  MULTIPOLYGON (((-102.685 18... 2680.8407\n## 7  MULTIPOLYGON (((-102.7778 1...  331.4161\n## 8  MULTIPOLYGON (((-102.7534 1...  102.7782\n## 9  MULTIPOLYGON (((-102.7617 1...  144.2841\n## 10 MULTIPOLYGON (((-102.7179 1...  269.7079\n\nFinalmente, veamos una de las ventajas de usar la sintaxis “tidy”, al concatenar varios procesos para obtener el mismo resultado.\n\nsbc_filt2 &lt;- veg |&gt;\n  filter(TIP_ECOV == \"SELVA CADUCIFOLIA\") |&gt;\n  mutate(area_ha = as.numeric(st_area(sbc)/10000)) |&gt;\n  filter(area_ha &lt;= 5000 & area_ha &gt;= 100)\nsbc_filt2\n## Simple feature collection with 855 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.9907 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry   area_ha\n## 1  MULTIPOLYGON (((-101.4022 1...  156.6867\n## 2  MULTIPOLYGON (((-102.8018 1...  125.9315\n## 3  MULTIPOLYGON (((-102.8374 1...  557.7210\n## 4  MULTIPOLYGON (((-102.7461 1... 2433.6324\n## 5  MULTIPOLYGON (((-102.7968 1...  122.1450\n## 6  MULTIPOLYGON (((-102.685 18... 2680.8407\n## 7  MULTIPOLYGON (((-102.7778 1...  331.4161\n## 8  MULTIPOLYGON (((-102.7534 1...  102.7782\n## 9  MULTIPOLYGON (((-102.7617 1...  144.2841\n## 10 MULTIPOLYGON (((-102.7179 1...  269.7079\n\n\n\nmun_diss &lt;- mun |&gt;\n  # Agrupar por CVE_ENT, lo cual puede ser útil cuando se tienen datos más complejos\n  mutate(area_ha = as.numeric(st_area(mun)/10000)) |&gt;\n  group_by(CVE_ENT) |&gt;\n  # Resumir, se puede aprovechar para resumir un atributo\n  summarise(area_ha = sum(area_ha)) |&gt;\n  st_cast(\"POLYGON\")\nmun_diss\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## # A tibble: 1 x 3\n##   CVE_ENT  area_ha                                                      geometry\n##   &lt;chr&gt;      &lt;dbl&gt;                                                 &lt;POLYGON [°]&gt;\n## 1 16      5877654. ((-101.4021 20.03894, -101.4021 20.03992, -101.4021 20.04014~\nplot(mun_diss)\n\n\n\n\nNoten que los únicos atributos son la variable por la que fueron agrupados los datos y el atributo que se resumió.\n\n\n\n\n\nOtra función bastante utilizada es unir tablas no espaciales a objetos espaciales mediante sus atributos. Así que cargaremos unos datos del censo agropecuario del 2007 desde mi github.\n\ncen_agrop &lt;- read.csv(\"https://github.com/JonathanVSV/CursoSIG/raw/main/material/cag_2007_04.csv\")\n\nVemos que hizo parcialmente la unión. ¿Quién adivina por qué?\n\nmun |&gt;\n  left_join(cen_agrop, \n            by = c(\"NOMGEO\" = \"entidad_y_municipio\"))\n## Simple feature collection with 113 features and 11 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##    CVEGEO CVE_ENT CVE_MUN         NOMGEO superficie_total_a\n## 1   16001      16     001       Acuitzio          13430.637\n## 2   16002      16     002      Aguililla         119237.074\n## 3   16003      16     003 Álvaro Obregón                 NA\n## 4   16004      16     004   Angamacutiro          15308.272\n## 5   16005      16     005      Angangueo           2476.861\n## 6   16006      16     006     Apatzingán                 NA\n## 7   16007      16     007          Aporo           3617.149\n## 8   16008      16     008         Aquila          70122.757\n## 9   16009      16     009           Ario          48324.613\n## 10  16010      16     010        Arteaga         236101.807\n##    regimen_de_tenencia_de_la_tierra_ejidal\n## 1                                1349.7480\n## 2                               41364.4160\n## 3                                       NA\n## 4                               11273.3090\n## 5                                2075.7966\n## 6                                       NA\n## 7                                 886.5822\n## 8                                5915.8852\n## 9                               22239.7259\n## 10                              53052.6941\n##    regimen_de_tenencia_de_la_tierra_comunal\n## 1                                   19.2265\n## 2                                    0.0000\n## 3                                        NA\n## 4                                    4.5000\n## 5                                    0.0000\n## 6                                        NA\n## 7                                    0.0000\n## 8                                27862.1605\n## 9                                    0.0000\n## 10                                5028.4367\n##    regimen_de_tenencia_de_la_tierra_privada\n## 1                                12060.5622\n## 2                                77858.5831\n## 3                                        NA\n## 4                                 4026.4626\n## 5                                  400.0645\n## 6                                        NA\n## 7                                 2721.5673\n## 8                                36344.7113\n## 9                                26078.8871\n## 10                              176369.9331\n##    regimen_de_tenencia_de_la_tierra_de_colonia\n## 1                                            0\n## 2                                            0\n## 3                                           NA\n## 4                                            0\n## 5                                            0\n## 6                                           NA\n## 7                                            0\n## 8                                            0\n## 9                                            0\n## 10                                           0\n##    regimen_de_tenencia_de_la_tierra_publica unidad_de_medida\n## 1                                     1.100        hectareas\n## 2                                    14.075        hectareas\n## 3                                        NA             &lt;NA&gt;\n## 4                                     4.000        hectareas\n## 5                                     1.000        hectareas\n## 6                                        NA             &lt;NA&gt;\n## 7                                     9.000        hectareas\n## 8                                     0.000        hectareas\n## 9                                     6.000        hectareas\n## 10                                 1650.744        hectareas\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3251 1...\n## 2  MULTIPOLYGON (((-102.6761 1...\n## 3  MULTIPOLYGON (((-101.0023 1...\n## 4  MULTIPOLYGON (((-101.6524 2...\n## 5  MULTIPOLYGON (((-100.2788 1...\n## 6  MULTIPOLYGON (((-102.2316 1...\n## 7  MULTIPOLYGON (((-100.3776 1...\n## 8  MULTIPOLYGON (((-103.54 18....\n## 9  MULTIPOLYGON (((-101.6504 1...\n## 10 MULTIPOLYGON (((-102.0921 1...\n\nAl parecer el problema está en los caracteres con acentos. Vamos a tener que hacer dos cosas para arreglar los datos. 1) Substituir los acentos por letras sin acentos en mun y substituir la primera letra del nombre del municipio a su equivalente en mayúsculas en cen_agrop.\n\nmun &lt;- mun |&gt;\n  # Aquí pasamos la fórmula al estilo purrr, otro paquete de R\n  # La lógica es indicar una función ~ aplicada a lo que viene antes, indicado por el .x\n  # Sustituimos todas las letras por su equivalente sin acento\n  mutate(across(NOMGEO, ~ str_replace_all(.x, c(\"Á\" = \"A\", \"á\" = \"a\", \"É\" = \"E\", \"é\" = \"e\", \"Í\" = \"I\", \"i\" = \"i\", \"Ó\" = \"O\", \"ó\" = \"o\", \"Ú\" = \"U\", \"u\" = \"u\")))) \n\ncen_agrop &lt;- cen_agrop |&gt;\n  # Vamos a tener que usar Regular Expressions para arreglar otro problema con los datos: algunos no empiezan con mayúsculas. Vamos a hacer esto para cambiar la primera letra de la primera palabra \"^\\\\w{1}\" a mayúscula\n  mutate(across(entidad_y_municipio, ~ str_replace_all(.x, \"^\\\\w{1}\", toupper)))\n\nAhora ya podemos unir los datos de manera correcta.\n\nmun &lt;- mun |&gt;\n  left_join(cen_agrop, \n            by = c(\"NOMGEO\" = \"entidad_y_municipio\")) \n\nUna vez realizado estos pasos, ya obtenemos nuestra capa sf con los atributos de la tabla sin información espacial. Este ejemplo, sirve para demostrar algunas de las capacidades de R para automatizar procesos y limpiar datos. Además, es un ejemplo de la vida real, en el que las bases de datos muchas veces contienen errores o no hay una compatibilidad al 100 % entre distintas bases de datos.\n\n\n\n\n\n\n\nPara generar visualizaciones más avanzadas podemos utilizar otros paquetes como ggplot2 o tmap. Aquí veremos un ejemplo de cada uno.\n\n\n\n\nEn ggplot se puede determinar directamente el color y relleno de cada capa vectorial.\n\nggplot() +\n  # Graficar cada capa por separado con sus características de visualización\n  geom_sf(data = mich, fill = \"gray70\", colour = \"red\") +\n  geom_sf(data = mun, fill = \"transparent\", colour = \"gray40\") +\n  geom_sf(data = sbc, fill = \"orange2\")\n\n\n\n\nSin embargo, también se puede utilizar un atributo de cada capa para determinar el color o relleno de los polígonos\n\nggplot() +\n  # Graficar cada capa por separado con sus características de visualización\n  geom_sf(data = mich, fill = \"gray70\", colour = \"red\") +\n  geom_sf(data = mun, fill = \"transparent\", colour = \"gray40\") +\n  geom_sf(data = sbc_bc, aes(fill = TIP_ECOV)) +\n  # Para sobreescribir valores de relleno por default\n  scale_fill_manual(values = c(\"forestgreen\", \"orange2\"))\n\n\n\n\n\n\n\nLa opción de tmap require de utilizar algún atributo de la información para determinar el color de relleno de cada polígono de acuerdo a los valores de ese atributo. Es similar a ggplot utilizando la opción de aes. Podemos ver algunas de las paletas que ya vienen pre hechas tanto para ggplot como para tmap con tmaptools::palette_explorer()\n\nlibrary(tmap)\n\n# Cargar shapr\ntm_shape(mich) +\n  # Elegir forma de visualización\n  tm_polygons() +\n  tm_shape(mun) +\n  tm_polygons() +\n  tm_shape(sbc_bc) +\n  tm_fill(col = \"TIP_ECOV\", palette = \"-RdYlGn\")"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#features",
    "href": "posts/2022-02-16-vectores-con-sf.html#features",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "El objeto básico en sf es un feature, es decir un rasgo o una característica. Este objeto usualmente contiene una geometría que describe la localización en el espacio de dicho rasgo y que puede contener más atributos que describen otras propiedades del mismo.\n\n\nExisten varios tipos de features de acuerdo a su geometría, los básicos y más comunes son:\n\n\n\nPunto (Point).\n\n\nLínea (Linestring).\n\n\nPolígono (Polygons).\n\n\nMultipunto (Multipoint).\n\n\nMultilínea (Multilinestring).\n\n\nMulitpolígono (Multipolygon).\n\n\nColección de geometrías (Geometrycollection).\n\n\n\nAhora, la geometría de cada rasgo va a estar asociado a un sistema de coordenadas de referencia (CRS). Por lo cual, dicho CRS indicará la proyección de los datos y el datum."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#funciones-en-sf",
    "href": "posts/2022-02-16-vectores-con-sf.html#funciones-en-sf",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Todas las funciones en sf estarán precedidas por st_ que significa spatial type."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#estructura-de-datos-sf",
    "href": "posts/2022-02-16-vectores-con-sf.html#estructura-de-datos-sf",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Los features van a estar organizados en un formato de data.frame, es decir, de una tabla o cuadro de datos. Sin embargo, como las geometrías usualmente no contienen un solo valor, se guardarán en una lista.\n\n\nPara ver un ejemplos carguemos un archivo shapefile.\n\nlibrary(sf)\n## Linking to GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1; sf_use_s2() is TRUE\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package=\"sf\"))\n## Reading layer `nc' from data source \n##   `D:\\JonathanVSV\\Documents\\R\\win-library\\4.2\\sf\\shape\\nc.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\nnc\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\n## First 10 features:\n##     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n## 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n## 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n## 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n## 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n## 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n## 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n## 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n## 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n## 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n## 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n##    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n## 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n## 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n## 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n## 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n## 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n## 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n## 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n## 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n## 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n## 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\nAquí podemos ver la tabla de atributos del archivo, así como el tipo de geometría (multipolígono) y las geometrías de cada entrada. A partir de esta información podemos ver que se trata de una tabla con 100 rasgos con 14 atributos + 1 columna con las geometrías de cada rasgo. Cada renglón de la tabla constituye un simple feature (sf), es decir un rasgo con ciertos atributos y su geometría. La geometría de cada rasgo constituye un simple feature geometry (sfg), mientras que la columna con todas las geometrías de los rasgos, una simple feature geometry list-column (sfc)."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#conversión-de-datos-tabulados-a-sf",
    "href": "posts/2022-02-16-vectores-con-sf.html#conversión-de-datos-tabulados-a-sf",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Un tipo de conversión bastante común es que contemos con una tabla de datos con coordenadas geográficas y ciertos atributos extra que deseamos convertir a sf. Para realizar dicha operación se puede usar la función st_as_sf.\n\n\nPrimero se creará un conjunto de datos de coordenadas y atributos.\n\ntabla &lt;- data.frame(lon = c(-101.2737, -101.0627, -101.15), \n                    lat = c(19.99155, 19.96613, 19.98),\n                    Atributo1 = c(\"A\", \"B\", \"C\"))\ntabla\n##         lon      lat Atributo1\n## 1 -101.2737 19.99155         A\n## 2 -101.0627 19.96613         B\n## 3 -101.1500 19.98000         C\n\nDespués se convierte a sf. Para ello, hay que indicar el CRS de la información, para lo cual se puede consultar los códigos EPSG en https://epsg.io/.\n\nvec1 &lt;- st_as_sf(tabla, \n                 # Nombre de las columnas con coordenadas x y\n                 coords = c( \"lon\", \"lat\"),\n                 # CRS en código EPSG\n                 crs = 4326,\n                 # ¿Quitar columnas con información espacial?\n                 remove = T)\nvec1\n## Simple feature collection with 3 features and 1 field\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -101.2737 ymin: 19.96613 xmax: -101.0627 ymax: 19.99155\n## Geodetic CRS:  WGS 84\n##   Atributo1                   geometry\n## 1         A POINT (-101.2737 19.99155)\n## 2         B POINT (-101.0627 19.96613)\n## 3         C      POINT (-101.15 19.98)\n\nAhora supongamos que queremos hacer un polígono a partir de ese vector.\n\npoly1 &lt;- vec1 %&gt;% \n  # Si se hacen varios polígonos de acuerdo a un atributo\n  # dplyr::group_by() %&gt;% \n  dplyr::summarise() %&gt;%\n  st_cast(\"POLYGON\")\npoly1\n## Simple feature collection with 1 feature and 0 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.2737 ymin: 19.96613 xmax: -101.0627 ymax: 19.99155\n## Geodetic CRS:  WGS 84\n##                         geometry\n## 1 POLYGON ((-101.15 19.98, -1..."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#lectura-y-escritura-de-datos",
    "href": "posts/2022-02-16-vectores-con-sf.html#lectura-y-escritura-de-datos",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Para leer y escribir datos desde archivos externos se utilizan las funciones st_read y st_write. Por ejemplo, carguemos un archivo que viene en el paquete sf:\n\nfilename &lt;- system.file(\"shape/nc.shp\", package=\"sf\")\nnc &lt;- st_read(filename)\n## Reading layer `nc' from data source \n##   `D:\\JonathanVSV\\Documents\\R\\win-library\\4.2\\sf\\shape\\nc.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\nnc\n## Simple feature collection with 100 features and 14 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n## Geodetic CRS:  NAD27\n## First 10 features:\n##     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n## 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n## 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n## 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n## 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n## 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n## 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n## 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n## 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n## 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n## 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n##    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n## 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n## 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n## 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n## 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n## 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n## 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n## 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n## 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n## 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n## 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3...\n\nPara escribir un vector al disco:\n\nst_write(nc, \n         \"nc_exp.shp\",\n         # sobreescribir si ya existe\n         append = F)\n## Deleting layer `nc_exp' using driver `ESRI Shapefile'\n## Writing layer `nc_exp' to data source `nc_exp.shp' using driver `ESRI Shapefile'\n## Writing 100 features with 14 fields and geometry type Multi Polygon.\n\nLas funciones st_read y st_write contienen más argumentos para definir"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#visualización-de-datos",
    "href": "posts/2022-02-16-vectores-con-sf.html#visualización-de-datos",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Por último, el visualizar los datos nos puede dar una muy buena idea de los productos intermedios en un flujo de trabajo o verificar que la información que importamos o exportamos es la correcta. Para ver el objecto sf con todos sus atributos:\n\nplot(nc)\n## Warning: plotting the first 10 out of 14 attributes; use max.plot = 14 to plot\n## all\n\n\n\n\nO para ver algún atributo en particular.\n\nplot(nc[\"AREA\"])"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#descargar-información-de-trabajo",
    "href": "posts/2022-02-16-vectores-con-sf.html#descargar-información-de-trabajo",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "Primero vamos a cargar información desde mi github.\n\n## [1] \"D:\\\\Descargas\\\\SIGmaterial\\\\16mun.zip\"       \n## [2] \"D:\\\\Descargas\\\\SIGmaterial\\\\MX.zip\"          \n## [3] \"D:\\\\Descargas\\\\SIGmaterial\\\\Mich.zip\"        \n## [4] \"D:\\\\Descargas\\\\SIGmaterial\\\\SerieVI_Mich.zip\"\n##      [,1]                                                              \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/16mun.shx\"\n##      [,2]                                                               \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.shx\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.cpg\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.dbf\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.prj\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mexico.shp\"\n##      [,3]                                                             \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/Mich.shx\"\n##      [,4]                                                                     \n## [1,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.cpg\"\n## [2,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.dbf\"\n## [3,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.prj\"\n## [4,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.shp\"\n## [5,] \"D:/Drive/Jonathan_trabaggio/Doctorado/R/SIG/Curso/Data/SerieVI_Mich.shx\"\n\nVeamos qué descargamos.\n\n# Ver qué archivos en la carpeta indicada cumplen con el patrón de \".shp\"\nfiles &lt;- list.files(paste0(getwd(), \"/Data\"), \".shp\")\nfiles\n## [1] \"16mun.shp\"        \"Mexico.shp\"       \"Mich.shp\"         \"roi.shp\"         \n## [5] \"SerieVI_Mich.shp\"\n# Leer los archivos\nmun &lt;- st_read(paste0(getwd(), \"/Data/\",\"16mun.shp\"))\n## Reading layer `16mun' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\16mun.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 113 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -50.89613 ymin: 1983660 xmax: 388695.4 ymax: 2258033\n## Projected CRS: WGS 84 / UTM zone 14N\nmx &lt;- st_read(paste0(getwd(), \"/Data/\",\"Mexico.shp\"))\n## Reading layer `Mexico' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\Mexico.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\nmich &lt;- st_read(paste0(getwd(), \"/Data/\",\"Mich.shp\"))\n## Reading layer `Mich' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\Mich.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\nveg &lt;- st_read(paste0(getwd(), \"/Data/\",\"SerieVI_Mich.shp\"))\n## Reading layer `SerieVI_Mich' from data source \n##   `D:\\Drive\\Jonathan_trabaggio\\Doctorado\\R\\SIG\\Curso\\Data\\SerieVI_Mich.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 6529 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\nmun\n## Simple feature collection with 113 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -50.89613 ymin: 1983660 xmax: 388695.4 ymax: 2258033\n## Projected CRS: WGS 84 / UTM zone 14N\n## First 10 features:\n##    CVEGEO CVE_ENT CVE_MUN         NOMGEO                       geometry\n## 1   16001      16     001       Acuitzio MULTIPOLYGON (((256032.1 21...\n## 2   16002      16     002      Aguililla MULTIPOLYGON (((113031.8 21...\n## 3   16003      16     003 Álvaro Obregón MULTIPOLYGON (((290455.6 22...\n## 4   16004      16     004   Angamacutiro MULTIPOLYGON (((222887 2240...\n## 5   16005      16     005      Angangueo MULTIPOLYGON (((365943.8 21...\n## 6   16006      16     006     Apatzingán MULTIPOLYGON (((160165.4 21...\n## 7   16007      16     007          Aporo MULTIPOLYGON (((355615.2 21...\n## 8   16008      16     008         Aquila MULTIPOLYGON (((20860.2 207...\n## 9   16009      16     009           Ario MULTIPOLYGON (((221485.2 21...\n## 10  16010      16     010        Arteaga MULTIPOLYGON (((173820.4 20...\nmx\n## Simple feature collection with 1 feature and 1 field\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\n##   COUNTRY                       geometry\n## 1  Mexico MULTIPOLYGON (((-97.77687 2...\nmich\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\n##   CODIGO    ESTADO                       geometry\n## 1   MX16 Michoacán POLYGON ((-103.4796 18.9672...\nveg\n## Simple feature collection with 6529 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO CLAVE            TIP_ECOV\n## 1                       OTRO RASGO    AH        NO APLICABLE\n## 2                       OTRO RASGO    AH        NO APLICABLE\n## 3                       OTRO RASGO    AH        NO APLICABLE\n## 4                       OTRO RASGO    AH        NO APLICABLE\n## 5                       OTRO RASGO    AH        NO APLICABLE\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BA BOSQUE DE CONÍFERAS\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BP BOSQUE DE CONÍFERAS\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BP BOSQUE DE CONÍFERAS\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA   BPQ BOSQUE DE CONÍFERAS\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA   BPQ BOSQUE DE CONÍFERAS\n##                  TIP_VEG       DESVEG      FASE_VS             OTROS    CAL_POS\n## 1           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 2           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 3           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 4           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 5           NO APLICABLE NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 6       BOSQUE DE OYAMEL     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 7         BOSQUE DE PINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 8         BOSQUE DE PINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 9  BOSQUE DE PINO-ENCINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n## 10 BOSQUE DE PINO-ENCINO     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3781 1...\n## 2  MULTIPOLYGON (((-101.3348 1...\n## 3  MULTIPOLYGON (((-101.3585 1...\n## 4  MULTIPOLYGON (((-101.3107 1...\n## 5  MULTIPOLYGON (((-101.4364 1...\n## 6  MULTIPOLYGON (((-101.42 19....\n## 7  MULTIPOLYGON (((-101.2158 1...\n## 8  MULTIPOLYGON (((-100.7489 1...\n## 9  MULTIPOLYGON (((-101.3228 1...\n## 10 MULTIPOLYGON (((-101.3273 1...\n\nVer los gráficos de la información.\n\nplot(mun)\n\n\n\nplot(mx)\n\n\n\nplot(mich)\n\n\n\n# Como está pesada esta capa mostrar sólo un atributo\nplot(veg[\"TIP_ECOV\"])"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#operaciones-basadas-en-geometrías",
    "href": "posts/2022-02-16-vectores-con-sf.html#operaciones-basadas-en-geometrías",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "En sf existe un conjunto de funciones diseñadas para realizar operaciones con las geometrías de los objetos sf. Aquí revisaremos algunas de las más utilizadas.\n\n\n\n\nComprobar que contiene geometrías válidas\n\nst_is_valid(mx)\n## [1] TRUE\n\nEn caso de que haya geometrías no válidas se puede forzar la eliminación de geometrías no válidas mediante st_make_valid.\n\n\n\n\n\nPara reproyectar una capa a otro CRS simplemente se puede indicar el CRS objetivo o utilizar otra capa para extraer el CRS objetivo mediante st_crs. En este ejemplo, primero veamos el CRS de las capas mun y las demás.\n\nst_crs(mun)\n## Coordinate Reference System:\n##   User input: WGS 84 / UTM zone 14N \n##   wkt:\n## PROJCRS[\"WGS 84 / UTM zone 14N\",\n##     BASEGEOGCRS[\"WGS 84\",\n##         DATUM[\"World Geodetic System 1984\",\n##             ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##                 LENGTHUNIT[\"metre\",1]]],\n##         PRIMEM[\"Greenwich\",0,\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         ID[\"EPSG\",4326]],\n##     CONVERSION[\"UTM zone 14N\",\n##         METHOD[\"Transverse Mercator\",\n##             ID[\"EPSG\",9807]],\n##         PARAMETER[\"Latitude of natural origin\",0,\n##             ANGLEUNIT[\"Degree\",0.0174532925199433],\n##             ID[\"EPSG\",8801]],\n##         PARAMETER[\"Longitude of natural origin\",-99,\n##             ANGLEUNIT[\"Degree\",0.0174532925199433],\n##             ID[\"EPSG\",8802]],\n##         PARAMETER[\"Scale factor at natural origin\",0.9996,\n##             SCALEUNIT[\"unity\",1],\n##             ID[\"EPSG\",8805]],\n##         PARAMETER[\"False easting\",500000,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8806]],\n##         PARAMETER[\"False northing\",0,\n##             LENGTHUNIT[\"metre\",1],\n##             ID[\"EPSG\",8807]]],\n##     CS[Cartesian,2],\n##         AXIS[\"(E)\",east,\n##             ORDER[1],\n##             LENGTHUNIT[\"metre\",1]],\n##         AXIS[\"(N)\",north,\n##             ORDER[2],\n##             LENGTHUNIT[\"metre\",1]],\n##     ID[\"EPSG\",32614]]\nst_crs(mx)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\nst_crs(mich)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\nst_crs(veg)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\n\nVemos que mun está en otro CRS. Para transformar la capa al mismo CRS que las demás capas.\n\nmun &lt;- st_transform(mun, st_crs(mx))\nst_crs(mun)\n## Coordinate Reference System:\n##   User input: WGS 84 \n##   wkt:\n## GEOGCRS[\"WGS 84\",\n##     DATUM[\"World Geodetic System 1984\",\n##         ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n##             LENGTHUNIT[\"metre\",1]]],\n##     PRIMEM[\"Greenwich\",0,\n##         ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     CS[ellipsoidal,2],\n##         AXIS[\"latitude\",north,\n##             ORDER[1],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##         AXIS[\"longitude\",east,\n##             ORDER[2],\n##             ANGLEUNIT[\"degree\",0.0174532925199433]],\n##     ID[\"EPSG\",4326]]\n\nVemos que ya se realizó la transformación deseada.\n\n\n\n\n\nPara calcular el área:\n\n# Normalmente el valor de área está en m^2\nst_area(mx)\n## 1.961269e+12 [m^2]\nst_area(mich)\n## 59654936304 [m^2]\n\nRecuerden que estamos trabajando con datos en coordenadas geográficas (no proyectados), por lo que sería mejor idea primero proyectarlos y después calcular su área para obtener medidas cómo el área o distancia. Esto se podría hacer mediante:\n\n# Normalmente el valor de área está en m^2\nmx |&gt;\n  st_transform(32614) |&gt;\n  st_area()\n## 1.98135e+12 [m^2]\n\nMás adelante explicaremos a qué se refiere el operador |&gt; pero por el momento lo podemos interpretar como una función que permite encadenar procesos.\n\n\n\n\n\nRevisar si existe intersección entre dos sf.\n\nst_intersects(mx, mich)\n## Sparse geometry binary predicate list of length 1, where the predicate\n## was `intersects'\n##  1: 1\n\nRetorna un valor por cada feature que contiene cada objeto. Si la salida es (empty) implica que no se intersectan, mientras que cuando la salida contiene números, estos indican para cada feature del objeto 1 con qué features del objeto2 se intersectan.\n\n\nPor el contrario, si se desea extraer la intersección entre dos objetos se usa st_intersection\n\nint_mx_mich &lt;- st_intersection(mx, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\n\n¿Qué creen que será el resultado?\n\nplot(int_mx_mich)\n\n\n\nint_mx_mich\n## Simple feature collection with 1 feature and 3 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7455 ymin: 17.92189 xmax: -100.057 ymax: 20.40305\n## Geodetic CRS:  WGS 84\n##   COUNTRY CODIGO    ESTADO                       geometry\n## 1  Mexico   MX16 Michoacán POLYGON ((-103.5775 18.8816...\n\nNoten que la tabla de atributos contiene los atributos del objeto 1 (mx) y del objeto 2 (mich).\n\n\n\n\n\nPara calcular la diferencia:\n\nmx_sin_mich &lt;- st_difference(mx, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\nplot(mx_sin_mich[\"COUNTRY\"])\n\n\n\n\n\n\n\nPara unir varias geometrías en una sola.\n\nmx_con_mich &lt;- st_union(mx_sin_mich, mich)\n## Warning: attribute variables are assumed to be spatially constant throughout all\n## geometries\nplot(mx_con_mich[\"COUNTRY\"])\n\n\n\n\n\n\n\nPara unir varios polígonos o rasgos espaciales dentro de una misma colección se utiliza la notación de tidyverse para unir tablas, es decir, bind_rows.\n\nmx_con_mich_sinunion &lt;- dplyr::bind_rows(mx_sin_mich, mich)\nmx_con_mich_sinunion\n## Simple feature collection with 2 features and 3 fields\n## Geometry type: GEOMETRY\n## Dimension:     XY\n## Bounding box:  xmin: -118.4042 ymin: 14.55055 xmax: -86.73862 ymax: 32.71846\n## Geodetic CRS:  WGS 84\n##   COUNTRY CODIGO    ESTADO                       geometry\n## 1  Mexico   MX16 Michoacán MULTIPOLYGON (((-103.5508 1...\n## 2    &lt;NA&gt;   MX16 Michoacán POLYGON ((-103.4796 18.9672...\nplot(mx_con_mich_sinunion[\"COUNTRY\"])\n\n\n\n\nRegresa Michoacán al polígono completo de México, aunque noten que quedan algunos polígonos basura.\n\n\n\n\n\nSe puede calcular el centroide de un polígono.\n\nmich_centroid &lt;- st_centroid(mich)\n## Warning in st_centroid.sf(mich): st_centroid assumes attributes are constant\n## over geometries of x\nplot(mich_centroid)\n\n\n\n\n\n\n\nAdemás, se puede calcular buffers.\n\n# Normalmente el valor de buffer está en m\nmich_centr_buff &lt;- st_buffer(mich_centroid, \n                             10000)\nplot(mich_centr_buff)\n\n\n\n\n\n\n\n\n\n\nEsta función es bastante utilizada para muestrear una superficie, lo cual es muy utilizado para verificar mapas clasificados u productos similares. Para realizar este muestreo se utiliza la función st_sample."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#operaciones-basadas-en-atributos",
    "href": "posts/2022-02-16-vectores-con-sf.html#operaciones-basadas-en-atributos",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "En sf existe un conjunto de funciones diseñadas para realizar operaciones con basados en los atributos de los objetos sf. Aquí revisaremos algunas de las más utilizadas.\n\n\n\n\nEn R existe un paquete llamado tidyverse que contiene un conjunto de paquetes muy útiles para gráficas (ggplot2), limpiar y arreglar bases de datos (tidyr y dplyr), los cuales hacen uso del operador %&gt;% o pipe para concatenar varias funciones de manera más resumida. Esta sintaxis será de mucha ayuda para concatenar un flujo de trabajo o para simplificar el código, lo cual muchas veces facilita su lectura. Por ello, para la mayoría de las operaciones basadas en atributos usaremos el operador %&gt;% para realizar las operaciones. Actualmente, en R &gt; 4.0.0, dicho operador fue incluido en R base como |&gt;.\n\n\n\n\n\nPrimero revisemos parte de los datos, así como los niveles de un atributo. Para consultar los niveles de un atributo lo podemos hacer con la sintaxis tradicional de R o a la manera tidyverse.\n\nlibrary(tidyverse)\n## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n## v ggplot2 3.3.5     v purrr   0.3.4\n## v tibble  3.1.6     v dplyr   1.0.7\n## v tidyr   1.1.4     v stringr 1.4.0\n## v readr   2.1.1     v forcats 0.5.1\n## -- Conflicts ------------------------------------------ tidyverse_conflicts() --\n## x dplyr::filter()     masks stats::filter()\n## x dplyr::lag()        masks stats::lag()\n## x readr::parse_date() masks curl::parse_date()\nhead(veg)\n## Simple feature collection with 6 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -101.4439 ymin: 19.40706 xmax: -101.3107 ymax: 19.54956\n## Geodetic CRS:  WGS 84\n##                          TIP_INFO CLAVE            TIP_ECOV          TIP_VEG\n## 1                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 2                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 3                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 4                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 5                      OTRO RASGO    AH        NO APLICABLE     NO APLICABLE\n## 6 ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BA BOSQUE DE CONÍFERAS BOSQUE DE OYAMEL\n##         DESVEG      FASE_VS             OTROS    CAL_POS\n## 1 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 2 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 3 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 4 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 5 NO APLICABLE NO APLICABLE URBANO CONSTRUIDO Aproximada\n## 6     PRIMARIA      NINGUNO      NO APLICABLE Aproximada\n##                         geometry\n## 1 MULTIPOLYGON (((-101.3781 1...\n## 2 MULTIPOLYGON (((-101.3348 1...\n## 3 MULTIPOLYGON (((-101.3585 1...\n## 4 MULTIPOLYGON (((-101.3107 1...\n## 5 MULTIPOLYGON (((-101.4364 1...\n## 6 MULTIPOLYGON (((-101.42 19....\n# Ver niveles únicos del atributo TIP_ECOV\nunique(veg$TIP_ECOV)\n##  [1] \"NO APLICABLE\"               \"BOSQUE DE CONÍFERAS\"       \n##  [3] \"BOSQUE DE ENCINO\"           \"VEGETACIÓN INDUCIDA\"       \n##  [5] \"SELVA CADUCIFOLIA\"          \"PASTIZAL\"                  \n##  [7] \"VEGETACIÓN HIDRÓFILA\"       \"MATORRAL XERÓFILO\"         \n##  [9] \"SELVA SUBCADUCIFOLIA\"       \"BOSQUE MESÓFILO DE MONTAÑA\"\n## [11] \"SELVA ESPINOSA\"\n# Lo mismo pero en forma tidyverse\nveg |&gt;\n  select(TIP_ECOV) |&gt;\n  distinct(TIP_ECOV)\n##                      TIP_ECOV\n## 1                NO APLICABLE\n## 2         BOSQUE DE CONÍFERAS\n## 3            BOSQUE DE ENCINO\n## 4         VEGETACIÓN INDUCIDA\n## 5           SELVA CADUCIFOLIA\n## 6                    PASTIZAL\n## 7        VEGETACIÓN HIDRÓFILA\n## 8           MATORRAL XERÓFILO\n## 9        SELVA SUBCADUCIFOLIA\n## 10 BOSQUE MESÓFILO DE MONTAÑA\n## 11             SELVA ESPINOSA\n\nSeleccionemos entonces todos los polígonos de selva caducifolia.\n\n# Lo mismo pero en forma tidyverse\nsbc &lt;- veg |&gt;\n  filter(TIP_ECOV == \"SELVA CADUCIFOLIA\")\nsbc\n## Simple feature collection with 1286 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3513 1...\n## 2  MULTIPOLYGON (((-101.4022 1...\n## 3  MULTIPOLYGON (((-102.8018 1...\n## 4  MULTIPOLYGON (((-102.8374 1...\n## 5  MULTIPOLYGON (((-102.7461 1...\n## 6  MULTIPOLYGON (((-102.7968 1...\n## 7  MULTIPOLYGON (((-102.685 18...\n## 8  MULTIPOLYGON (((-102.7767 1...\n## 9  MULTIPOLYGON (((-102.7778 1...\n## 10 MULTIPOLYGON (((-102.7534 1...\n# Para hacer lo mismo en sintaxis tradicional\nveg[veg$TIP_ECOV == \"SELVA CADUCIFOLIA\",]\n## Simple feature collection with 1286 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                            TIP_INFO   CLAVE          TIP_ECOV\n## 66  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 67  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 192 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 193 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 194 ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 262 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 263 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 264 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 265 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 266 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                    TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 66  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 67  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 192 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 193 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 194 SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 262 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 263 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 264 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 265 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 266 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                           geometry\n## 66  MULTIPOLYGON (((-101.3513 1...\n## 67  MULTIPOLYGON (((-101.4022 1...\n## 192 MULTIPOLYGON (((-102.8018 1...\n## 193 MULTIPOLYGON (((-102.8374 1...\n## 194 MULTIPOLYGON (((-102.7461 1...\n## 262 MULTIPOLYGON (((-102.7968 1...\n## 263 MULTIPOLYGON (((-102.685 18...\n## 264 MULTIPOLYGON (((-102.7767 1...\n## 265 MULTIPOLYGON (((-102.7778 1...\n## 266 MULTIPOLYGON (((-102.7534 1...\n\nA partir de ahora utilizaremos únicamente la notación “tidy”. También podemos seleccionar entradas a partir de uno o más niveles de algún atributo. El operador %in% indica que se busquen las entradas donde su atributo TIP_ECOV sea alguna de las entradas indicadas en el vector siguiente, es decir: SELVA CADUCIFOLIA o BOSQUE DE CONÍFERAS.\n\n# Lo mismo pero en forma tidyverse\nsbc_bc &lt;- veg |&gt;\n  filter(TIP_ECOV %in% c(\"SELVA CADUCIFOLIA\", \"BOSQUE DE CONÍFERAS\"))\nsbc_bc\n## Simple feature collection with 2346 features and 8 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.1266 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO  CLAVE            TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BA BOSQUE DE CONÍFERAS\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BP BOSQUE DE CONÍFERAS\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     BP BOSQUE DE CONÍFERAS\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA    BPQ BOSQUE DE CONÍFERAS\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/BA BOSQUE DE CONÍFERAS\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/BP BOSQUE DE CONÍFERAS\n##                  TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1       BOSQUE DE OYAMEL   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 2         BOSQUE DE PINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3         BOSQUE DE PINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 7  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 8  BOSQUE DE PINO-ENCINO   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 9       BOSQUE DE OYAMEL SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10        BOSQUE DE PINO SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n##                          geometry\n## 1  MULTIPOLYGON (((-101.42 19....\n## 2  MULTIPOLYGON (((-101.2158 1...\n## 3  MULTIPOLYGON (((-100.7489 1...\n## 4  MULTIPOLYGON (((-101.3228 1...\n## 5  MULTIPOLYGON (((-101.3273 1...\n## 6  MULTIPOLYGON (((-101.2634 1...\n## 7  MULTIPOLYGON (((-101.4312 1...\n## 8  MULTIPOLYGON (((-101.2528 1...\n## 9  MULTIPOLYGON (((-101.4514 1...\n## 10 MULTIPOLYGON (((-101.3691 1...\n\n\n\n\nPara agregar una nueva columna o un nuevo atributo se utiliza la función mutate seguido del nombre del nuevo atributo y de la definición del nuevo atributo de acuerdo a una función o un único valor.\n\nsbc &lt;- sbc |&gt;\n  # as.numeric se utiliza para convertir los valores a numéricos y quitarle la propiedad de units (ver sección cálculo de área). Además, al dividir entre 10000 se pasa de m2 a ha.\n  mutate(area_ha = as.numeric(st_area(sbc)/10000))\nsbc\n## Simple feature collection with 1286 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.99039 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry    area_ha\n## 1  MULTIPOLYGON (((-101.3513 1...   57.60691\n## 2  MULTIPOLYGON (((-101.4022 1...  156.68668\n## 3  MULTIPOLYGON (((-102.8018 1...  125.93153\n## 4  MULTIPOLYGON (((-102.8374 1...  557.72104\n## 5  MULTIPOLYGON (((-102.7461 1... 2433.63242\n## 6  MULTIPOLYGON (((-102.7968 1...  122.14498\n## 7  MULTIPOLYGON (((-102.685 18... 2680.84067\n## 8  MULTIPOLYGON (((-102.7767 1...   31.28422\n## 9  MULTIPOLYGON (((-102.7778 1...  331.41608\n## 10 MULTIPOLYGON (((-102.7534 1...  102.77817\n\n\n\n\nAhora vamos a filtrar usando variables numéricas. En este caso, para quedarnos con entradas con un área entre 100 y 5000 ha.\n\nsbc_filt &lt;- sbc |&gt;\n  filter(area_ha &lt;= 5000 & area_ha &gt;= 100)\nsbc_filt\n## Simple feature collection with 855 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.9907 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry   area_ha\n## 1  MULTIPOLYGON (((-101.4022 1...  156.6867\n## 2  MULTIPOLYGON (((-102.8018 1...  125.9315\n## 3  MULTIPOLYGON (((-102.8374 1...  557.7210\n## 4  MULTIPOLYGON (((-102.7461 1... 2433.6324\n## 5  MULTIPOLYGON (((-102.7968 1...  122.1450\n## 6  MULTIPOLYGON (((-102.685 18... 2680.8407\n## 7  MULTIPOLYGON (((-102.7778 1...  331.4161\n## 8  MULTIPOLYGON (((-102.7534 1...  102.7782\n## 9  MULTIPOLYGON (((-102.7617 1...  144.2841\n## 10 MULTIPOLYGON (((-102.7179 1...  269.7079\n\nFinalmente, veamos una de las ventajas de usar la sintaxis “tidy”, al concatenar varios procesos para obtener el mismo resultado.\n\nsbc_filt2 &lt;- veg |&gt;\n  filter(TIP_ECOV == \"SELVA CADUCIFOLIA\") |&gt;\n  mutate(area_ha = as.numeric(st_area(sbc)/10000)) |&gt;\n  filter(area_ha &lt;= 5000 & area_ha &gt;= 100)\nsbc_filt2\n## Simple feature collection with 855 features and 9 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7093 ymin: 17.9907 xmax: -100.2101 ymax: 20.37962\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##                           TIP_INFO   CLAVE          TIP_ECOV\n## 1  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSA/SBC SELVA CADUCIFOLIA\n## 2  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 3  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 4  ECOLÓGICA-FLORÍSTICA-FISONÓMICA     SBC SELVA CADUCIFOLIA\n## 5  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 6  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 7  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 8  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 9  ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n## 10 ECOLÓGICA-FLORÍSTICA-FISONÓMICA VSa/SBC SELVA CADUCIFOLIA\n##                   TIP_VEG     DESVEG   FASE_VS        OTROS    CAL_POS\n## 1  SELVA BAJA CADUCIFOLIA SECUNDARIA   ARBÓREA NO APLICABLE Aproximada\n## 2  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 3  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 4  SELVA BAJA CADUCIFOLIA   PRIMARIA   NINGUNO NO APLICABLE Aproximada\n## 5  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 6  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 7  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 8  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 9  SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n## 10 SELVA BAJA CADUCIFOLIA SECUNDARIA ARBUSTIVA NO APLICABLE Aproximada\n##                          geometry   area_ha\n## 1  MULTIPOLYGON (((-101.4022 1...  156.6867\n## 2  MULTIPOLYGON (((-102.8018 1...  125.9315\n## 3  MULTIPOLYGON (((-102.8374 1...  557.7210\n## 4  MULTIPOLYGON (((-102.7461 1... 2433.6324\n## 5  MULTIPOLYGON (((-102.7968 1...  122.1450\n## 6  MULTIPOLYGON (((-102.685 18... 2680.8407\n## 7  MULTIPOLYGON (((-102.7778 1...  331.4161\n## 8  MULTIPOLYGON (((-102.7534 1...  102.7782\n## 9  MULTIPOLYGON (((-102.7617 1...  144.2841\n## 10 MULTIPOLYGON (((-102.7179 1...  269.7079\n\n\n\nmun_diss &lt;- mun |&gt;\n  # Agrupar por CVE_ENT, lo cual puede ser útil cuando se tienen datos más complejos\n  mutate(area_ha = as.numeric(st_area(mun)/10000)) |&gt;\n  group_by(CVE_ENT) |&gt;\n  # Resumir, se puede aprovechar para resumir un atributo\n  summarise(area_ha = sum(area_ha)) |&gt;\n  st_cast(\"POLYGON\")\nmun_diss\n## Simple feature collection with 1 feature and 2 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## # A tibble: 1 x 3\n##   CVE_ENT  area_ha                                                      geometry\n##   &lt;chr&gt;      &lt;dbl&gt;                                                 &lt;POLYGON [°]&gt;\n## 1 16      5877654. ((-101.4021 20.03894, -101.4021 20.03992, -101.4021 20.04014~\nplot(mun_diss)\n\n\n\n\nNoten que los únicos atributos son la variable por la que fueron agrupados los datos y el atributo que se resumió.\n\n\n\n\n\nOtra función bastante utilizada es unir tablas no espaciales a objetos espaciales mediante sus atributos. Así que cargaremos unos datos del censo agropecuario del 2007 desde mi github.\n\ncen_agrop &lt;- read.csv(\"https://github.com/JonathanVSV/CursoSIG/raw/main/material/cag_2007_04.csv\")\n\nVemos que hizo parcialmente la unión. ¿Quién adivina por qué?\n\nmun |&gt;\n  left_join(cen_agrop, \n            by = c(\"NOMGEO\" = \"entidad_y_municipio\"))\n## Simple feature collection with 113 features and 11 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -103.7381 ymin: 17.91491 xmax: -100.063 ymax: 20.39456\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##    CVEGEO CVE_ENT CVE_MUN         NOMGEO superficie_total_a\n## 1   16001      16     001       Acuitzio          13430.637\n## 2   16002      16     002      Aguililla         119237.074\n## 3   16003      16     003 Álvaro Obregón                 NA\n## 4   16004      16     004   Angamacutiro          15308.272\n## 5   16005      16     005      Angangueo           2476.861\n## 6   16006      16     006     Apatzingán                 NA\n## 7   16007      16     007          Aporo           3617.149\n## 8   16008      16     008         Aquila          70122.757\n## 9   16009      16     009           Ario          48324.613\n## 10  16010      16     010        Arteaga         236101.807\n##    regimen_de_tenencia_de_la_tierra_ejidal\n## 1                                1349.7480\n## 2                               41364.4160\n## 3                                       NA\n## 4                               11273.3090\n## 5                                2075.7966\n## 6                                       NA\n## 7                                 886.5822\n## 8                                5915.8852\n## 9                               22239.7259\n## 10                              53052.6941\n##    regimen_de_tenencia_de_la_tierra_comunal\n## 1                                   19.2265\n## 2                                    0.0000\n## 3                                        NA\n## 4                                    4.5000\n## 5                                    0.0000\n## 6                                        NA\n## 7                                    0.0000\n## 8                                27862.1605\n## 9                                    0.0000\n## 10                                5028.4367\n##    regimen_de_tenencia_de_la_tierra_privada\n## 1                                12060.5622\n## 2                                77858.5831\n## 3                                        NA\n## 4                                 4026.4626\n## 5                                  400.0645\n## 6                                        NA\n## 7                                 2721.5673\n## 8                                36344.7113\n## 9                                26078.8871\n## 10                              176369.9331\n##    regimen_de_tenencia_de_la_tierra_de_colonia\n## 1                                            0\n## 2                                            0\n## 3                                           NA\n## 4                                            0\n## 5                                            0\n## 6                                           NA\n## 7                                            0\n## 8                                            0\n## 9                                            0\n## 10                                           0\n##    regimen_de_tenencia_de_la_tierra_publica unidad_de_medida\n## 1                                     1.100        hectareas\n## 2                                    14.075        hectareas\n## 3                                        NA             &lt;NA&gt;\n## 4                                     4.000        hectareas\n## 5                                     1.000        hectareas\n## 6                                        NA             &lt;NA&gt;\n## 7                                     9.000        hectareas\n## 8                                     0.000        hectareas\n## 9                                     6.000        hectareas\n## 10                                 1650.744        hectareas\n##                          geometry\n## 1  MULTIPOLYGON (((-101.3251 1...\n## 2  MULTIPOLYGON (((-102.6761 1...\n## 3  MULTIPOLYGON (((-101.0023 1...\n## 4  MULTIPOLYGON (((-101.6524 2...\n## 5  MULTIPOLYGON (((-100.2788 1...\n## 6  MULTIPOLYGON (((-102.2316 1...\n## 7  MULTIPOLYGON (((-100.3776 1...\n## 8  MULTIPOLYGON (((-103.54 18....\n## 9  MULTIPOLYGON (((-101.6504 1...\n## 10 MULTIPOLYGON (((-102.0921 1...\n\nAl parecer el problema está en los caracteres con acentos. Vamos a tener que hacer dos cosas para arreglar los datos. 1) Substituir los acentos por letras sin acentos en mun y substituir la primera letra del nombre del municipio a su equivalente en mayúsculas en cen_agrop.\n\nmun &lt;- mun |&gt;\n  # Aquí pasamos la fórmula al estilo purrr, otro paquete de R\n  # La lógica es indicar una función ~ aplicada a lo que viene antes, indicado por el .x\n  # Sustituimos todas las letras por su equivalente sin acento\n  mutate(across(NOMGEO, ~ str_replace_all(.x, c(\"Á\" = \"A\", \"á\" = \"a\", \"É\" = \"E\", \"é\" = \"e\", \"Í\" = \"I\", \"i\" = \"i\", \"Ó\" = \"O\", \"ó\" = \"o\", \"Ú\" = \"U\", \"u\" = \"u\")))) \n\ncen_agrop &lt;- cen_agrop |&gt;\n  # Vamos a tener que usar Regular Expressions para arreglar otro problema con los datos: algunos no empiezan con mayúsculas. Vamos a hacer esto para cambiar la primera letra de la primera palabra \"^\\\\w{1}\" a mayúscula\n  mutate(across(entidad_y_municipio, ~ str_replace_all(.x, \"^\\\\w{1}\", toupper)))\n\nAhora ya podemos unir los datos de manera correcta.\n\nmun &lt;- mun |&gt;\n  left_join(cen_agrop, \n            by = c(\"NOMGEO\" = \"entidad_y_municipio\")) \n\nUna vez realizado estos pasos, ya obtenemos nuestra capa sf con los atributos de la tabla sin información espacial. Este ejemplo, sirve para demostrar algunas de las capacidades de R para automatizar procesos y limpiar datos. Además, es un ejemplo de la vida real, en el que las bases de datos muchas veces contienen errores o no hay una compatibilidad al 100 % entre distintas bases de datos."
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#ggplot2",
    "href": "posts/2022-02-16-vectores-con-sf.html#ggplot2",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "En ggplot se puede determinar directamente el color y relleno de cada capa vectorial.\n\nggplot() +\n  # Graficar cada capa por separado con sus características de visualización\n  geom_sf(data = mich, fill = \"gray70\", colour = \"red\") +\n  geom_sf(data = mun, fill = \"transparent\", colour = \"gray40\") +\n  geom_sf(data = sbc, fill = \"orange2\")\n\n\n\n\nSin embargo, también se puede utilizar un atributo de cada capa para determinar el color o relleno de los polígonos\n\nggplot() +\n  # Graficar cada capa por separado con sus características de visualización\n  geom_sf(data = mich, fill = \"gray70\", colour = \"red\") +\n  geom_sf(data = mun, fill = \"transparent\", colour = \"gray40\") +\n  geom_sf(data = sbc_bc, aes(fill = TIP_ECOV)) +\n  # Para sobreescribir valores de relleno por default\n  scale_fill_manual(values = c(\"forestgreen\", \"orange2\"))"
  },
  {
    "objectID": "posts/2022-02-16-vectores-con-sf.html#tmap",
    "href": "posts/2022-02-16-vectores-con-sf.html#tmap",
    "title": "Información espacial en formato vector en R",
    "section": "",
    "text": "La opción de tmap require de utilizar algún atributo de la información para determinar el color de relleno de cada polígono de acuerdo a los valores de ese atributo. Es similar a ggplot utilizando la opción de aes. Podemos ver algunas de las paletas que ya vienen pre hechas tanto para ggplot como para tmap con tmaptools::palette_explorer()\n\nlibrary(tmap)\n\n# Cargar shapr\ntm_shape(mich) +\n  # Elegir forma de visualización\n  tm_polygons() +\n  tm_shape(mun) +\n  tm_polygons() +\n  tm_shape(sbc_bc) +\n  tm_fill(col = \"TIP_ECOV\", palette = \"-RdYlGn\")"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html",
    "href": "posts/2022-03-04-regular-expressions.html",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Regular expressions in R are a very useful way to work with strings and patterns found in them. For this exercise we are going to use the stringr package.\nRegular expressions are expressions that describe patterns in strings. They are very useful to find general patterns instead of having to indicate every possible combination. For example, you can use regular expressions to find letters, numbers and other special characters.\n\n\nUsing regular expressions you need to escape special characters. For example, special characters such as . or \\, need to be escaped with a preceding \\\\. Thus, to look for a point in a string you would use \\\\.. Other specual characters such as punctutaion characters, parentheses and brackets need to be escaped.\n\n\n\nRegular expressions enable looking for groups of characters. For example, letters, numbers, spaces, etc. Such groups of characters are usually written [:group:]. Examples of these groups are:\n[:digit:] # digits\n[:alpha:] # letters\n[:lower:] # lowercase letters\n[:upper:] # uppercase letters\n[:alnum:] # letters and numbers\n[:punct:] # punctuation\n[:graph:] # all the previous\n[:space:] # spaces\n[:blank:] # space and tab\n. # every character\n\n\n\nAdditionally, to indicating groups of characters, you can indicate how many instances of the character or group of characters you are interested in finding. The quantifiers are:\nx? # zero or one\nx* # zero or more\na+ # one or more\nx{n} # n times\nx{n,} # n or more\nx{n,m} # between n and m\nLet’s do a simple example with tidyverse that contains stringr. In this example we will use str_extract that extracts only the first match with the indicated pattern. If you wish to extract all the matches, you might use str_extract_all and then unnest.\nlibrary(tidyverse)\n\ndf1 &lt;- tibble(char = c(\"letters\", \"LETTERS\", 43561, \"lett342\", \"letters321;ok.no\"))\n\ndf1 |&gt;\n  mutate(letter = str_extract(char, \"[:alpha:]\"),\n         letters = str_extract(char, \"[:alpha:]+\"),\n         numbers = str_extract(char, \"[:digit:]+\"),\n         punct = str_extract(char, \"[:punct:]\"))\nResulting in the following:\n## A tibble: 5 x 5\n#  char             letter letters numbers punct\n#  &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;\n#1 letters          l      letters NA      NA   \n#2 LETTERS          L      LETTERS NA      NA   \n#3 43561            NA     NA      43561   NA   \n#4 lett342          l      lett    342     NA   \n#5 letters321;ok.no l      letters 321     ;  \n\n\n\nAdditional expressions can refer to the position of a pattern in a string. For example, if the pattern is at the start or end of the string.\n^x # start of the string\nx$ # end of the string\n\n\n\nIf you are not intereseted in any of the general groups of characters you can create your own group of characters of interest. This can be done with the following expressions.\nx|y # or\n[xy] # one of\n[^xy] # anything but \n[a-f] # range\nContinuing with the example\ndf1 |&gt;\n  mutate(a = str_extract(char, \"[a-f]+\"),\n         b = str_extract(char, \"[e|s]+\"),\n         c = str_extract(char, \"[^t]+\"),\n         d = str_extract(char, \"[ls]+\"))\n## A tibble: 5 x 5\n#  char             a     b     c       d    \n#  &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#1 letters          e     e     le      l    \n#2 LETTERS          NA    NA    LETTERS NA   \n#3 43561            NA    NA    43561   NA   \n#4 lett342          e     e     le      l    \n#5 letters321;ok.no e     e     le      l   \n\n\n\nLookarounds are used to include characters that precede or proceed after the pattern of interest that can help determine the exact pattern we are interested in. There are four lookarounds:\nx(?=y) # x followed by y\nx(?!y)  # x not followed by y\n(?&lt;=y)x # x preceded by y\n(?&lt;!y)x # x not preceded by y\n\n\n\nIn some cases, you are not interested just in extracting a string pattern, but you might want to actually use that precise string (instead of the general pattern). In this cases, you might define groups using () and then refer to each group by its order of appearance.\nFor example, in this case we will replace “lett” for the first group character, which is only an “e”.\ndf1 |&gt;\n  mutate(a = str_replace(char, \"l(e)tt\", \"\\\\1\"))\n## A tibble: 5 x 2\n#  char             a            \n#  &lt;chr&gt;            &lt;chr&gt;        \n#1 letters          eers         \n#2 LETTERS          LETTERS      \n#3 43561            43561        \n#4 lett342          e342         \n#5 letters321;ok.no eers321;ok.no"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#escaping-special-characters",
    "href": "posts/2022-03-04-regular-expressions.html#escaping-special-characters",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Using regular expressions you need to escape special characters. For example, special characters such as . or \\, need to be escaped with a preceding \\\\. Thus, to look for a point in a string you would use \\\\.. Other specual characters such as punctutaion characters, parentheses and brackets need to be escaped."
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#groups-of-characters",
    "href": "posts/2022-03-04-regular-expressions.html#groups-of-characters",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Regular expressions enable looking for groups of characters. For example, letters, numbers, spaces, etc. Such groups of characters are usually written [:group:]. Examples of these groups are:\n[:digit:] # digits\n[:alpha:] # letters\n[:lower:] # lowercase letters\n[:upper:] # uppercase letters\n[:alnum:] # letters and numbers\n[:punct:] # punctuation\n[:graph:] # all the previous\n[:space:] # spaces\n[:blank:] # space and tab\n. # every character"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#quantifiers",
    "href": "posts/2022-03-04-regular-expressions.html#quantifiers",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Additionally, to indicating groups of characters, you can indicate how many instances of the character or group of characters you are interested in finding. The quantifiers are:\nx? # zero or one\nx* # zero or more\na+ # one or more\nx{n} # n times\nx{n,} # n or more\nx{n,m} # between n and m\nLet’s do a simple example with tidyverse that contains stringr. In this example we will use str_extract that extracts only the first match with the indicated pattern. If you wish to extract all the matches, you might use str_extract_all and then unnest.\nlibrary(tidyverse)\n\ndf1 &lt;- tibble(char = c(\"letters\", \"LETTERS\", 43561, \"lett342\", \"letters321;ok.no\"))\n\ndf1 |&gt;\n  mutate(letter = str_extract(char, \"[:alpha:]\"),\n         letters = str_extract(char, \"[:alpha:]+\"),\n         numbers = str_extract(char, \"[:digit:]+\"),\n         punct = str_extract(char, \"[:punct:]\"))\nResulting in the following:\n## A tibble: 5 x 5\n#  char             letter letters numbers punct\n#  &lt;chr&gt;            &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;\n#1 letters          l      letters NA      NA   \n#2 LETTERS          L      LETTERS NA      NA   \n#3 43561            NA     NA      43561   NA   \n#4 lett342          l      lett    342     NA   \n#5 letters321;ok.no l      letters 321     ;"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#position-in-string",
    "href": "posts/2022-03-04-regular-expressions.html#position-in-string",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Additional expressions can refer to the position of a pattern in a string. For example, if the pattern is at the start or end of the string.\n^x # start of the string\nx$ # end of the string"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#more-specific-groups",
    "href": "posts/2022-03-04-regular-expressions.html#more-specific-groups",
    "title": "Regular expressions in R",
    "section": "",
    "text": "If you are not intereseted in any of the general groups of characters you can create your own group of characters of interest. This can be done with the following expressions.\nx|y # or\n[xy] # one of\n[^xy] # anything but \n[a-f] # range\nContinuing with the example\ndf1 |&gt;\n  mutate(a = str_extract(char, \"[a-f]+\"),\n         b = str_extract(char, \"[e|s]+\"),\n         c = str_extract(char, \"[^t]+\"),\n         d = str_extract(char, \"[ls]+\"))\n## A tibble: 5 x 5\n#  char             a     b     c       d    \n#  &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#1 letters          e     e     le      l    \n#2 LETTERS          NA    NA    LETTERS NA   \n#3 43561            NA    NA    43561   NA   \n#4 lett342          e     e     le      l    \n#5 letters321;ok.no e     e     le      l"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#lookarounds",
    "href": "posts/2022-03-04-regular-expressions.html#lookarounds",
    "title": "Regular expressions in R",
    "section": "",
    "text": "Lookarounds are used to include characters that precede or proceed after the pattern of interest that can help determine the exact pattern we are interested in. There are four lookarounds:\nx(?=y) # x followed by y\nx(?!y)  # x not followed by y\n(?&lt;=y)x # x preceded by y\n(?&lt;!y)x # x not preceded by y"
  },
  {
    "objectID": "posts/2022-03-04-regular-expressions.html#general-groups-used-afterwards",
    "href": "posts/2022-03-04-regular-expressions.html#general-groups-used-afterwards",
    "title": "Regular expressions in R",
    "section": "",
    "text": "In some cases, you are not interested just in extracting a string pattern, but you might want to actually use that precise string (instead of the general pattern). In this cases, you might define groups using () and then refer to each group by its order of appearance.\nFor example, in this case we will replace “lett” for the first group character, which is only an “e”.\ndf1 |&gt;\n  mutate(a = str_replace(char, \"l(e)tt\", \"\\\\1\"))\n## A tibble: 5 x 2\n#  char             a            \n#  &lt;chr&gt;            &lt;chr&gt;        \n#1 letters          eers         \n#2 LETTERS          LETTERS      \n#3 43561            43561        \n#4 lett342          e342         \n#5 letters321;ok.no eers321;ok.no"
  },
  {
    "objectID": "posts/2022-10-17-presentations-in-r.html",
    "href": "posts/2022-10-17-presentations-in-r.html",
    "title": "Presentations in R",
    "section": "",
    "text": "Using the xaringan package, you can construct beautiful presentations using R. Essentially, the RMarkdown syntax is used to add text, tables and figures.\n\n\n--- to start a new slide\n-- to show additional content in the same slide (previously hidden).\n\n\nSet titles.\n# Header 1\n# Header 2\n# Header 3\n\n\n\nHighlight words in italic or bold font.\n_italic_, **bold**\n\n\n\nYou can choose between three different types of lists: hyphens, numbered and bullets.\nHyphens\n- a\n- b\nNumbered\n1. a\n2. b\nBullets\n* a\n* b\n\n\n\nAlthough you can add images directly with markdown, I recommend using knitr to include images using r code. This way you can better control the size of the image (instead of using directly its size) and setting other options as its alignment.\n\\`\\`\\`{r echo=F, out.width=\"90%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/test.png\")\n\\`\\`\\`\n\n\n\nThere are two default styles to set the objects inside the slides in a two-column format:\nThe first one puts your slides in two columns with each one expanding aprox. 50 % of the total width of the slide\n.pull-left[\n  your content\n]\n.pull-right[\n  your content\n]\nThe second one puts your slides in two columns with the first expanding aprox. 25 % of the total width of the slide, and the second, 75 %.\n.left-column[\n  your content\n]\n.right-column[\n  your content\n]\n\n\n\nYou can add special slides with a different theme than the default. One commonly used is the ‘inverse’ class, which is the theme used for the starting slide. Additionally, you can set other classes such as ‘center’ or ‘bottom’ or combine them to set the position of the text.\nclass: center, bottom, inverse\n\n\n\nYou can add images as background for certain slides by selecting the image and setting its position and size.\nbackground-image: url(\"img/end.png\")\nbackground-position: 50% 50%\nbackground-size: cover\n\n\n\nYou can use kable inside the knitr package to draw formatted tables.\nknitr::kable(tab1, \n             format = \"html\",\n             table.attr = \"style='width:80%;'\") |&gt;\n  kable_styling(bootstrap_options = c(\"striped\"), \n                full_width = T,\n                font_size = 14) \n\n\n\nYou can add formulas or use mathematica notation using $$ $$ for equations or $ $ for mathematical notations.\n$$OA = \\displaystyle \\frac {TP + TN} {TP + TN + FP + FN}$$\n\n\n\nFinally, when the document is ready, knit the document (string ball icon in Rstudio) to create the html file with the slides.\n\n\n\n\nIn the following code the R code blocks are indicated with ``` instead of the three block quotes\n\n# Title slide\n\n---\ntitle: \"My presentation\"\nauthor: |\n    | Myself\n    | Others\ninstitute: \"My Company\"\ndate: \"27/05/2022\"\noutput:\n  xaringan::moon_reader:\n    css: [default, default-fonts, mystyle.css]\nlib_dir: libs\nnature:\n  highlightStyle: github\nhighlightLines: true\ncountIncrementalSlides: false\n---\n\\`\\`\\`{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(kableExtra)\n\\`\\`\\`\n\n# First slide\n\nText\n\n\\`\\`\\`{r echo=F, out.width=\"50%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/rxar.png\")\n\\`\\`\\`\n\n---\n# Second slide\n\nList:\n  - 1.\n  - 2. \n  - 3.\n  - 4.\n\n# Empty line\n&nbsp;&lt;br&gt;\n\n# Another image\n\n\\`\\`\\`{r echo=F, out.width=\"10%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/xaringan.png\")\n\\`\\`\\`\n\n---\n# Third slide\n\n.pull-left[\ntext at left\n]\n\n.pull-right[\ntext at right\n]\n\n---\n# Fourth slide\n\nA table.\n\n\\`\\`\\`{r echo=F, out.width=\"100%\"}\n\ntab1 &lt;- data.frame(a = 1:4,\n                   b = 4:7,\n                   c = 5:8,\n                   d = 12:15)\n\nknitr::kable(tab1, \n             escape = FALSE, \n             format = \"html\",\n             table.attr = \"style='width:100%;'\",\n             col.names = c(\"0\", \n                           \"1\", \n                           \"2\", \n                           \"3\"),\n             align = c(\"l\", rep(\"r\", 3))) |&gt;\n  kable_styling(bootstrap_options = c(\"striped\"), \n                full_width = T,\n                font_size = 14) |&gt;\n  kableExtra::row_spec(1, extra_css = \"border-top: 1px solid\")\n\\`\\`\\`\n\n---\nbackground-image: url(\"img/r.png\")\nbackground-position: 50% 50%\nbackground-size: cover\nclass: center, bottom, inverse\n\n# ¡Thx!\n\n## contact\nThe result is the following (click on the following broken link image to view the pdf presentation).\n\n\n\nResulting slides"
  },
  {
    "objectID": "posts/2022-10-17-presentations-in-r.html#syntax-summary",
    "href": "posts/2022-10-17-presentations-in-r.html#syntax-summary",
    "title": "Presentations in R",
    "section": "",
    "text": "--- to start a new slide\n-- to show additional content in the same slide (previously hidden).\n\n\nSet titles.\n# Header 1\n# Header 2\n# Header 3\n\n\n\nHighlight words in italic or bold font.\n_italic_, **bold**\n\n\n\nYou can choose between three different types of lists: hyphens, numbered and bullets.\nHyphens\n- a\n- b\nNumbered\n1. a\n2. b\nBullets\n* a\n* b\n\n\n\nAlthough you can add images directly with markdown, I recommend using knitr to include images using r code. This way you can better control the size of the image (instead of using directly its size) and setting other options as its alignment.\n\\`\\`\\`{r echo=F, out.width=\"90%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/test.png\")\n\\`\\`\\`\n\n\n\nThere are two default styles to set the objects inside the slides in a two-column format:\nThe first one puts your slides in two columns with each one expanding aprox. 50 % of the total width of the slide\n.pull-left[\n  your content\n]\n.pull-right[\n  your content\n]\nThe second one puts your slides in two columns with the first expanding aprox. 25 % of the total width of the slide, and the second, 75 %.\n.left-column[\n  your content\n]\n.right-column[\n  your content\n]\n\n\n\nYou can add special slides with a different theme than the default. One commonly used is the ‘inverse’ class, which is the theme used for the starting slide. Additionally, you can set other classes such as ‘center’ or ‘bottom’ or combine them to set the position of the text.\nclass: center, bottom, inverse\n\n\n\nYou can add images as background for certain slides by selecting the image and setting its position and size.\nbackground-image: url(\"img/end.png\")\nbackground-position: 50% 50%\nbackground-size: cover\n\n\n\nYou can use kable inside the knitr package to draw formatted tables.\nknitr::kable(tab1, \n             format = \"html\",\n             table.attr = \"style='width:80%;'\") |&gt;\n  kable_styling(bootstrap_options = c(\"striped\"), \n                full_width = T,\n                font_size = 14) \n\n\n\nYou can add formulas or use mathematica notation using $$ $$ for equations or $ $ for mathematical notations.\n$$OA = \\displaystyle \\frac {TP + TN} {TP + TN + FP + FN}$$\n\n\n\nFinally, when the document is ready, knit the document (string ball icon in Rstudio) to create the html file with the slides."
  },
  {
    "objectID": "posts/2022-10-17-presentations-in-r.html#minimal-example",
    "href": "posts/2022-10-17-presentations-in-r.html#minimal-example",
    "title": "Presentations in R",
    "section": "",
    "text": "In the following code the R code blocks are indicated with ``` instead of the three block quotes\n\n# Title slide\n\n---\ntitle: \"My presentation\"\nauthor: |\n    | Myself\n    | Others\ninstitute: \"My Company\"\ndate: \"27/05/2022\"\noutput:\n  xaringan::moon_reader:\n    css: [default, default-fonts, mystyle.css]\nlib_dir: libs\nnature:\n  highlightStyle: github\nhighlightLines: true\ncountIncrementalSlides: false\n---\n\\`\\`\\`{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(kableExtra)\n\\`\\`\\`\n\n# First slide\n\nText\n\n\\`\\`\\`{r echo=F, out.width=\"50%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/rxar.png\")\n\\`\\`\\`\n\n---\n# Second slide\n\nList:\n  - 1.\n  - 2. \n  - 3.\n  - 4.\n\n# Empty line\n&nbsp;&lt;br&gt;\n\n# Another image\n\n\\`\\`\\`{r echo=F, out.width=\"10%\", fig.align=\"center\"}\nknitr::include_graphics(\"img/xaringan.png\")\n\\`\\`\\`\n\n---\n# Third slide\n\n.pull-left[\ntext at left\n]\n\n.pull-right[\ntext at right\n]\n\n---\n# Fourth slide\n\nA table.\n\n\\`\\`\\`{r echo=F, out.width=\"100%\"}\n\ntab1 &lt;- data.frame(a = 1:4,\n                   b = 4:7,\n                   c = 5:8,\n                   d = 12:15)\n\nknitr::kable(tab1, \n             escape = FALSE, \n             format = \"html\",\n             table.attr = \"style='width:100%;'\",\n             col.names = c(\"0\", \n                           \"1\", \n                           \"2\", \n                           \"3\"),\n             align = c(\"l\", rep(\"r\", 3))) |&gt;\n  kable_styling(bootstrap_options = c(\"striped\"), \n                full_width = T,\n                font_size = 14) |&gt;\n  kableExtra::row_spec(1, extra_css = \"border-top: 1px solid\")\n\\`\\`\\`\n\n---\nbackground-image: url(\"img/r.png\")\nbackground-position: 50% 50%\nbackground-size: cover\nclass: center, bottom, inverse\n\n# ¡Thx!\n\n## contact\nThe result is the following (click on the following broken link image to view the pdf presentation).\n\n\n\nResulting slides"
  },
  {
    "objectID": "posts/2023-01-13-exploratory-data-analysis-in-r.html",
    "href": "posts/2023-01-13-exploratory-data-analysis-in-r.html",
    "title": "Exploratory data analysis in R",
    "section": "",
    "text": "In this post we are going to use two packages designed to perform exploratory data analysis. This is usually the first thing to do with any data base or data frame, to get to know the data, its distribution and possible missing data. These two packages are skimr and dataxray.\n\n\nFor this example, we are going to use flights dataset.\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(nycflights13)\n# devtools::install_github(\"agstn/dataxray\")\nlibrary(dataxray)\n\n# Get flights data\ndata(flights)\n\n\n\nSkimr is a package designed to skim over the data and get a basic description of the data. The information included in this disciption includes:\n\nNumber of rows and columns.\nNumber of variables by type (character, numeric, date).\nNumber and percentage of missing values.\nNumber of unique values (character) or mean, sd and quartiles (numeric).\nHistograms.\n\n# General skim\nflights |&gt;\n  skim()\n\n\n\nExample of skim results\n\n\nYou can also use traditional dplyr syntax to select only particular variables or non missing rows.\n# Select non na entries\nflights |&gt;\n  skim() |&gt;\n  select(-n_missing)\n\n# Skim particular variables\nflights |&gt;\n  skim(air_time)\n\n\n\nDataxray is a package that performs a similar exploratory data analysis to skimr, but its main advantage is that it has an interactive interface and has a fancier design. Nonetheless, it shows almost the same information as skimr; however it takes more time to show the results.\nflights |&gt;\n  # Just to accelerate creation of xray\n  slice(1:50000) |&gt;\n  make_xray() |&gt;\n  view_xray()\n\n\n\nExample of dataxray interface"
  },
  {
    "objectID": "posts/2023-01-13-exploratory-data-analysis-in-r.html#data",
    "href": "posts/2023-01-13-exploratory-data-analysis-in-r.html#data",
    "title": "Exploratory data analysis in R",
    "section": "",
    "text": "For this example, we are going to use flights dataset.\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(nycflights13)\n# devtools::install_github(\"agstn/dataxray\")\nlibrary(dataxray)\n\n# Get flights data\ndata(flights)"
  },
  {
    "objectID": "posts/2023-01-13-exploratory-data-analysis-in-r.html#skimr",
    "href": "posts/2023-01-13-exploratory-data-analysis-in-r.html#skimr",
    "title": "Exploratory data analysis in R",
    "section": "",
    "text": "Skimr is a package designed to skim over the data and get a basic description of the data. The information included in this disciption includes:\n\nNumber of rows and columns.\nNumber of variables by type (character, numeric, date).\nNumber and percentage of missing values.\nNumber of unique values (character) or mean, sd and quartiles (numeric).\nHistograms.\n\n# General skim\nflights |&gt;\n  skim()\n\n\n\nExample of skim results\n\n\nYou can also use traditional dplyr syntax to select only particular variables or non missing rows.\n# Select non na entries\nflights |&gt;\n  skim() |&gt;\n  select(-n_missing)\n\n# Skim particular variables\nflights |&gt;\n  skim(air_time)"
  },
  {
    "objectID": "posts/2023-01-13-exploratory-data-analysis-in-r.html#dataxray",
    "href": "posts/2023-01-13-exploratory-data-analysis-in-r.html#dataxray",
    "title": "Exploratory data analysis in R",
    "section": "",
    "text": "Dataxray is a package that performs a similar exploratory data analysis to skimr, but its main advantage is that it has an interactive interface and has a fancier design. Nonetheless, it shows almost the same information as skimr; however it takes more time to show the results.\nflights |&gt;\n  # Just to accelerate creation of xray\n  slice(1:50000) |&gt;\n  make_xray() |&gt;\n  view_xray()\n\n\n\nExample of dataxray interface"
  },
  {
    "objectID": "posts/2023-01-19-species-occurrence-data-in-r.html",
    "href": "posts/2023-01-19-species-occurrence-data-in-r.html",
    "title": "Species occurrence data in r",
    "section": "",
    "text": "Species occurrence data\nThe purpose of this post is to download data from GBIF to obtain occurrences registries of a particular species and then to transform that data into a geospatial object and obtain a map.\nThe first step is to load the required packages. Rgbif is the package that will connect R with the GBIF API, skimr is going to be useful to get a quick view of the data we just downloaded, dply and tidyr will help wrangle and clean the data, rnaturalearth will be used to download a polygon of Mexico’s extent, while sf is going to be used to transform the data into a spatial object (sf) and finally, tmap will be used to make a map.\nlibrary(rgbif)\nlibrary(skimr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(rnaturalearth)\nlibrary(sf)\nlibrary(tmap)\nThe first step will be to set your credentials to be able to acess GBIF. If you do not have these credentials, you can register in their website and obtain them (https://www.gbif.org/user/profile). Then rewrite that information into the R environment\n# ---------------1. Set credentials----------------------\n# Set credentials\n# usethis::edit_r_environ()\n\n# Edit .Renviron\n# GBIF_USER=\"myname\"\n# GBIF_PWD=\"mypass\"\n# GBIF_EMAIL=\"yeahyeahyeah@myorg.org\"\nThe next step is downloading the data of interest. In this example, I am going to download the data for Rhizhophora mangle in Mexico. You will have to wait for the download to complete. Meanwhile, you can check the status of the download using occ_download_wait and putting in the key of numbers that will appear in the console. Once the download have been finished, you can import the data into R.\n# -----------2. Search and download data-----------------\n# Now you can use without logging in every session\nid &lt;- name_backbone(\"Rhizophora mangle\")$usageKey\n# Send download request\nocc_download(pred(\"taxonKey\", id),\n             pred(\"country\", \"MX\"),\n             format = \"SIMPLE_CSV\")\n# Check status of download\nocc_download_wait('key_of_numbers')\n\n# Once finished download to hard drive and save it in df\ndf &lt;- occ_download_get('key_of_numbers') %&gt;%\n  occ_download_import()\nNext, you can use skimr to take a look at the general structure of the data and select the columns of interest. Additinoally, you can drop registries without location. (longitude / latitude).\n# ---------3. Select vars of interest-------------------\nskim(df)\n\n# Select columns of importance\nrhizMang &lt;- df |&gt;\n  select(scientificName, identifiedBy,\n         decimalLatitude, decimalLongitude, coordinateUncertaintyInMeters,\n         year, month, day,\n         elevation, elevationAccuracy) |&gt;\n  # Drop registries without spatial reference\n  drop_na(decimalLatitude, decimalLongitude)\nFinally, you can transform the data into a spatial object and make a map. Here, I use ne_countries to get the polygon of Mexico and tmap to create the map. Finally, you can export the map.\n# ---------4. Geo transformation and map------------------\n# Transform into sf object\nrhizMang &lt;- st_as_sf(rhizMang, \n                     coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n                     crs = st_crs(4326))\n\n# Get map of Mexico\nmx &lt;- ne_countries(scale = 110, \n                   type = \"countries\", \n                   # continent = NULL,\n                   country = \"Mexico\", \n                   returnclass = c(\"sf\"))\n\n# Do a quick map to see the location of the registries\nmap1 &lt;- tm_shape(mx) +\n  tm_borders() +\n  tm_shape(rhizMang) +\n  tm_dots(col = \"firebrick2\", size = 0.05) +\n  tm_graticules(lines = F) +\n  tm_scale_bar(position = c(0.01,0)) +\n  tm_compass(type = \"arrow\",\n             position = c(0.90,0.85))\n\ntmap_save(tm = map1,\n          filename = \"Plots/Map1.png\",\n          width = 15,\n          height = 10,\n          units = \"cm\",\n          dpi = 300)\n\n\n\nMap with Rhizophora mangle registries in Mexico"
  },
  {
    "objectID": "posts/2023-02-23-rgb-shaded-relief-maps-in-r.html",
    "href": "posts/2023-02-23-rgb-shaded-relief-maps-in-r.html",
    "title": "RGB Shaded relief maps in R",
    "section": "",
    "text": "RGB Shaded relief maps in R\nIn this post I will show you how to make an RGB composite with shaded relief using rayshader, elevatr, maptiles,sf, terra and magick packages. First load the libraries we are going to use.\nlibrary(elevatr)\nlibrary(maptiles)\nlibrary(sf)\nlibrary(terra)\nlibrary(rayshader)\nlibrary(magick)\nThen, read the roi polygon file and use it to obtain the RGB tiles and DEM data.\n# Get polygon of roi\n# Can be downloaded from: https://github.com/JonathanVSV/Ppage2/tree/master/assets/data\npoly &lt;- st_read(\"MX_inegi.gpkg\")\n# Get RGB mosaic\nrgb &lt;- get_tiles(poly,\n                 provider = \"Esri.WorldImagery\",\n                 cachedir = \"cache\",\n                 crop = T,\n                 zoom = 6)\n# Get elevation data using elevatr\ndem &lt;- get_elev_raster(poly,\n                      prj = \"EPSG:4326\",\n                      src = \"aws\",\n                      z = 6,\n                      neg_to_na = FALSE)\nThen, mask the images using the roi’s polygon and crop the dem to the extent of the RGB.\n# Mask areas according to polygon\nrgb &lt;- mask(rgb, poly)\ndem &lt;- mask(dem, poly)\n\n# Crop dem extent to rgb\ndem &lt;- crop(rast(dem), rgb)\nAfterward, transform the RGB into an array and the dem into a matrix.\n# Restack\n# And convert it to a matrix:\ndem_mat &lt;-  raster_to_matrix(dem)\nrgb_mat &lt;- as.array(rgb)\nMake a hillshade using the dem (as matrix). Transform it to rast again, set its extent and mask with the roi’s polygon.\n# Make hillshade\nhillshade &lt;- dem_mat %&gt;%\n  sphere_shade(sunangle = 315,\n               texture = 'bw',\n               zscale = 250,\n               colorintensity = 0.5)\n\n# Convert back to rast\nhillshade &lt;- rast(hillshade)\n\n# Add extent from rgb and mask\next(hillshade) &lt;- ext(rgb)\nhillshade &lt;- mask(hillshade, poly)\nThen export the two images in a single png, setting some transparency in the second image so the hillshade can be appreciated under the RGB composite. In this case, you need to create a folder named “Plots” outside R in your working directory or use dir.create(\"Plots\") inside R, so you can export the file in the exact same location as in the example. Other alternative, might be to delete the folder part (i.e., “Plots/”)and just export it directly in the working directory.\n# Export to png\npng(\"Plots/Mexico_hillshade.png\",\n    width = 20,\n    height = 15,\n    units = \"cm\",\n    res = 300)\n\n# Plot hillshade\nplotRGB(hillshade, \n        stretch = \"hist\",\n        smooth = T,\n        # completely opaque\n        alpha = 255,\n        add = F,\n        maxcell=Inf, \n        # Make zoom to the bounding box of the roi\n        xlim = c(st_bbox(poly)[[1]]-0.05,st_bbox(poly)[[3]]+0.1),\n        ylim = c(st_bbox(poly)[[2]],st_bbox(poly)[[4]]))\n\n# Plot RGB composite\nplotRGB(rgb, \n        stretch = \"lin\",\n        smooth = T,\n        # Partially transparent\n        alpha = 180,\n        # Add to previous plot\n        add = T,\n        maxcell=Inf) \n\ndev.off()\nOnce you obtain the png, you will see that the colors of the image are somewhat pale. Thus, you can use magick to increase the saturation of the colors, increase the contrast and write the image into another png.\n# Final enhancements\n# Read image\nim1 &lt;- image_read(\"Plots/Mexico_hillshade.png\")\n# Add color saturation\nim2 &lt;- image_modulate(im1, \n                      brightness = 100, \n                      saturation = 200, \n                      hue = 100)\n# Increase contrast\nim2 &lt;- image_contrast(im2, sharpen = 2)\n# Write image\nimage_write(im2, \n            path = \"Plots/Mexico_hillshade_final.png\", \n            format = \"png\")\nThe result:\n\n\n\nRGB shaded relief map of Mexico.\n\n\nIf you are familiar with the surrounding of Morelia, Michoacán, Mexico, you will immediatly recognize Patzcuaro and Cuitzeo lakes, as well as some hills, such as the Quinceo."
  },
  {
    "objectID": "posts/2023-03-09-Volcanos-rayshader.html",
    "href": "posts/2023-03-09-Volcanos-rayshader.html",
    "title": "Volcanos 3d maps",
    "section": "",
    "text": "I have continued playing with rayshader, rayvista and magick packages to make beautiful 3d maps. This post shows the code used to make a 3d map with some of the highest peaks in Mexico, which all have a volcanic origin. Additionally, the area shown in the map is part of the Trans-Mexican Volcanic Belt. The code used to obtain this map is shown in the first section. The second section of the post contains the code used to make the zoom-ins to each volcano, while the third section contains the code used to merge all the images.\nFirst load the required packages.\nlibrary(rayvista)\nlibrary(rayshader)\nlibrary(terra)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(magrittr)\nlibrary(magick)\nLoad the roi polygon to make the large map and also a geopackage file that contains points with the locations of each volcano, with its name and altitude. Although initially I wanted to label also Sierra Negra peak, it was overlapping with the Pico de Orizaba so I removed it. Then, the coordinates are extracted from that same file, added as columns and then added a color column to indicate the color of the labels (white: for names that overlapped with the rgb composite and black those that did not). Finally, calculate the area to add it in the end as a label. The data used in this example can be downloaded from: https://github.com/JonathanVSV/Ppage2/tree/master/assets/data\n# Zscale for 3d map\nzscale &lt;- 60\n# Background color for all maps\nbg_col &lt;- \"gray60\"\n\n# ROI\npicos_poly &lt;- st_read(\"Data/Picos.gpkg\")\n# Points of each peak with its name and altitude\npicos_names &lt;- st_read(\"Data/picos_names.gpkg\") |&gt;\n  # Removed Sierra Negra because was overlapping with Pico de Orizaba\n  filter(Name != \"Sierra Negra\")\n# Get its coordinates\ncoords &lt;- picos_names |&gt;\n  st_coordinates()\n# Add the coordinates as another column and add a color column\npicos_names &lt;- picos_names |&gt;\n  bind_cols(coords, color = c(\"white\", \"white\", \"white\",\n                              \"white\", \"black\", \"black\", \"white\")) |&gt;\n  # Arrange by altitude for the individual volcanos plots\n  arrange(desc(Alt))\n\n # Calculate area in sq. km \nareasqkm &lt;- 25000\n\n# Aprox area without zoom\n# picos_poly |&gt;\n  # st_transform(32614) |&gt;\n  # st_area() |&gt;\n  # as.numeric() |&gt;\n  # multiply_by(1/1000000)\nThen, obtain the RGB data with the DEM.\n\n\nObtain rgb composite and DEM data.\npicos&lt;- plot_3d_vista(req_area = picos_poly,\n                          overlay_detail=10, \n                          overlay_alpha = 0.7, \n                          elevation_detail=9, \n                          show_vista = F)\nThen, create the 3d representation and add the labels and save a snapshot of the rendered image.\n# Use dem matrix data\npicos$dem_matrix|&gt;\n  # Add texture\n  add_overlay(texture_shade(picos$dem_matrix,\n                            detail=0.9)) |&gt;\n  # Add snowy peaks effect\n  add_overlay(generate_altitude_overlay(height_shade(picos$dem_matrix, \n                                                     texture = \"white\",\n                                                     range = c(5000,5700)),\n                                        picos$dem_matrix, \n                                        start_transition = 4500, \n                                        end_transition = 5000, \n                                        lower=FALSE),\n              alphalayer = 1)  |&gt;\n  # Add Shadow\n  add_shadow(ray_shade(picos$dem_matrix, zscale=zscale), 0.7)|&gt;\n  # Add RGB composite\n  add_overlay(picos$texture,rescale_original=TRUE)|&gt;\n  # Plot 3d\n  plot_3d(picos$dem_matrix, \n          zscale=zscale,\n          windowsize = 1200, \n          zoom=0.17, \n          phi=7, \n          theta=280,\n          background = bg_col)\n\n# Add labels\nfor(i in 1:nrow(picos_names)){\n  # color &lt;- \"black\"\n  render_label(picos$dem_matrix,\n               long = picos_names$X[i],\n               lat = picos_names$Y[i],\n               zscale = zscale+60,\n               extent = attr(picos$dem_matrix, \"extent\"),\n               text = paste0(picos_names$Name[i]),\n               linecolor = picos_names$color[i],\n               textcolor = picos_names$color[i])\n}\n\n# Save as png\nrender_snapshot(filename = \"Plots/Volcanos_snap.png\",\n                software_render = F,\n                background = bg_col)\n\n\n\nThis section contains the code used to make the zoom-ins to each volcano. It contains basically the same code as the previous sections but obtains the DEM and RGB composite using the location of each volcano. Finally, to make everything more easy, an lapply is used to make the exact same process for each volcano and save the rendered image as a png.\nlapply(1:nrow(picos_names), function(i){\n  # Get RGB and DEM for each volcano\n  volcano&lt;- plot_3d_vista(\n    lat=picos_names$Y[i],\n    long=picos_names$X[i],\n    radius=10000,\n    overlay_detail=12, \n    overlay_alpha = 0.7, \n    elevation_detail=12, \n    show_vista = F)\n  \n  # Make similar visualization to the large map\n  volcano$dem_matrix|&gt;\n    add_overlay(texture_shade(volcano$dem_matrix,\n                              detail=0.9)) |&gt;\n    # Add RGB composite\n    add_overlay(volcano$texture,\n                rescale_original=TRUE,\n                alphalayer = 0.7)|&gt;\n    add_overlay(generate_altitude_overlay(height_shade(volcano$dem_matrix,\n                                                       texture = \"white\",\n                                                       range = c(5000,5700)),\n                                          volcano$dem_matrix,\n                                          start_transition = 4500,\n                                          end_transition = 5000,\n                                          lower=FALSE),\n                alphalayer = 0.7)  |&gt;\n    plot_3d(volcano$dem_matrix, \n            zscale=10,\n            windowsize = 1200, \n            zoom=0.6, \n            phi=0, \n            theta=90,\n            baseshape = \"rectangle\",\n            background = bg_col)\n  \n  # Save as png          \n  render_snapshot(filename = paste0(\"Plots/\",picos_names$Name[i],\"_snap.png\"),\n                  software_render = F,\n                  title_position = \"north\",\n                  title_font = \"sans\",\n                  title_size = 50,\n                  title_text = paste0(picos_names$Name[i], \n                                      \"\\n\", \n                                      picos_names$Alt[i],\n                                      \" m amsl\"),\n                  title_offset = c(0,100),\n                  gravity = \"north\",\n                  background = bg_col)\n})\n\n\n\nFinally, this part makes use of the magick package to stitch together all the images and add some labels\n# Read the large map image and make some adjustments\nimall &lt;- image_read(\"Plots/Volcanos_snap.png\") |&gt;\n  # Make it bigger\n  image_resize(\"1975\") |&gt;\n  # Add title\n  image_annotate(text = \"Mexico's Highest Peaks\", \n                 weight = 700,\n                 font = \"sans\", \n                 location = \"+100+20\",\n                 color = \"black\", \n                 size = 80, \n                 gravity = \"north\") |&gt;\n  # Add a label of aprox. area shown               \n  image_annotate(text = paste0(\"Aprox. area shown: \", scales::comma(areasqkm), \" km\\U00B2\"), \n                 weight = 400,\n                 font = \"sans\", \n                 location = \"+0+10\",\n                 color = \"black\", \n                 size = 32, \n                 gravity = \"south\") |&gt;\n  # Eliminate empty spaces               \n  image_trim() |&gt; \n  # Add border\n  image_border(color = bg_col,\n               geometry = \"50x50\") \n\n# Read individual volcanoes images into a list\nimsingle &lt;- lapply(picos_names$Name, function(x){\n  image_read(paste0(\"Plots/\", x, \"_snap.png\")) |&gt;\n    # Eliminate empty spaces\n    image_trim() |&gt;\n    # Add new border\n    image_border(color = bg_col,\n                 geometry = \"20x20\") |&gt;\n    # Resize image\n    image_resize(\"400\")\n})\n\n# Stack all single volcanos vertically\nstacked_im &lt;- image_append(Reduce(c, imsingle), stack = T)\n\n# Stitch horizontally the map and the stacked volcanoes images\nimage_append(c(imall, stacked_im)) |&gt;\n# Add color saturation and contrast\n  image_modulate(brightness = 150, \n                 saturation = 130, \n                 hue = 100) |&gt;\n  # Increase contrast\n  image_contrast(sharpen = 5) |&gt;\n  # Write image\n  image_write(path = \"Plots/Volcanos_all_final.png\", \n              format = \"png\")\nThe result:\n\n\n\nMexico’s highest peaks\n\n\nIn the final map, the tallest peaks can be appreciated with its labels, as well as a zoom-in to all of them individually (right-side panel). I like to think of the resulting image as a simple infography."
  },
  {
    "objectID": "posts/2023-03-09-Volcanos-rayshader.html#large-map",
    "href": "posts/2023-03-09-Volcanos-rayshader.html#large-map",
    "title": "Volcanos 3d maps",
    "section": "",
    "text": "Obtain rgb composite and DEM data.\npicos&lt;- plot_3d_vista(req_area = picos_poly,\n                          overlay_detail=10, \n                          overlay_alpha = 0.7, \n                          elevation_detail=9, \n                          show_vista = F)\nThen, create the 3d representation and add the labels and save a snapshot of the rendered image.\n# Use dem matrix data\npicos$dem_matrix|&gt;\n  # Add texture\n  add_overlay(texture_shade(picos$dem_matrix,\n                            detail=0.9)) |&gt;\n  # Add snowy peaks effect\n  add_overlay(generate_altitude_overlay(height_shade(picos$dem_matrix, \n                                                     texture = \"white\",\n                                                     range = c(5000,5700)),\n                                        picos$dem_matrix, \n                                        start_transition = 4500, \n                                        end_transition = 5000, \n                                        lower=FALSE),\n              alphalayer = 1)  |&gt;\n  # Add Shadow\n  add_shadow(ray_shade(picos$dem_matrix, zscale=zscale), 0.7)|&gt;\n  # Add RGB composite\n  add_overlay(picos$texture,rescale_original=TRUE)|&gt;\n  # Plot 3d\n  plot_3d(picos$dem_matrix, \n          zscale=zscale,\n          windowsize = 1200, \n          zoom=0.17, \n          phi=7, \n          theta=280,\n          background = bg_col)\n\n# Add labels\nfor(i in 1:nrow(picos_names)){\n  # color &lt;- \"black\"\n  render_label(picos$dem_matrix,\n               long = picos_names$X[i],\n               lat = picos_names$Y[i],\n               zscale = zscale+60,\n               extent = attr(picos$dem_matrix, \"extent\"),\n               text = paste0(picos_names$Name[i]),\n               linecolor = picos_names$color[i],\n               textcolor = picos_names$color[i])\n}\n\n# Save as png\nrender_snapshot(filename = \"Plots/Volcanos_snap.png\",\n                software_render = F,\n                background = bg_col)"
  },
  {
    "objectID": "posts/2023-03-09-Volcanos-rayshader.html#individual-volcanoes",
    "href": "posts/2023-03-09-Volcanos-rayshader.html#individual-volcanoes",
    "title": "Volcanos 3d maps",
    "section": "",
    "text": "This section contains the code used to make the zoom-ins to each volcano. It contains basically the same code as the previous sections but obtains the DEM and RGB composite using the location of each volcano. Finally, to make everything more easy, an lapply is used to make the exact same process for each volcano and save the rendered image as a png.\nlapply(1:nrow(picos_names), function(i){\n  # Get RGB and DEM for each volcano\n  volcano&lt;- plot_3d_vista(\n    lat=picos_names$Y[i],\n    long=picos_names$X[i],\n    radius=10000,\n    overlay_detail=12, \n    overlay_alpha = 0.7, \n    elevation_detail=12, \n    show_vista = F)\n  \n  # Make similar visualization to the large map\n  volcano$dem_matrix|&gt;\n    add_overlay(texture_shade(volcano$dem_matrix,\n                              detail=0.9)) |&gt;\n    # Add RGB composite\n    add_overlay(volcano$texture,\n                rescale_original=TRUE,\n                alphalayer = 0.7)|&gt;\n    add_overlay(generate_altitude_overlay(height_shade(volcano$dem_matrix,\n                                                       texture = \"white\",\n                                                       range = c(5000,5700)),\n                                          volcano$dem_matrix,\n                                          start_transition = 4500,\n                                          end_transition = 5000,\n                                          lower=FALSE),\n                alphalayer = 0.7)  |&gt;\n    plot_3d(volcano$dem_matrix, \n            zscale=10,\n            windowsize = 1200, \n            zoom=0.6, \n            phi=0, \n            theta=90,\n            baseshape = \"rectangle\",\n            background = bg_col)\n  \n  # Save as png          \n  render_snapshot(filename = paste0(\"Plots/\",picos_names$Name[i],\"_snap.png\"),\n                  software_render = F,\n                  title_position = \"north\",\n                  title_font = \"sans\",\n                  title_size = 50,\n                  title_text = paste0(picos_names$Name[i], \n                                      \"\\n\", \n                                      picos_names$Alt[i],\n                                      \" m amsl\"),\n                  title_offset = c(0,100),\n                  gravity = \"north\",\n                  background = bg_col)\n})"
  },
  {
    "objectID": "posts/2023-03-09-Volcanos-rayshader.html#image-composition-and-final-adjustments",
    "href": "posts/2023-03-09-Volcanos-rayshader.html#image-composition-and-final-adjustments",
    "title": "Volcanos 3d maps",
    "section": "",
    "text": "Finally, this part makes use of the magick package to stitch together all the images and add some labels\n# Read the large map image and make some adjustments\nimall &lt;- image_read(\"Plots/Volcanos_snap.png\") |&gt;\n  # Make it bigger\n  image_resize(\"1975\") |&gt;\n  # Add title\n  image_annotate(text = \"Mexico's Highest Peaks\", \n                 weight = 700,\n                 font = \"sans\", \n                 location = \"+100+20\",\n                 color = \"black\", \n                 size = 80, \n                 gravity = \"north\") |&gt;\n  # Add a label of aprox. area shown               \n  image_annotate(text = paste0(\"Aprox. area shown: \", scales::comma(areasqkm), \" km\\U00B2\"), \n                 weight = 400,\n                 font = \"sans\", \n                 location = \"+0+10\",\n                 color = \"black\", \n                 size = 32, \n                 gravity = \"south\") |&gt;\n  # Eliminate empty spaces               \n  image_trim() |&gt; \n  # Add border\n  image_border(color = bg_col,\n               geometry = \"50x50\") \n\n# Read individual volcanoes images into a list\nimsingle &lt;- lapply(picos_names$Name, function(x){\n  image_read(paste0(\"Plots/\", x, \"_snap.png\")) |&gt;\n    # Eliminate empty spaces\n    image_trim() |&gt;\n    # Add new border\n    image_border(color = bg_col,\n                 geometry = \"20x20\") |&gt;\n    # Resize image\n    image_resize(\"400\")\n})\n\n# Stack all single volcanos vertically\nstacked_im &lt;- image_append(Reduce(c, imsingle), stack = T)\n\n# Stitch horizontally the map and the stacked volcanoes images\nimage_append(c(imall, stacked_im)) |&gt;\n# Add color saturation and contrast\n  image_modulate(brightness = 150, \n                 saturation = 130, \n                 hue = 100) |&gt;\n  # Increase contrast\n  image_contrast(sharpen = 5) |&gt;\n  # Write image\n  image_write(path = \"Plots/Volcanos_all_final.png\", \n              format = \"png\")\nThe result:\n\n\n\nMexico’s highest peaks\n\n\nIn the final map, the tallest peaks can be appreciated with its labels, as well as a zoom-in to all of them individually (right-side panel). I like to think of the resulting image as a simple infography."
  },
  {
    "objectID": "posts/2023-05-31-shiny-app-spatial.html",
    "href": "posts/2023-05-31-shiny-app-spatial.html",
    "title": "Shiny App with spatial data",
    "section": "",
    "text": "Shiny App with spatial data\nThis post will show you how to build a shiny app to visualize spatial data (mainly in raster and vector format). Remember that you can also build other types of shiny apps, but I decided to focus this post on spatial data.\nSo the first thing is going to open RStudio, click on New Project -&gt; New Project -&gt; Shiny application and create new shiny app folder.\nThe first thing is to load the necessary packages\nlibrary(shiny)\nlibrary(raster)\nlibrary(leaflet)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(RColorBrewer)\nThen you are going to load the raster and vector data. Additionally, you need to create a palette to show the DEM we loaded and set customized icons to show the vector data. Finally, you will create the legend entries for each of the customized icons.\n# Load the raster and vector data\nsitios &lt;- st_read(\"Data/SitiosPtsAll.gpkg\") |&gt;\n  st_transform(4326)\nbarrancas &lt;- st_read(\"Data/BarrancasAll.gpkg\") |&gt;\n  st_transform(4326)\nDEM &lt;- raster(\"Data/DEM.tif\")\n\n# Palette to show DEM\nmypal &lt;- palette(gray(seq(0,1,length.out = 10)))\n\nmyIcons &lt;- icons(\n  iconUrl = case_when(sitios$Geositio == \"Localidad\" ~ \"www/house.png\",\n                      sitios$Geositio == \"Templo\" ~ \"www/iglesia.png\",\n                      sitios$Geositio == \"Arbol\" ~ \"www/tree.png\",\n                      sitios$Geositio == \"Cerro\" ~ \"www/peak.png\",\n                      sitios$Geositio == \"Paraje\" ~ \"www/walker.png\",\n                      sitios$Geositio == \"Ranchería\" ~ \"www/hostel.png\",\n                      sitios$Geositio == \"Crucero\" ~ \"www/crossroad.png\",\n                      TRUE ~ \"www/circle.png\"),\n  iconWidth = 15, \n  iconHeight = 15,\n  iconAnchorX = 7,\n  iconAnchorY = 7,\n  className = \"Sitios\"\n)\n\nhtml_legend &lt;- '&lt;img src=\"house.png\" height=\"15\" width=\"15\"&gt;Localidad&lt;br&gt;\n                &lt;img src=\"iglesia.png\" height=\"15\" width=\"15\"&gt;Templo&lt;br&gt;\n                &lt;img src=\"tree.png\" height=\"15\" width=\"15\"&gt;Árbol&lt;br&gt;\n                &lt;img src=\"peak.png\" height=\"15\" width=\"15\"&gt;Cerro&lt;br&gt;\n                &lt;img src=\"walker.png\" height=\"15\" width=\"15\"&gt;Paraje&lt;br&gt;\n                &lt;img src=\"hostel.png\" height=\"15\" width=\"15\"&gt;Ranchería&lt;br&gt;\n                &lt;img src=\"crossroad.png\" height=\"15\" width=\"15\"&gt;Crucero&lt;br&gt;\n                &lt;img src=\"circle.png\" height=\"15\" width=\"15\"&gt;Otro&lt;br&gt;'\nThen, you need to set up the users interface. In this case, since we are interested in navigating spatial data, we are using a vertical layout.\n# Define the UI for the app\nui &lt;- fluidPage(\n  titlePanel(\"Cuilala App\"),\n  verticalLayout(\n    titlePanel(\"Cuilala información espacial\"),\n  )\n)\nThen create below that same script the server side script. Most of this part is setting up the leaflet visualization, adding a basemap (ESRI world imagery), adding the markers (point data), DEM (raster data) and other features (lines data), adding control layers buttons, as well as the legend for our customized icons and a scale bar. Finally, you need to create an observe event to watch for clicks over the markers, to show up their details when clicked.\n# Define the server for the app\nserver &lt;- function(input, output) {\n  # Render the map\n  output$map &lt;- renderLeaflet({\n    # Create the leaflet map\n    leaflet(data = sitios) %&gt;%\n      addProviderTiles('Esri.WorldImagery') %&gt;% \n      # Add markers for vector data\n      addMarkers(data = sitios,\n                 popup = ~Nombre,\n                 group = \"Sitios\",\n                 icon = myIcons,\n               ) %&gt;%\n      # Add the raster layer\n      addRasterImage(x = DEM,\n                     colors = mypal,\n                     method = \"ngb\",\n                     group = \"MDE\",\n                     opacity = 70) %&gt;%\n      # Add polylines layer\n      addPolylines(data = barrancas,\n        color = \"royalblue\",\n        group = \"Barrancas\",\n        popup = ~Nombre\n      ) %&gt;%\n      # Add Layers control (turn on and off)\n      addLayersControl(\n        baseGroups = c(\"ESRI Imagery\"),\n        overlayGroups = c(\"Sitios\", \"Barrancas\", \"MDE\"),\n        options = layersControlOptions(collapsed = FALSE)\n      ) %&gt;%\n      # Add legend for custom icons\n      addControl(\n        html = html_legend,\n        position = \"bottomleft\"\n      ) %&gt;%\n      # Add scale bar\n      addScaleBar(position = \"bottomright\",\n                  options = scaleBarOptions(\n                    maxWidth = 100,\n                    metric = TRUE,\n                    imperial = FALSE,\n                    updateWhenIdle = TRUE\n                  ))\n  }) \n  \n  # Observe event for clicking over a marker and showing details\n  observeEvent(input$mapmarker_click, { \n    p &lt;- input$map_marker_click \n    print(p)\n  })\n}\nFinally, run the app.\n# Run the app\nshinyApp(ui, server)\nA snapshot of the result:\n\n\n\nShiny app to visualize and explore spatial data.\n\n\nThe real results hosted in shinyapps.io: https://jonathanvsv.shinyapps.io/cuilalaapp/"
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html",
    "href": "posts/2023-06-21-open-foris-tools.html",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "In this post I will show you how to easily run two Open Foris tools in R to easily validate a map and obtain the area estimates corrected by the producer’s accuracies obtained in the confusion matrix. The repository of these tools can be found here: https://github.com/openforis/accuracy-assessment\nThere are several ways you can run the apps; however the easiest is to run the shiny app directly from the github repo.\n\n\nFirst, we will explore the design app.\nlibrary(shiny)\noptions(shiny.launch.browser = TRUE)\nrunGitHub(\"openforis/accuracy-assessment\",subdir=\"aa_design\")\nOnce you open R and run the previous code, you should see the following screen.\n\n\n\nOpen Foris design app\n\n\n\n\n\nIn this app, you will see in the left panel several submenus. The first one is the Map input, where you can load your classification. Once your image is loaded, go to the next submenu, Strata areas.\n\n\n\nIn this menu, the first option will read: area calculation and legend generation. Click here and wait several seconds until the menu that is under this one (Legend labeling) appears with the values of the raster. Here you can change the raster values for a description of that class. For example, Class name 1 could be water, class name 2, forest, etc. Once the descriptions have been added, click on submit legend. Once the legend is submitted the panel on the upper right side should appear with the names of the classes and its area in a table. You can download that table as a csv. Then go to the next submenu: Strata selection.\n\n\n\nHere you set the expected user’s accuracy for each class. Commonly the high value is set for common classes and the low value for rare classes. Once you select the high and low expected user’s accuracy in the sliders, in the lower right panel select the confidence values for each class. Click on the empty spaces and select each class in its corresponding high or low value.\n\n\n\nThe next step is selecting the sample size to obtain a desired standard error of the overall accuracy of the map. Here you can select the target standard error (default value = 0.01) and the minimum sample size per strata (default value = 100). A smaller standard error will imply a higher number of points, while the minimum sample size is sometimes recommended of being around 50. If the panel on the right does not adjust its estimates once you change the values in the first panel, verify that the modify the sampling size button is turned off.\n\n\n\nFinally, you just need to generate the sampling points by clicking in the button of the final menu. Here a vector file will be generated with the areas to be verified to get the accuracy of the map. Here you can set the size of the intepretation box (min 30 m). Once the points are generated (after several seconds) a map will appear showing the generated points and a new submenu will appear to download the points in the format you desire."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#design",
    "href": "posts/2023-06-21-open-foris-tools.html#design",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "First, we will explore the design app.\nlibrary(shiny)\noptions(shiny.launch.browser = TRUE)\nrunGitHub(\"openforis/accuracy-assessment\",subdir=\"aa_design\")\nOnce you open R and run the previous code, you should see the following screen.\n\n\n\nOpen Foris design app"
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#map-input",
    "href": "posts/2023-06-21-open-foris-tools.html#map-input",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "In this app, you will see in the left panel several submenus. The first one is the Map input, where you can load your classification. Once your image is loaded, go to the next submenu, Strata areas."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#strata-areas",
    "href": "posts/2023-06-21-open-foris-tools.html#strata-areas",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "In this menu, the first option will read: area calculation and legend generation. Click here and wait several seconds until the menu that is under this one (Legend labeling) appears with the values of the raster. Here you can change the raster values for a description of that class. For example, Class name 1 could be water, class name 2, forest, etc. Once the descriptions have been added, click on submit legend. Once the legend is submitted the panel on the upper right side should appear with the names of the classes and its area in a table. You can download that table as a csv. Then go to the next submenu: Strata selection."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#strata-selection",
    "href": "posts/2023-06-21-open-foris-tools.html#strata-selection",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "Here you set the expected user’s accuracy for each class. Commonly the high value is set for common classes and the low value for rare classes. Once you select the high and low expected user’s accuracy in the sliders, in the lower right panel select the confidence values for each class. Click on the empty spaces and select each class in its corresponding high or low value."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#sampling-size",
    "href": "posts/2023-06-21-open-foris-tools.html#sampling-size",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "The next step is selecting the sample size to obtain a desired standard error of the overall accuracy of the map. Here you can select the target standard error (default value = 0.01) and the minimum sample size per strata (default value = 100). A smaller standard error will imply a higher number of points, while the minimum sample size is sometimes recommended of being around 50. If the panel on the right does not adjust its estimates once you change the values in the first panel, verify that the modify the sampling size button is turned off."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#sample-allocation",
    "href": "posts/2023-06-21-open-foris-tools.html#sample-allocation",
    "title": "Open Foris tools in r",
    "section": "",
    "text": "Finally, you just need to generate the sampling points by clicking in the button of the final menu. Here a vector file will be generated with the areas to be verified to get the accuracy of the map. Here you can set the size of the intepretation box (min 30 m). Once the points are generated (after several seconds) a map will appear showing the generated points and a new submenu will appear to download the points in the format you desire."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#inputs",
    "href": "posts/2023-06-21-open-foris-tools.html#inputs",
    "title": "Open Foris tools in r",
    "section": "Inputs",
    "text": "Inputs\nHere you should add the csv file that contains the data for each validation points generated in the previous app. However this file has been verified an thus, it should contain one column indicating the reference data (by ground truth or visual interpretation) and the original map data (the classification). Afterward, you should add a csv file containing the area data by class (generated in the previous app).\nOnce you add the two files, a new panel will appear on the right side. Here you should indicate which column has the reference data (by ground truth or visual interpretation) and which one the map class. Also, indicate the columns in the area file indicating the area and the class."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#check",
    "href": "posts/2023-06-21-open-foris-tools.html#check",
    "title": "Open Foris tools in r",
    "section": "Check",
    "text": "Check\nHere you can check the spatial distribution of your verification data. Here you just need to indicate the columns containing the x and y coordinates data."
  },
  {
    "objectID": "posts/2023-06-21-open-foris-tools.html#results",
    "href": "posts/2023-06-21-open-foris-tools.html#results",
    "title": "Open Foris tools in r",
    "section": "Results",
    "text": "Results\nHere you can see the confusion matrix from your data. Also, in the lower part you can set the desired confidence interval for the area estimates (by default 95 %). Finally. the corrected area estimates should appear in the right panel. In the last test I made with this app, this last part had a bug; thus, I suggest cloning the repo and running it locally as a shiny app. In this last approach, you need to open the app_analysis_bckup_20161024 file inside the Rscript folder and run eveything from start to end. Finally, this way the app should work without any error showing that the names in the two files (1) reference and map classes and 2) areas) do not match."
  },
  {
    "objectID": "posts/2023-06-22-working-with-lidar.html",
    "href": "posts/2023-06-22-working-with-lidar.html",
    "title": "Working with LiDAR data in R",
    "section": "",
    "text": "Working with LiDAR data in R\nFor this example we are going to use the lidR package. Additionally, we are going to load terra sf and dplyr. In this example, we will work with lascatalogs, which enables working with several las files at once.\nThe first thing is to load the LiDAR data as a catalog and load a shapefile with the areas of interest (that can correspond to in-field measurements). Reading data as a catalog enables refering to the original files without loading all of them into memory.\nlibrary(lidR)\nlibrary(terra)\nlibrary(sf)\nlibrary(dplyr)\n\n# Load files\narchivos&lt;-list.files(\".\",\n    pattern=\"*.las\",\n    full.names=T)\nlidares&lt;-readLAScatalog(archivos)\n\n# Load plots data\nptos &lt;- read.csv(\"Data/Plots.csv\")\nSince ptos is a csv table, first we need to transform it to an sf object and then project it in the same crs as the LiDAR data (EPSG:32615). So lets do that by first indicating the crs in which the coordinates in the original table are and then transforming them to the target EPSG and then create a buffer of radius = 10 m. We also can select only the columns of interest and rename it.\nptos &lt;- st_as_sf(ptos, \n                  coords = c(\"Easting_Geo\", \"Northing_Geo\"),\n                  crs = 4326) |&gt;\n  st_transform(32615) |&gt;\n  st_buffer(10) |&gt;\n  select(Id_parcela) |&gt;\n  rename(\"PLOT_ID\" = \"Id_parcela\")\nNow, lets check if everything is ok. First, lets run some tests to see if everything is ok.\nlas_check(lidares)\nNow let’s check if both datasets have the same crs and overlap. In this case, I will select a single property of the sf object named “Id_parcela”.\nplot(lidares)\nplot(ptos[\"Id_parcela\"], add = T)\nYou should see something similar to the following image:\n\n\n\nExample of spatial overlap between the liDAR data and field plots.\n\n\nAfter making those tests, we are ready to process the data.\nSince we are working with a LAScatalog, in order to calculate the metrics of interest we can focus to work with only the places where we have field data (ptos). Thus, we can clip the field data plots to the las catalog. There could be plots that do not fall inside the LiDAR data, so we can filter just to stay with the ones that have LiDAR associated data.\next_lidares &lt;- ext(lidares)\nptos &lt;- st_crop(ptos,\n                ext_lidares)\nThe next step is creating a digital terrain model (DTM) using a knn nearest neighbor algorithm. Here you can select another algorithm such as knnidw, tin and kriging.\ndtm &lt;- rasterize_terrain(lidares,\n                         res = 1,\n                         algorithm = knnidw(k = 6L, p = 2))\nplot(dtm)                         \nThen we can use the DTM to subtract those values to the vegetation points in order to get the vegetation height values. This is usually known as normalization. Here we need to set additional options to process chunks.\n# Set output for normalized data, here I will use a files folder\nopt_chunk_size(lidares) = 0\nopt_output_files(lidares) &lt;-  paste0(\"files\", \"/{*}_norm\")\nnlas &lt;- normalize_height(lidares, \n                         algorithm  = tin(),\n                         dtm = dtm)\nThe next step is to get the point cloud metrics by plot. In this case, we are going to use the default std metrics from z. Here you can set any function using the folowing notation: ~list(q10 = quantile(Z, probs = 0.10),q95 = quantile(Z, probs = 0.95)). Before running the following code, we need to change the options to export the files produced for each plot. Here I will use the pattern “ID” to get each file with a consecutive number.\nopt_output_files(nlas) &lt;-  paste0(\"files\", \"/{ID}\")\nmetrics &lt;- plot_metrics(nlas, \n                        .stdmetrics_z,\n                        ptos)\nFinally, you will obtain a data frame with the plot’s ID and its corresponding z- metrics."
  },
  {
    "objectID": "posts/2023-07-17-AGB-forest-sampling-calculations.html",
    "href": "posts/2023-07-17-AGB-forest-sampling-calculations.html",
    "title": "AGB forest sampling calculations",
    "section": "",
    "text": "AGB forest sampling calculations\nThis post shows an example of how to calculate some common plot-level variables from a forest sampling.\nlibrary(BIOMASS)\nlibrary(stringr)\nlibrary(tidyverse)\nRead data\n# Field data with individual tree measures\ndf &lt;- read.csv(\"D:/Drive/Jonathan_trabaggio/Doctorado/R/Ayuquila_Degradation/CleanData/df_all.csv\",\n               na.strings = \"NA\")\n\n# Coordinates of each site.\ncoords &lt;- read.csv(\"D:/Drive/Jonathan_trabaggio/Doctorado/R/Ayuquila_Degradation/Data/gpscoords.csv\")\nHow the headers of the data look like the following for the df object.\n     Nombre              Especie Observaciones DAP1 DAP2 DAP3 DAP4 DAP5 DAP6 DAP7 DAP8 DAP9 DAP10 DAP11\n1      &lt;NA&gt;                 &lt;NA&gt;          &lt;NA&gt; 3.44   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n2      &lt;NA&gt;                 &lt;NA&gt;          &lt;NA&gt; 6.81   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n3  lysiloma Lysiloma divaricatum          &lt;NA&gt; 3.12   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n4 leocarpus      Heliocarpus sp.          &lt;NA&gt; 8.72   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n5    muerto                 &lt;NA&gt;          &lt;NA&gt; 4.04   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n6 leocarpus      Heliocarpus sp.          &lt;NA&gt; 3.34   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\n  DAP12 DAP13 DAP14 DAP15 DAP16 DAP17 DAP18 DAP19 DAP20 DAP21 DAP22 DAP23 DAP24 Altura  parcela         x\n1    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   1.66 Amacuau1 19°53.904\n2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   4.56 Amacuau1 19°53.904\n3    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   3.65 Amacuau1 19°53.904\n4    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   5.29 Amacuau1 19°53.904\n5    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   2.69 Amacuau1 19°53.904\n6    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   3.02 Amacuau1 19°53.904\n           y cobertura register Observaciones.sitio id   DAP1.BA DAP2.BA DAP3.BA DAP4.BA DAP5.BA DAP6.BA\n1 104°06.428     70-80      Yan                &lt;NA&gt;  1  9.294088      NA      NA      NA      NA      NA\n2 104°06.428     70-80      Yan                &lt;NA&gt;  2 36.423704      NA      NA      NA      NA      NA\n3 104°06.428     70-80      Yan                &lt;NA&gt;  3  7.645380      NA      NA      NA      NA      NA\n4 104°06.428     70-80      Yan                &lt;NA&gt;  4 59.720420      NA      NA      NA      NA      NA\n5 104°06.428     70-80      Yan                &lt;NA&gt;  5 12.818955      NA      NA      NA      NA      NA\n6 104°06.428     70-80      Yan                &lt;NA&gt;  6  8.761588      NA      NA      NA      NA      NA\n  DAP7.BA DAP8.BA DAP9.BA DAP10.BA DAP11.BA DAP12.BA DAP13.BA DAP14.BA DAP15.BA DAP16.BA DAP17.BA DAP18.BA\n1      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n2      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n3      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n4      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n5      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n6      NA      NA      NA       NA       NA       NA       NA       NA       NA       NA       NA       NA\n  DAP19.BA DAP20.BA DAP21.BA DAP22.BA DAP23.BA DAP24.BA\n1       NA       NA       NA       NA       NA       NA\n2       NA       NA       NA       NA       NA       NA\n3       NA       NA       NA       NA       NA       NA\n4       NA       NA       NA       NA       NA       NA\n5       NA       NA       NA       NA       NA       NA\n6       NA       NA       NA       NA       NA       NA\nand like the following for the coords file.\n      name elevation       date         x        y     xutm    ytum\n1   LIMON1 1118.1133 2022/05/12 -104.1652 19.83815 587412.5 2193788\n2 AMACUAU1  998.5761 2022/05/13 -104.1071 19.89840 593460.8 2200486\n\n\nFix taxonomy and get wood density for AGB calculation\nThe first step is to get the corrected names of the species registered in the field. This information will be used to get the wood density by species, genus or family, depending on what info is available in the global woodensity database. Then this wood density is going to be used to calculate AGB as\n# Separate genus and species\ndf &lt;- df |&gt;\n  mutate(genus = str_extract(Especie, \"[A-z]+(?= )\"),\n         species = str_extract(Especie, \"(?&lt;= )[A-z]+(?=)\")) |&gt;\n  mutate(across(species, ~gsub(\"sp|sp.\",\"NA\",.x)))\n\n# Correct taxo names\ntaxo &lt;- correctTaxo(genus = df$genus, \n                    species = df$species, \n                    useCache = F, \n                    verbose = FALSE)\n\n# Add as new columns\ndf &lt;- df |&gt;\n  mutate(genuscorr = taxo$genusCorrected,\n         speciescorr = taxo$speciesCorrected)\n\n# Get family according to APG 3\nAPG &lt;- getTaxonomy(df$genuscorr, findOrder = TRUE)\n\n# Add to original df\ndf &lt;- df |&gt;\n  mutate(family = APG$family)\n\n# Get wood density\ndataWD &lt;- getWoodDensity(\n  genus = df$genuscorr,\n  species = df$speciescorr,\n  family = df$family,\n  region = \"World\",\n  stand = df$parcela\n)\n\n# add as columns to df\ndf &lt;- df |&gt;\n  mutate(meanwood = dataWD$meanWD,\n         sdwood = dataWD$sdWD,\n         levelwood = dataWD$levelWD,\n         nInd = dataWD$nInd)\n\n# Compute AGB for all DAP\ndf_agb &lt;- df |&gt;\n  mutate(across(matches(\"DAP[0-9]+$\"), ~ computeAGB(D = .x,\n                                                    WD = meanwood,\n                                                    H = Altura))) |&gt;\n  select(id, matches(\"DAP[0-9]+$\"))\n\ncolnames(df_agb) &lt;- c(\"id\", paste0((\"AGB\"), seq(1,24)))\n\n# Join AGB by id\ndf &lt;- df |&gt;\n  left_join(df_agb, \"id\")\nAfter these steps we now got the individual AGB for each stem and individual, as new columns of the original df. So the next step is going to calculate these same metrics for each individual (e.g., individual AGB sum of all of its stems). Watch that you might need to change some parameters of the subplot_size definition according to your own sampling design.\n# Max DAP, plot extent\nsubplot_size &lt;- df|&gt;\n  select(id, matches(\"DAP[0-9]+$\")) |&gt;\n  pivot_longer(cols = -id, \n               names_to = c(\"AGB\")) |&gt;\n  drop_na(value) |&gt;\n  group_by(id) |&gt;\n  summarise(DAP_max = max(value)) |&gt;\n  mutate(subplot_size = case_when(DAP_max &gt;= 5 ~ 500,\n                                  DAP_max &gt;= 2.5 & DAP_max &lt; 5 ~ 29,\n                                  DAP_max &lt; 2.5 ~ 0))\n\n# AGB sum\nAGB &lt;- df|&gt;\n  select(id, starts_with(\"AGB\")) |&gt;\n  pivot_longer(cols = -id, \n               names_to = c(\"AGB\")) |&gt;\n  drop_na(value) |&gt;\n  group_by(id) |&gt;\n  summarise(AGB_sum = sum(value))\n\n# number of stems\nStems &lt;- df|&gt;\n  select(id, starts_with(\"AGB\")) |&gt;\n  pivot_longer(cols = -id, \n               names_to = c(\"AGB\")) |&gt;\n  drop_na(value) |&gt;\n  group_by(id) |&gt;\n  summarise(Stem_sum = n())\n\n# Basal area\nBA &lt;- df|&gt;\n  select(id, ends_with(\"BA\")) |&gt;\n  pivot_longer(cols = -id, \n               names_to = c(\"BA\")) |&gt;\n  drop_na(value) |&gt;\n  group_by(id) |&gt;\n  summarise(BA_sum = sum(value))\n\n# Join previous calculation to original df\ndf &lt;- df |&gt;\n  left_join(AGB, \"id\") |&gt;\n  left_join(BA, \"id\") |&gt;\n  left_join(Stems, \"id\") |&gt;\n  left_join(subplot_size, \"id\")\n\n# Select variables of interest\ndf &lt;- df |&gt;\n  select(parcela, x, y, cobertura, Observaciones.sitio, \n         id, subplot_size, AGB_sum, BA_sum, Stem_sum, Altura, \n         genuscorr, speciescorr, meanwood, levelwood,\n         register) \nNow that we have the individual measures we need to calculate the per plot variables: AGBplot, BAplot, Dplot, Stemplot, Hmplot, H10plot. Since some of these measures are sums, extrapolated to 1 ha sums, means, etc, each one is summarised using the most common function to calculate it (e.g., AGB sum, height mean). Finally, we assume that the best registered coordinates are located in the coords file; thus, these coordinates are pasted on to the final result.\n# -------------------Per plot variables------------------------------\n# Summarise variables that need to be extrapolated\nvars1 &lt;- df |&gt;\n  group_by(parcela, subplot_size) |&gt;\n  # Sums by subplot_size\n  summarise(AGBsubplot = sum(AGB_sum),\n            BAsubplot = sum(BA_sum) / 10000,\n            Dsubplot = n(),\n            Stemsubplot = sum(Stem_sum)) |&gt;\n  # Extrapolate to 1 ha according to the subplot size\n  mutate(across(c(AGBsubplot, BAsubplot, Dsubplot, Stemsubplot), ~.x * 10000 / subplot_size)) |&gt;\n  ungroup() |&gt;\n  group_by(parcela) |&gt;\n  # Sum both subplot estimates\n  summarise(AGBplot = sum(AGBsubplot),\n            BAplot = sum(BAsubplot),\n            Dplot = sum(Dsubplot),\n            Stemplot = sum(Stemsubplot))\n\n# Calculate top 10 mean height\nvars2 &lt;- df |&gt;\n  group_by(parcela) |&gt;\n  slice_max(Altura, n = 10) |&gt;\n  summarise(H10plot = mean(Altura))\n\n# Cover\nvars3 &lt;- df |&gt;\n  select(parcela, cobertura) |&gt;\n  separate(col = cobertura, \n           sep = \"-\",\n           into = c(\"cob1\", \"cob2\")) |&gt;\n  mutate(across(starts_with(\"cob\"), ~as.numeric(.x))) |&gt;\n  group_by(parcela) |&gt;\n  summarise(cob = mean(c(cob1, cob2), na.rm = T))\n\n# Mean height\nvars4 &lt;- df |&gt;\n  group_by(parcela) |&gt;\n  summarise(Hmplot = mean(Altura))\n\n# Join all calculations\nresul &lt;- vars1 |&gt;\n  left_join(vars2, \"parcela\") |&gt;\n  left_join(vars3, \"parcela\") |&gt;\n  left_join(df |&gt; \n              select(c(x, y, parcela)) |&gt;\n              distinct(parcela, .keep_all = T),\n            \"parcela\") |&gt;\n  left_join(vars4, \"parcela\") |&gt;\n  select(parcela, x, y, cob, AGBplot, BAplot, Dplot, Stemplot, Hmplot, H10plot)\n\n# Rename columns\ncolnames(resul) &lt;- c(\"Plot\", \"Lat\", \"Long\",\n                     \"Cob(%)\", \"AGB(Mgha-1)\", \"BA(m2ha-1)\",\n                     \"Dplot(indha-1)\", \"Stemplot(stemha-1)\",\n                     \"Hmean(m)\", \"H10mean(m)\")\n\nresul &lt;- resul |&gt;\n  select(-c(Lat, Long))\n\ncoords &lt;- coords |&gt;\n  rename(\"yutm\" = \"ytum\") |&gt;\n  select(name, elevation, date, xutm, yutm) |&gt;\n  mutate(across(name, ~str_to_title(.x))) |&gt;\n  rename(\"Plot\" = \"name\")\n\nresul &lt;- resul |&gt;\n  left_join(coords, \"Plot\") |&gt;\n  select(Plot, xutm, yutm, everything()) |&gt;\n  mutate(year = 2022)\nResults look like the following.\n# A tibble: 2 × 13\n  Plot     xutm   yutm `Cob(%)` `AGB(Mgha-1)` `BA(m2ha-1)` `Dplot(indha-1)` `Stemplot(stemha-1)` `Hmean(m)`\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;            &lt;dbl&gt;                &lt;dbl&gt;      &lt;dbl&gt;\n1 Amacu… 5.93e5 2.20e6       75          37.6         18.2            2919.                5159.       4.46\n2 Limon1 5.87e5 2.19e6       75          52.8         29.4            2130.                4410.       3.77\n# ℹ 4 more variables: `H10mean(m)` &lt;dbl&gt;, elevation &lt;dbl&gt;, date &lt;chr&gt;, year &lt;dbl&gt;"
  },
  {
    "objectID": "posts/2024-05-29-raster-parallel-processing.html",
    "href": "posts/2024-05-29-raster-parallel-processing.html",
    "title": "Raster parallel processing in R",
    "section": "",
    "text": "Raster parallel processing in R\nThis post shows how to parallelize raster processing in R.\nFirst load the required packages\nlibrary(raster)\nlibrary(parallel)\nlibrary(doParallel)\nlibrary(foreach)\nThen read a raster example from the terra package\nr &lt;- raster(system.file(\"ex/elev.tif\", package = \"terra\"))\nr &lt;- stack(r, r)\nInitialize cluster and run process in parallel. Notice that inside the foreach you should indicate the packages that need to be loaded into the parallel processing.\ncls &lt;- makeCluster(2L)\nregisterDoParallel(cls)\nclust_list_t &lt;- foreach(i = 1:2, \n                        .packages = \"raster\") %dopar% {\n                          if(i == 1){\n                            ras &lt;- r[[i]] * 3\n                          }else{\n                            ras &lt;- r[[i]] * 5\n                          }\n                          \n                          return(ras)\n                        }"
  },
  {
    "objectID": "posts/2024-12-10-extract-pdf-tables.html",
    "href": "posts/2024-12-10-extract-pdf-tables.html",
    "title": "Extract tables from pdf in R",
    "section": "",
    "text": "This blog entry will show how to extract tables from a pdf, using tabulizer. Load necessary packages.\nlibrary(tabulizer)\nlibrary(tidyverse)\nRead the pdf of interest, indicating the pages in which the table is located.\ntable1 &lt;- extract_tables(\"IUCN_mesoamerica_restoration.pdf\",\n                            output = \"data.frame\",\n                            pages = c(388:417), \n                            area = NULL,\n                            guess = TRUE\n                            \n)\nThen join tables located in different pages as the same table. Substitute empty cells by NA and locate extra rows based on the NA located in the first column (Familia). Then join extra rows with the previous one.\n# Unir listas como filas de un mismo dataframe\nexp_table &lt;- dplyr::bind_rows(table1)\n# Sustituir espacios en blanco por NA\nexp_table[exp_table==\"\"] &lt;- NA\n# Ver dónde hay NA en la columna de Familias para identificar filas extra\ninds &lt;- which(is.na(exp_table$Familia))\n\n# PAra esas filas extra pegar el texto con la fila anterior\nfor(i in inds){\n  if(!is.na(exp_table$Hábitat[i])){\n    exp_table$Hábitat[(i-1)] &lt;- paste(exp_table$Hábitat[(i-1)], exp_table$Hábitat[i], collapse = \" \")  \n  }\n  if(!is.na(exp_table$Distribución[i])){\n    exp_table$Distribución[(i-1)] &lt;- paste(exp_table$Distribución[(i-1)], exp_table$Distribución[i], collapse = \" \")\n  }\n}\nFinally, export the result to a csv\n# Exportar\nexp_table |&gt;\n  # Quitar columnas con NA en la columna familia\n  filter(!is.na(Familia)) |&gt;\n  # Escribir\n  write.csv(\"IUCN_ApendiceA1.csv\",\n            row.names = FALSE,\n            fileEncoding = \"UTF-8\")"
  },
  {
    "objectID": "posts/2024-12-13-Google-drive-in-r.html",
    "href": "posts/2024-12-13-Google-drive-in-r.html",
    "title": "Google Drive in R",
    "section": "",
    "text": "This post shows how to connect to your Google Drive API. A very good tutorial can be found here: trackdown tutorial.\nHere are the main steps\nlibrary(googledriveR)\n\n\nGo to Google Cloud Console and accept terms of use. Then, create a new project, specify name an accept. The tab opnening the projects is right next to Google Cloud logo.\n\n\n\nGoogle cloud project\n\n\nOnce created, open the project (using the same tab as previous step) and click on the three lines left of the Google Cloud logo, go to APIs & Services and Enabled APIs & services.\n\n\n\nGoogle Cloud API\n\n\nNext, go to enable apis and services.\n]\nThen search for google drive api and click on it. An enable button will appear, click on it to enable. Do the same for Google Docs API.\n\n\n\nGCAPI\n\n\nOnce both APIS are enabled go back to the APIs & Services menu and click on OAuth consent screen. Then click on external option and create.\n\n\n\nConsent\n\n\nThen, you need to create an app name and associate an email with the app, as well as a developer contact. Next click on add or remove scopes. Activate “…/auth/userinfo.email” “openid”, “…/auth/drive” and “…/auth/docs”. Finally, update, save changes and accept.\nBack in the OAuth consent screen publish app and confirm.\nThe next step is go to the credentials menu and create a nuew OAuth 2.0 Client IDs. Go to create credentials, OAUth client ID, select application type = Desktop app and set the desired name. Next, the credential will be shown. Click on download json and save file in your local disk.\n\n\n\nCredentials\n\n\nNext, open RStudio locally, install “usethis” package and use usethis::edit_r_environ() to modify the environment, which will be run everytime R starts. In this file save the following: GOOGLEDRIVE_PATH = {location}, setting the location of your json secret instead of {location}.\nAfter this step, save, restart R, and install “googledrive”. And add the following to your script. First time you run the auth configure step, a window will popup asking for permission. Give permissions and you are ready to use Google Drive from R.\nlibrary(googledrive)\n\ndrive_auth_configure(gargle::gargle_oauth_client_from_json(Sys.getenv(\"GOOGLEDRIVE_PATH\")))"
  },
  {
    "objectID": "posts/2024-12-13-Google-drive-in-r.html#create-project-in-google-cloud",
    "href": "posts/2024-12-13-Google-drive-in-r.html#create-project-in-google-cloud",
    "title": "Google Drive in R",
    "section": "",
    "text": "Go to Google Cloud Console and accept terms of use. Then, create a new project, specify name an accept. The tab opnening the projects is right next to Google Cloud logo.\n\n\n\nGoogle cloud project\n\n\nOnce created, open the project (using the same tab as previous step) and click on the three lines left of the Google Cloud logo, go to APIs & Services and Enabled APIs & services.\n\n\n\nGoogle Cloud API\n\n\nNext, go to enable apis and services.\n]\nThen search for google drive api and click on it. An enable button will appear, click on it to enable. Do the same for Google Docs API.\n\n\n\nGCAPI\n\n\nOnce both APIS are enabled go back to the APIs & Services menu and click on OAuth consent screen. Then click on external option and create.\n\n\n\nConsent\n\n\nThen, you need to create an app name and associate an email with the app, as well as a developer contact. Next click on add or remove scopes. Activate “…/auth/userinfo.email” “openid”, “…/auth/drive” and “…/auth/docs”. Finally, update, save changes and accept.\nBack in the OAuth consent screen publish app and confirm.\nThe next step is go to the credentials menu and create a nuew OAuth 2.0 Client IDs. Go to create credentials, OAUth client ID, select application type = Desktop app and set the desired name. Next, the credential will be shown. Click on download json and save file in your local disk.\n\n\n\nCredentials\n\n\nNext, open RStudio locally, install “usethis” package and use usethis::edit_r_environ() to modify the environment, which will be run everytime R starts. In this file save the following: GOOGLEDRIVE_PATH = {location}, setting the location of your json secret instead of {location}.\nAfter this step, save, restart R, and install “googledrive”. And add the following to your script. First time you run the auth configure step, a window will popup asking for permission. Give permissions and you are ready to use Google Drive from R.\nlibrary(googledrive)\n\ndrive_auth_configure(gargle::gargle_oauth_client_from_json(Sys.getenv(\"GOOGLEDRIVE_PATH\")))"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Map accuracy in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMar 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCreate certificates in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle Drive in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nExtract tables from pdf in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSTAC in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRaster parallel processing in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLeaflet in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAGB forest sampling calculations\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRasters and vectors with terra\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJul 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with LiDAR data in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJun 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBeautiful-plots(ggplot2)-in-r\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJun 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping with r\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Foris tools in r\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJun 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nShiny App with spatial data\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMay 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify API in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nApr 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nVolcanos 3d maps\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMar 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nShaded relief maps in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRGB Shaded relief maps in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n3D maps in r\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies occurrence data in r\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLandscape metrics in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory data analysis in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n3D histograms in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPresentations in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSoundscape analysis in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRegular expressions in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nMar 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInformación espacial en formato raster en R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInformación espacial en formato vector en R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with tidymodels and rasters in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWordcloud in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nMaking maps in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nMaking diagrams in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nMaking animations in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nJan 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating image texture in R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nAug 23, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nModelos digitales de elevación en R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nManejo de imágenes en R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nClasificación supervisada en R\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nFeb 6, 2020\n\n\n\n\n\nNo matching items"
  }
]